{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from collections import deque\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "parameters",
     "key"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    key = key or input()\n",
    "except NameError:\n",
    "    key = input('type your wandb api key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfelissi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\felixwong/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b598050de0a74af1b3b7a51c29daab32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\felixwong\\Desktop\\py alg practice\\machine_learning\\1024\\wandb\\run-20230221_115946-f0pojqh3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/felissi/my-awesome-project/runs/f0pojqh3' target=\"_blank\">azure-mountain-24</a></strong> to <a href='https://wandb.ai/felissi/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/felissi/my-awesome-project' target=\"_blank\">https://wandb.ai/felissi/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/felissi/my-awesome-project/runs/f0pojqh3' target=\"_blank\">https://wandb.ai/felissi/my-awesome-project/runs/f0pojqh3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in thread NetStatThr:\n",
      "ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\threading.py\", line 910, in run\n",
      "    self.run()\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 256, in check_network_status\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 274, in check_stop_status\n",
      "    self._loop_check_status(    \n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 214, in _loop_check_status\n",
      "self._loop_check_status(\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 214, in _loop_check_status\n",
      "    local_handle = request()\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 788, in deliver_stop_status\n",
      "    local_handle = request()\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 796, in deliver_network_status\n",
      "        return self._deliver_stop_status(status)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 586, in _deliver_stop_status\n",
      "return self._deliver_network_status(status)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 602, in _deliver_network_status\n",
      "    return self._deliver_record(record)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 561, in _deliver_record\n",
      "    return self._deliver_record(record)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 561, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py\", line 445, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py\", line 445, in _deliver_record\n",
      "    interface._publish(record)    interface._publish(record)\n",
      "\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)    \n",
      "self.send_server_request(server_req)  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n",
      "\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n",
      "    self._send_message(msg)\n",
      "    self._sendall_with_error_handle(header + data)  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n",
      "\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host    sent = self._sock.send(data)\n",
      "ConnectionResetError\n",
      ": [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 1133, in init\n",
      "    run = wi.init()\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 816, in init\n",
      "    run._on_start()\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 2166, in _on_start\n",
      "    self._on_ready()\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 2207, in _on_ready\n",
      "    self._telemetry_flush()\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 704, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 101, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"c:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: C:\\Users\\felixwong\\AppData\\Local\\Temp\\ipykernel_9404\\3596492707.py 1 <cell line: 1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"my-awesome-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Agent import Agent\n",
    "from Board import Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE         = int(1e4)\n",
    "BATCH_SIZE          = 64\n",
    "GAMMA               = 0.90  # discount factor\n",
    "TAU                 = 1e-3  # soft update of target parameter\n",
    "LEARNING_RATE       = 1e-3\n",
    "UPDATE_EVERY        = 10    # how often to update the local\n",
    "TARGET_UPDATE_EVERY = 50    # how often to update the target\n",
    "STATE_SIZE          = 16\n",
    "ACTION_SIZE         = 4   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(STATE_SIZE, ACTION_SIZE, LEARNING_RATE, BUFFER_SIZE, BATCH_SIZE)\n",
    "env = Board()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must call `wandb.init` before calling watch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\felixwong\\Desktop\\py alg practice\\machine_learning\\1024\\wandb_log.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/felixwong/Desktop/py%20alg%20practice/machine_learning/1024/wandb_log.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m wandb\u001b[39m.\u001b[39;49mwatch(agent\u001b[39m.\u001b[39;49mqnetwork_local,log_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\felixwong\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_watch.py:54\u001b[0m, in \u001b[0;36mwatch\u001b[1;34m(models, criterion, log, log_freq, idx, log_graph)\u001b[0m\n\u001b[0;32m     51\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mWatching\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m wandb\u001b[39m.\u001b[39mrun \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou must call `wandb.init` before calling watch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[39mif\u001b[39;00m log \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mgradients\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mparameters\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m}:\n\u001b[0;32m     57\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlog must be one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mgradients\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mparameters\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or None\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: You must call `wandb.init` before calling watch"
     ]
    }
   ],
   "source": [
    "wandb.watch(agent.qnetwork_local,log_freq=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring metrics and parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for how the model doing and updating\n",
    "1. q values\n",
    "1. gradients\n",
    "1. loss\n",
    "1. eps\n",
    "1. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Metrics for model's performance\n",
    "1. largest number of the board\n",
    "1. accumulate reward\n",
    "1. number of rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent: Agent, n_episodes, max_time_step, eps_start, eps_end, eps_decay):\n",
    "    scores = []\n",
    "    num_rounds = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    eps = eps_start\n",
    "    for episode in range(n_episodes):\n",
    "        env.reset()\n",
    "        state = env.board\n",
    "        accumulate_reward = 0\n",
    "        rounds = 0\n",
    "        for time_step in range(max_time_step):\n",
    "            action_values = agent.q_value(state, eps)\n",
    "            action = agent.decide(action_values, eps)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            \"\"\" === this step has finished === \"\"\"\n",
    "            wandb.log({'action':action, 'reward': reward, 'eps': eps})\n",
    "            wandb.log({f'action_values[{i}]':q for i, q in enumerate(action_values.cpu().numpy().flatten()) })\n",
    "            if agent.time_step % UPDATE_EVERY == 0 and len(agent.memory) > BATCH_SIZE:\n",
    "                loss = agent.learn_from_experience()\n",
    "                wandb.log({'loss':loss})\n",
    "            if agent.time_step % TARGET_UPDATE_EVERY == 0:\n",
    "                agent.soft_update()\n",
    "            \"\"\" === next iteration === \"\"\"\n",
    "            state = next_state\n",
    "            accumulate_reward += reward\n",
    "            rounds += 1\n",
    "            if done:\n",
    "                wandb.log({'rounds':rounds,'accumulate_reward':accumulate_reward, 'max_number':np.max(state)})\n",
    "                break\n",
    "        scores_window.append(accumulate_reward)\n",
    "        scores.append(accumulate_reward)\n",
    "        num_rounds.append(rounds)\n",
    "        eps = max(eps_end, eps-eps_decay)\n",
    "        if episode % 100 == 0:\n",
    "            print(episode, np.mean(scores_window))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pt')\n",
    "    return scores, num_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rounds': 75, 'accumulate_reward': 1460, 'max_number': 32, 'loss': tensor(609.5389, grad_fn=<MseLossBackward0>)}\n",
      "0 1460.0\n",
      "{'rounds': 57, 'accumulate_reward': 1060, 'max_number': 32, 'loss': tensor(542.6468, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 168, 'accumulate_reward': 2180, 'max_number': 128, 'loss': tensor(417.6039, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 1970, 'max_number': 128, 'loss': tensor(332.1172, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 126, 'accumulate_reward': 1770, 'max_number': 128, 'loss': tensor(370.2298, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1430, 'max_number': 64, 'loss': tensor(255.6561, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1500, 'max_number': 32, 'loss': tensor(338.3432, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(471.4345, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1410, 'max_number': 64, 'loss': tensor(279.0791, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 159, 'accumulate_reward': 2020, 'max_number': 128, 'loss': tensor(268.6292, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 144, 'accumulate_reward': 2020, 'max_number': 128, 'loss': tensor(347.0225, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 2030, 'max_number': 128, 'loss': tensor(253.9778, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 133, 'accumulate_reward': 1900, 'max_number': 128, 'loss': tensor(256.6115, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 158, 'accumulate_reward': 2090, 'max_number': 128, 'loss': tensor(254.1276, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 150, 'accumulate_reward': 2040, 'max_number': 128, 'loss': tensor(271.3648, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 1960, 'max_number': 128, 'loss': tensor(238.2364, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1600, 'max_number': 64, 'loss': tensor(288.2675, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 134, 'accumulate_reward': 1890, 'max_number': 128, 'loss': tensor(340.8445, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 154, 'accumulate_reward': 2150, 'max_number': 128, 'loss': tensor(289.7308, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(354.2971, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 176, 'accumulate_reward': 2070, 'max_number': 128, 'loss': tensor(326.5484, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1490, 'max_number': 64, 'loss': tensor(363.8285, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1880, 'max_number': 128, 'loss': tensor(312.4085, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 1560, 'max_number': 64, 'loss': tensor(330.4497, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(329.7204, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 150, 'accumulate_reward': 2000, 'max_number': 128, 'loss': tensor(267.5815, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1840, 'max_number': 128, 'loss': tensor(215.7744, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1500, 'max_number': 64, 'loss': tensor(301.8724, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1220, 'max_number': 64, 'loss': tensor(192.8953, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1550, 'max_number': 64, 'loss': tensor(232.9510, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 153, 'accumulate_reward': 1740, 'max_number': 128, 'loss': tensor(242.9126, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1530, 'max_number': 64, 'loss': tensor(205.9114, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 146, 'accumulate_reward': 2020, 'max_number': 128, 'loss': tensor(311.5573, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(337.4973, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1450, 'max_number': 64, 'loss': tensor(334.3631, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1810, 'max_number': 64, 'loss': tensor(220.3680, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 107, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(186.0829, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1790, 'max_number': 128, 'loss': tensor(191.8241, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1290, 'max_number': 64, 'loss': tensor(267.7085, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 1940, 'max_number': 128, 'loss': tensor(306.4214, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 137, 'accumulate_reward': 1990, 'max_number': 128, 'loss': tensor(301.5783, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1360, 'max_number': 64, 'loss': tensor(228.7188, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 178, 'accumulate_reward': 2050, 'max_number': 128, 'loss': tensor(310.9259, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1540, 'max_number': 64, 'loss': tensor(211.7769, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1510, 'max_number': 64, 'loss': tensor(152.1550, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 1910, 'max_number': 64, 'loss': tensor(215.8368, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 153, 'accumulate_reward': 2420, 'max_number': 128, 'loss': tensor(193.7475, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 151, 'accumulate_reward': 1900, 'max_number': 128, 'loss': tensor(221.1759, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1630, 'max_number': 128, 'loss': tensor(180.0610, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 139, 'accumulate_reward': 2150, 'max_number': 128, 'loss': tensor(217.3993, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 119, 'accumulate_reward': 1680, 'max_number': 128, 'loss': tensor(221.5694, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 149, 'accumulate_reward': 2160, 'max_number': 128, 'loss': tensor(208.0150, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1640, 'max_number': 64, 'loss': tensor(215.7526, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 1790, 'max_number': 128, 'loss': tensor(156.7708, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 85, 'accumulate_reward': 1350, 'max_number': 64, 'loss': tensor(238.7230, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(203.0688, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1700, 'max_number': 128, 'loss': tensor(152.8056, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1880, 'max_number': 64, 'loss': tensor(174.1729, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(200.0232, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 203, 'accumulate_reward': 2300, 'max_number': 256, 'loss': tensor(179.3051, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 155, 'accumulate_reward': 2120, 'max_number': 128, 'loss': tensor(166.1882, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 144, 'accumulate_reward': 2190, 'max_number': 128, 'loss': tensor(150.9992, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 107, 'accumulate_reward': 1760, 'max_number': 128, 'loss': tensor(193.5163, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 137, 'accumulate_reward': 1730, 'max_number': 128, 'loss': tensor(137.8711, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 131, 'accumulate_reward': 1910, 'max_number': 128, 'loss': tensor(196.6861, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1950, 'max_number': 64, 'loss': tensor(203.9240, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1250, 'max_number': 32, 'loss': tensor(149.9581, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1840, 'max_number': 128, 'loss': tensor(133.9153, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 148, 'accumulate_reward': 2310, 'max_number': 128, 'loss': tensor(149.0445, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 84, 'accumulate_reward': 1530, 'max_number': 64, 'loss': tensor(209.5848, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 149, 'accumulate_reward': 1900, 'max_number': 128, 'loss': tensor(195.6243, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(165.4078, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1530, 'max_number': 32, 'loss': tensor(152.5755, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 169, 'accumulate_reward': 2210, 'max_number': 128, 'loss': tensor(77.4468, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 168, 'accumulate_reward': 2040, 'max_number': 128, 'loss': tensor(131.7276, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 166, 'accumulate_reward': 2190, 'max_number': 128, 'loss': tensor(109.7939, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 57, 'accumulate_reward': 1200, 'max_number': 32, 'loss': tensor(122.2317, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 156, 'accumulate_reward': 1900, 'max_number': 128, 'loss': tensor(104.8840, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 65, 'accumulate_reward': 1370, 'max_number': 32, 'loss': tensor(147.8919, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1550, 'max_number': 64, 'loss': tensor(119.1086, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(152.9335, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1640, 'max_number': 64, 'loss': tensor(163.4545, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 69, 'accumulate_reward': 1360, 'max_number': 32, 'loss': tensor(137.4616, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 156, 'accumulate_reward': 2320, 'max_number': 128, 'loss': tensor(113.8371, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 66, 'accumulate_reward': 1430, 'max_number': 32, 'loss': tensor(156.3122, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 70, 'accumulate_reward': 1250, 'max_number': 32, 'loss': tensor(170.7951, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(147.0167, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 93, 'accumulate_reward': 1600, 'max_number': 64, 'loss': tensor(122.8136, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1670, 'max_number': 32, 'loss': tensor(121.0412, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 65, 'accumulate_reward': 1340, 'max_number': 32, 'loss': tensor(118.5751, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1720, 'max_number': 32, 'loss': tensor(145.2613, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 93, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(133.6929, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1620, 'max_number': 32, 'loss': tensor(89.9324, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 133, 'accumulate_reward': 1940, 'max_number': 64, 'loss': tensor(118.4266, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1770, 'max_number': 64, 'loss': tensor(126.6517, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1860, 'max_number': 64, 'loss': tensor(93.3274, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 175, 'accumulate_reward': 2290, 'max_number': 128, 'loss': tensor(137.8290, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 55, 'accumulate_reward': 1170, 'max_number': 32, 'loss': tensor(92.6996, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(148.3748, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 129, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(59.7540, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1700, 'max_number': 64, 'loss': tensor(131.2401, grad_fn=<MseLossBackward0>)}\n",
      "100 1756.9\n",
      "{'rounds': 60, 'accumulate_reward': 1500, 'max_number': 32, 'loss': tensor(100.8343, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 2020, 'max_number': 64, 'loss': tensor(100.8405, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 135, 'accumulate_reward': 1960, 'max_number': 128, 'loss': tensor(170.8695, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 136, 'accumulate_reward': 2080, 'max_number': 128, 'loss': tensor(121.9941, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 144, 'accumulate_reward': 2030, 'max_number': 128, 'loss': tensor(149.3519, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 119, 'accumulate_reward': 1980, 'max_number': 64, 'loss': tensor(161.5838, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1390, 'max_number': 64, 'loss': tensor(114.3551, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1870, 'max_number': 64, 'loss': tensor(142.1754, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 86, 'accumulate_reward': 1490, 'max_number': 64, 'loss': tensor(91.6751, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 140, 'accumulate_reward': 2120, 'max_number': 128, 'loss': tensor(117.9237, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1790, 'max_number': 64, 'loss': tensor(145.7136, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1390, 'max_number': 32, 'loss': tensor(158.8446, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(138.8652, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1490, 'max_number': 32, 'loss': tensor(124.7994, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 86, 'accumulate_reward': 1820, 'max_number': 32, 'loss': tensor(148.1664, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 90, 'accumulate_reward': 1650, 'max_number': 32, 'loss': tensor(125.8875, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1860, 'max_number': 32, 'loss': tensor(125.9186, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 48, 'accumulate_reward': 1100, 'max_number': 16, 'loss': tensor(104.0165, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1470, 'max_number': 32, 'loss': tensor(93.7528, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 64, 'accumulate_reward': 1280, 'max_number': 32, 'loss': tensor(133.3628, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 59, 'accumulate_reward': 1520, 'max_number': 16, 'loss': tensor(172.7406, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(146.8337, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1770, 'max_number': 64, 'loss': tensor(114.0991, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(98.7099, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(102.9446, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 118, 'accumulate_reward': 2120, 'max_number': 64, 'loss': tensor(120.3388, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 172, 'accumulate_reward': 2420, 'max_number': 128, 'loss': tensor(140.6504, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1590, 'max_number': 32, 'loss': tensor(136.9244, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 107, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(70.3911, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(121.4294, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(105.6579, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(106.2297, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 76, 'accumulate_reward': 1460, 'max_number': 32, 'loss': tensor(113.0813, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 90, 'accumulate_reward': 1770, 'max_number': 64, 'loss': tensor(119.8726, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 58, 'accumulate_reward': 1480, 'max_number': 16, 'loss': tensor(167.4803, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 65, 'accumulate_reward': 1380, 'max_number': 32, 'loss': tensor(113.0810, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1860, 'max_number': 64, 'loss': tensor(133.2701, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1470, 'max_number': 32, 'loss': tensor(115.2714, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1500, 'max_number': 32, 'loss': tensor(145.6320, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(98.7941, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(134.7667, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1710, 'max_number': 32, 'loss': tensor(127.4706, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(138.9429, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1910, 'max_number': 32, 'loss': tensor(120.2401, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 117, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(136.5747, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(108.9417, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1540, 'max_number': 64, 'loss': tensor(102.0781, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 136, 'accumulate_reward': 2070, 'max_number': 64, 'loss': tensor(90.8632, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 65, 'accumulate_reward': 1390, 'max_number': 32, 'loss': tensor(127.5957, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(130.6899, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1410, 'max_number': 64, 'loss': tensor(111.0985, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 117, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(109.6915, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 129, 'accumulate_reward': 2050, 'max_number': 64, 'loss': tensor(104.9224, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 86, 'accumulate_reward': 1360, 'max_number': 32, 'loss': tensor(104.4693, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(113.2113, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1670, 'max_number': 32, 'loss': tensor(129.6258, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(121.2804, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 126, 'accumulate_reward': 1950, 'max_number': 128, 'loss': tensor(145.2308, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(107.2139, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 61, 'accumulate_reward': 1430, 'max_number': 16, 'loss': tensor(123.5364, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 165, 'accumulate_reward': 2070, 'max_number': 128, 'loss': tensor(109.2467, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 2210, 'max_number': 128, 'loss': tensor(113.8887, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1810, 'max_number': 32, 'loss': tensor(120.1232, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 75, 'accumulate_reward': 1430, 'max_number': 32, 'loss': tensor(142.9086, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(116.1655, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(159.7597, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 52, 'accumulate_reward': 1230, 'max_number': 16, 'loss': tensor(129.3791, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 64, 'accumulate_reward': 1320, 'max_number': 32, 'loss': tensor(124.7775, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 51, 'accumulate_reward': 1270, 'max_number': 16, 'loss': tensor(146.0666, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1420, 'max_number': 64, 'loss': tensor(162.6691, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 86, 'accumulate_reward': 1550, 'max_number': 64, 'loss': tensor(141.1992, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1620, 'max_number': 64, 'loss': tensor(140.2690, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1350, 'max_number': 32, 'loss': tensor(70.1098, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1620, 'max_number': 64, 'loss': tensor(127.7325, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(126.6012, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(129.7084, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 76, 'accumulate_reward': 1480, 'max_number': 32, 'loss': tensor(99.9722, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 159, 'accumulate_reward': 2120, 'max_number': 128, 'loss': tensor(142.9627, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1380, 'max_number': 64, 'loss': tensor(108.2312, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(101.0259, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1500, 'max_number': 32, 'loss': tensor(100.9860, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 58, 'accumulate_reward': 1220, 'max_number': 32, 'loss': tensor(186.6551, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(91.1972, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1870, 'max_number': 32, 'loss': tensor(92.7384, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(128.7256, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(125.8073, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 116, 'accumulate_reward': 2040, 'max_number': 64, 'loss': tensor(112.2478, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 70, 'accumulate_reward': 1500, 'max_number': 32, 'loss': tensor(134.1669, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 142, 'accumulate_reward': 2160, 'max_number': 128, 'loss': tensor(120.7462, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 2010, 'max_number': 64, 'loss': tensor(91.1434, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1810, 'max_number': 32, 'loss': tensor(107.6518, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 139, 'accumulate_reward': 2060, 'max_number': 128, 'loss': tensor(148.1678, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(140.0872, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1890, 'max_number': 32, 'loss': tensor(97.9412, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 1570, 'max_number': 64, 'loss': tensor(148.3966, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1860, 'max_number': 64, 'loss': tensor(161.1715, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 2050, 'max_number': 64, 'loss': tensor(108.7240, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1510, 'max_number': 64, 'loss': tensor(110.8355, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 141, 'accumulate_reward': 2160, 'max_number': 64, 'loss': tensor(97.3937, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 66, 'accumulate_reward': 1260, 'max_number': 32, 'loss': tensor(134.9281, grad_fn=<MseLossBackward0>)}\n",
      "200 1704.0\n",
      "{'rounds': 112, 'accumulate_reward': 1870, 'max_number': 64, 'loss': tensor(103.4520, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 1860, 'max_number': 64, 'loss': tensor(93.1667, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(134.2821, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 160, 'accumulate_reward': 2080, 'max_number': 64, 'loss': tensor(129.6083, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 2090, 'max_number': 64, 'loss': tensor(112.5302, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1970, 'max_number': 64, 'loss': tensor(80.5818, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 165, 'accumulate_reward': 2370, 'max_number': 128, 'loss': tensor(98.0131, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 84, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(81.4366, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 133, 'accumulate_reward': 2170, 'max_number': 128, 'loss': tensor(114.1493, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1520, 'max_number': 32, 'loss': tensor(96.0471, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1470, 'max_number': 64, 'loss': tensor(95.1800, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1440, 'max_number': 32, 'loss': tensor(125.4862, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1730, 'max_number': 32, 'loss': tensor(86.8331, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(116.1221, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1600, 'max_number': 64, 'loss': tensor(130.5181, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1500, 'max_number': 32, 'loss': tensor(104.1495, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(136.4441, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 225, 'accumulate_reward': 2480, 'max_number': 256, 'loss': tensor(70.3072, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(95.8690, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 158, 'accumulate_reward': 1920, 'max_number': 128, 'loss': tensor(115.3919, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 162, 'accumulate_reward': 2110, 'max_number': 128, 'loss': tensor(164.2621, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(85.9001, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 129, 'accumulate_reward': 1870, 'max_number': 64, 'loss': tensor(118.8677, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 133, 'accumulate_reward': 1950, 'max_number': 64, 'loss': tensor(128.9184, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(158.1414, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 144, 'accumulate_reward': 2270, 'max_number': 128, 'loss': tensor(87.3095, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1870, 'max_number': 64, 'loss': tensor(170.3029, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 2040, 'max_number': 64, 'loss': tensor(89.4951, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 90, 'accumulate_reward': 1810, 'max_number': 64, 'loss': tensor(130.5324, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(104.8681, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 64, 'accumulate_reward': 1350, 'max_number': 32, 'loss': tensor(86.8385, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1810, 'max_number': 64, 'loss': tensor(76.3964, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 155, 'accumulate_reward': 1920, 'max_number': 128, 'loss': tensor(100.2833, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 135, 'accumulate_reward': 1910, 'max_number': 128, 'loss': tensor(117.5303, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 107, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(93.7094, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1600, 'max_number': 32, 'loss': tensor(116.3151, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 116, 'accumulate_reward': 1950, 'max_number': 64, 'loss': tensor(105.3852, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1810, 'max_number': 32, 'loss': tensor(93.3651, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1630, 'max_number': 64, 'loss': tensor(84.0632, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1760, 'max_number': 32, 'loss': tensor(86.5845, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 174, 'accumulate_reward': 2350, 'max_number': 128, 'loss': tensor(102.3123, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1470, 'max_number': 32, 'loss': tensor(110.3056, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1530, 'max_number': 64, 'loss': tensor(95.9420, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 61, 'accumulate_reward': 1340, 'max_number': 32, 'loss': tensor(106.4444, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(134.3197, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1750, 'max_number': 32, 'loss': tensor(82.3857, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1770, 'max_number': 32, 'loss': tensor(139.5191, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1700, 'max_number': 64, 'loss': tensor(80.4313, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 137, 'accumulate_reward': 2120, 'max_number': 64, 'loss': tensor(135.4248, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1510, 'max_number': 64, 'loss': tensor(103.3133, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 152, 'accumulate_reward': 1800, 'max_number': 128, 'loss': tensor(172.4808, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 123, 'accumulate_reward': 2050, 'max_number': 128, 'loss': tensor(97.1670, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(97.4269, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 1780, 'max_number': 128, 'loss': tensor(84.7675, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1430, 'max_number': 32, 'loss': tensor(135.5200, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 185, 'accumulate_reward': 2170, 'max_number': 128, 'loss': tensor(120.5499, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 64, 'accumulate_reward': 1260, 'max_number': 32, 'loss': tensor(139.7085, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 1640, 'max_number': 128, 'loss': tensor(103.9861, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 105, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(127.6709, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(79.0545, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1900, 'max_number': 64, 'loss': tensor(111.8777, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 130, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(95.7050, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(99.8117, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1810, 'max_number': 64, 'loss': tensor(101.2910, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1330, 'max_number': 32, 'loss': tensor(92.7773, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1740, 'max_number': 32, 'loss': tensor(111.3371, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 116, 'accumulate_reward': 1900, 'max_number': 64, 'loss': tensor(135.4032, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1880, 'max_number': 64, 'loss': tensor(112.6963, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 130, 'accumulate_reward': 1920, 'max_number': 128, 'loss': tensor(106.9172, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(138.2193, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1930, 'max_number': 64, 'loss': tensor(127.3222, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 159, 'accumulate_reward': 2070, 'max_number': 128, 'loss': tensor(114.6900, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1550, 'max_number': 32, 'loss': tensor(126.3147, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 148, 'accumulate_reward': 2270, 'max_number': 128, 'loss': tensor(131.1200, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 47, 'accumulate_reward': 1170, 'max_number': 16, 'loss': tensor(105.8153, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 71, 'accumulate_reward': 1730, 'max_number': 32, 'loss': tensor(95.3953, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(99.3344, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 66, 'accumulate_reward': 1170, 'max_number': 32, 'loss': tensor(105.2136, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1560, 'max_number': 64, 'loss': tensor(108.8312, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 107, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(129.2660, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 90, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(137.0733, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 187, 'accumulate_reward': 2190, 'max_number': 256, 'loss': tensor(105.8877, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1610, 'max_number': 32, 'loss': tensor(144.3168, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(169.3653, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 2080, 'max_number': 128, 'loss': tensor(95.4221, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1940, 'max_number': 64, 'loss': tensor(105.3068, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(126.1578, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 152, 'accumulate_reward': 2070, 'max_number': 128, 'loss': tensor(104.7705, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 40, 'accumulate_reward': 1110, 'max_number': 16, 'loss': tensor(154.3554, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 304, 'accumulate_reward': 2580, 'max_number': 256, 'loss': tensor(85.5564, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1560, 'max_number': 64, 'loss': tensor(111.4847, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 144, 'accumulate_reward': 1830, 'max_number': 128, 'loss': tensor(91.4354, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 60, 'accumulate_reward': 1220, 'max_number': 32, 'loss': tensor(142.8386, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 138, 'accumulate_reward': 2000, 'max_number': 128, 'loss': tensor(136.3693, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 163, 'accumulate_reward': 2110, 'max_number': 128, 'loss': tensor(141.4861, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1900, 'max_number': 64, 'loss': tensor(138.6173, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 172, 'accumulate_reward': 2080, 'max_number': 128, 'loss': tensor(121.5327, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 147, 'accumulate_reward': 1960, 'max_number': 128, 'loss': tensor(146.9138, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 150, 'accumulate_reward': 1990, 'max_number': 128, 'loss': tensor(86.6240, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(106.3188, grad_fn=<MseLossBackward0>)}\n",
      "300 1796.3\n",
      "{'rounds': 97, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(137.7178, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 178, 'accumulate_reward': 2270, 'max_number': 256, 'loss': tensor(140.9224, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(85.6591, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1950, 'max_number': 64, 'loss': tensor(100.0411, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1640, 'max_number': 32, 'loss': tensor(133.7271, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(149.5168, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 76, 'accumulate_reward': 1560, 'max_number': 64, 'loss': tensor(144.5910, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1370, 'max_number': 32, 'loss': tensor(134.1884, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 128, 'accumulate_reward': 2070, 'max_number': 128, 'loss': tensor(131.5380, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 84, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(111.0347, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 2110, 'max_number': 64, 'loss': tensor(74.2209, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 116, 'accumulate_reward': 1870, 'max_number': 64, 'loss': tensor(128.7180, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 69, 'accumulate_reward': 1290, 'max_number': 64, 'loss': tensor(137.5391, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 107, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(155.7586, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1520, 'max_number': 64, 'loss': tensor(124.8789, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 2250, 'max_number': 64, 'loss': tensor(148.3807, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 2130, 'max_number': 128, 'loss': tensor(92.7956, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(152.4029, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(138.8478, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 2120, 'max_number': 64, 'loss': tensor(181.8430, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 76, 'accumulate_reward': 1780, 'max_number': 32, 'loss': tensor(131.7423, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 157, 'accumulate_reward': 2050, 'max_number': 128, 'loss': tensor(120.9020, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 117, 'accumulate_reward': 1920, 'max_number': 64, 'loss': tensor(130.5327, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1980, 'max_number': 64, 'loss': tensor(118.9814, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 2000, 'max_number': 64, 'loss': tensor(129.0899, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 167, 'accumulate_reward': 2070, 'max_number': 128, 'loss': tensor(156.8323, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1380, 'max_number': 32, 'loss': tensor(100.8599, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 126, 'accumulate_reward': 2020, 'max_number': 64, 'loss': tensor(104.8330, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(131.1591, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 1950, 'max_number': 64, 'loss': tensor(98.6302, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1450, 'max_number': 64, 'loss': tensor(127.3134, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 162, 'accumulate_reward': 2150, 'max_number': 128, 'loss': tensor(139.0983, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 127, 'accumulate_reward': 1920, 'max_number': 64, 'loss': tensor(101.7726, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 131, 'accumulate_reward': 2150, 'max_number': 64, 'loss': tensor(86.2398, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1460, 'max_number': 32, 'loss': tensor(104.7555, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(110.6062, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 122, 'accumulate_reward': 1870, 'max_number': 128, 'loss': tensor(97.3352, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(154.1267, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1510, 'max_number': 64, 'loss': tensor(96.0442, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 122, 'accumulate_reward': 1960, 'max_number': 64, 'loss': tensor(136.8211, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(98.2773, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(115.2971, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 133, 'accumulate_reward': 2090, 'max_number': 128, 'loss': tensor(157.4806, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(129.7650, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1650, 'max_number': 32, 'loss': tensor(104.7324, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(125.4111, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1820, 'max_number': 32, 'loss': tensor(128.7360, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(103.9930, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 122, 'accumulate_reward': 2000, 'max_number': 128, 'loss': tensor(143.7509, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(90.6510, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 163, 'accumulate_reward': 2150, 'max_number': 128, 'loss': tensor(98.5733, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1770, 'max_number': 64, 'loss': tensor(133.0365, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 164, 'accumulate_reward': 2530, 'max_number': 128, 'loss': tensor(80.5470, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1640, 'max_number': 64, 'loss': tensor(84.8767, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1700, 'max_number': 64, 'loss': tensor(87.4557, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(91.3620, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1520, 'max_number': 32, 'loss': tensor(98.9556, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 118, 'accumulate_reward': 1930, 'max_number': 64, 'loss': tensor(111.3286, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(81.6233, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 2120, 'max_number': 64, 'loss': tensor(107.0987, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(91.2771, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(106.6346, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1860, 'max_number': 64, 'loss': tensor(141.9732, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 85, 'accumulate_reward': 1580, 'max_number': 32, 'loss': tensor(115.6983, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 75, 'accumulate_reward': 1610, 'max_number': 32, 'loss': tensor(139.8570, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 1980, 'max_number': 128, 'loss': tensor(107.8151, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(170.1081, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 2200, 'max_number': 128, 'loss': tensor(153.7678, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 43, 'accumulate_reward': 1200, 'max_number': 16, 'loss': tensor(132.8844, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 2060, 'max_number': 128, 'loss': tensor(94.7889, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 166, 'accumulate_reward': 2320, 'max_number': 128, 'loss': tensor(144.9834, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(162.5428, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1970, 'max_number': 128, 'loss': tensor(101.6157, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 150, 'accumulate_reward': 1940, 'max_number': 64, 'loss': tensor(192.2459, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 84, 'accumulate_reward': 1550, 'max_number': 32, 'loss': tensor(86.6127, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 75, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(142.3254, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(128.7535, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1700, 'max_number': 64, 'loss': tensor(106.4099, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1720, 'max_number': 32, 'loss': tensor(146.4373, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(129.7204, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 127, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(129.0859, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 61, 'accumulate_reward': 1470, 'max_number': 16, 'loss': tensor(127.7645, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(123.0412, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1570, 'max_number': 64, 'loss': tensor(138.2388, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1900, 'max_number': 64, 'loss': tensor(121.8196, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1510, 'max_number': 32, 'loss': tensor(116.1577, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1690, 'max_number': 128, 'loss': tensor(128.0641, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 2000, 'max_number': 128, 'loss': tensor(127.4522, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 165, 'accumulate_reward': 2060, 'max_number': 128, 'loss': tensor(104.3035, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(84.4393, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(129.2597, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 62, 'accumulate_reward': 1550, 'max_number': 64, 'loss': tensor(118.0964, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(84.3435, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1900, 'max_number': 64, 'loss': tensor(108.4050, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 196, 'accumulate_reward': 2190, 'max_number': 128, 'loss': tensor(80.9742, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(59.6724, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 65, 'accumulate_reward': 1430, 'max_number': 32, 'loss': tensor(142.3458, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 171, 'accumulate_reward': 1890, 'max_number': 128, 'loss': tensor(115.9639, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 186, 'accumulate_reward': 2060, 'max_number': 128, 'loss': tensor(105.0054, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 155, 'accumulate_reward': 2280, 'max_number': 64, 'loss': tensor(112.4240, grad_fn=<MseLossBackward0>)}\n",
      "400 1815.6\n",
      "{'rounds': 154, 'accumulate_reward': 2360, 'max_number': 64, 'loss': tensor(92.2527, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 71, 'accumulate_reward': 1350, 'max_number': 32, 'loss': tensor(138.0160, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(102.6524, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 65, 'accumulate_reward': 1370, 'max_number': 32, 'loss': tensor(125.0002, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1600, 'max_number': 32, 'loss': tensor(92.9307, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 63, 'accumulate_reward': 1300, 'max_number': 32, 'loss': tensor(147.8955, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1630, 'max_number': 32, 'loss': tensor(99.5373, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 67, 'accumulate_reward': 1380, 'max_number': 32, 'loss': tensor(110.4723, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1710, 'max_number': 32, 'loss': tensor(136.5668, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 123, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(133.6126, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(105.0688, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 90, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(93.8792, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(90.3523, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1570, 'max_number': 32, 'loss': tensor(114.8886, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 2030, 'max_number': 64, 'loss': tensor(123.1093, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(99.7215, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(112.8244, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1410, 'max_number': 32, 'loss': tensor(129.7230, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1440, 'max_number': 32, 'loss': tensor(156.0985, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 47, 'accumulate_reward': 1140, 'max_number': 16, 'loss': tensor(126.4667, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 122, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(121.1563, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 159, 'accumulate_reward': 1920, 'max_number': 128, 'loss': tensor(147.3307, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 58, 'accumulate_reward': 1390, 'max_number': 16, 'loss': tensor(127.9142, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1620, 'max_number': 32, 'loss': tensor(146.4764, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 118, 'accumulate_reward': 1930, 'max_number': 128, 'loss': tensor(139.1014, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 134, 'accumulate_reward': 1890, 'max_number': 128, 'loss': tensor(126.6804, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 188, 'accumulate_reward': 1980, 'max_number': 128, 'loss': tensor(128.3688, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 119, 'accumulate_reward': 1880, 'max_number': 64, 'loss': tensor(83.2816, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 183, 'accumulate_reward': 2010, 'max_number': 128, 'loss': tensor(162.4199, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(96.2040, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(104.0917, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 1860, 'max_number': 64, 'loss': tensor(120.9592, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(90.7255, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1600, 'max_number': 32, 'loss': tensor(129.8112, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1680, 'max_number': 32, 'loss': tensor(98.7432, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(105.9432, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 185, 'accumulate_reward': 2510, 'max_number': 128, 'loss': tensor(113.5536, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 138, 'accumulate_reward': 2160, 'max_number': 128, 'loss': tensor(146.6689, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1350, 'max_number': 32, 'loss': tensor(101.7397, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(122.9559, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(92.8171, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 69, 'accumulate_reward': 1590, 'max_number': 32, 'loss': tensor(127.0314, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 136, 'accumulate_reward': 1990, 'max_number': 128, 'loss': tensor(84.8274, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1600, 'max_number': 32, 'loss': tensor(100.1409, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 1790, 'max_number': 64, 'loss': tensor(155.4147, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(118.6243, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 263, 'accumulate_reward': 2650, 'max_number': 256, 'loss': tensor(117.8576, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1580, 'max_number': 32, 'loss': tensor(130.7751, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1850, 'max_number': 64, 'loss': tensor(91.0196, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 1820, 'max_number': 128, 'loss': tensor(127.4946, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(102.9920, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 138, 'accumulate_reward': 2170, 'max_number': 128, 'loss': tensor(94.5419, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 60, 'accumulate_reward': 1310, 'max_number': 32, 'loss': tensor(89.3122, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1550, 'max_number': 32, 'loss': tensor(102.7352, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1760, 'max_number': 32, 'loss': tensor(99.9025, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 142, 'accumulate_reward': 2220, 'max_number': 64, 'loss': tensor(108.1286, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 69, 'accumulate_reward': 1550, 'max_number': 32, 'loss': tensor(59.3159, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 2200, 'max_number': 64, 'loss': tensor(126.4874, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 1770, 'max_number': 128, 'loss': tensor(88.1409, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 117, 'accumulate_reward': 2050, 'max_number': 64, 'loss': tensor(143.3202, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(131.5352, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 2000, 'max_number': 64, 'loss': tensor(131.3063, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(97.8767, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1620, 'max_number': 64, 'loss': tensor(113.9678, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 67, 'accumulate_reward': 1390, 'max_number': 32, 'loss': tensor(83.4636, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 149, 'accumulate_reward': 2220, 'max_number': 128, 'loss': tensor(103.3909, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 150, 'accumulate_reward': 1920, 'max_number': 128, 'loss': tensor(97.3037, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 2070, 'max_number': 64, 'loss': tensor(123.9724, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 170, 'accumulate_reward': 2330, 'max_number': 128, 'loss': tensor(97.5499, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1610, 'max_number': 32, 'loss': tensor(126.3224, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(93.4186, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 93, 'accumulate_reward': 1510, 'max_number': 64, 'loss': tensor(154.0578, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 129, 'accumulate_reward': 1980, 'max_number': 128, 'loss': tensor(118.8618, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1520, 'max_number': 64, 'loss': tensor(82.1195, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1560, 'max_number': 32, 'loss': tensor(145.7836, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1250, 'max_number': 32, 'loss': tensor(93.7202, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 186, 'accumulate_reward': 2410, 'max_number': 256, 'loss': tensor(111.9785, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 52, 'accumulate_reward': 1280, 'max_number': 16, 'loss': tensor(113.4198, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1620, 'max_number': 64, 'loss': tensor(140.7058, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(153.8412, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1550, 'max_number': 32, 'loss': tensor(98.8076, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1680, 'max_number': 32, 'loss': tensor(135.8921, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1420, 'max_number': 32, 'loss': tensor(137.1915, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 126, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(122.5375, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1560, 'max_number': 64, 'loss': tensor(103.5661, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1520, 'max_number': 32, 'loss': tensor(167.6582, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 107, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(144.6579, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 134, 'accumulate_reward': 1960, 'max_number': 64, 'loss': tensor(61.3556, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(104.4673, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 69, 'accumulate_reward': 1640, 'max_number': 32, 'loss': tensor(98.0221, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 52, 'accumulate_reward': 1300, 'max_number': 16, 'loss': tensor(128.1029, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 1910, 'max_number': 128, 'loss': tensor(133.3075, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(151.4810, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1640, 'max_number': 32, 'loss': tensor(148.1408, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 53, 'accumulate_reward': 1090, 'max_number': 32, 'loss': tensor(136.8583, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1510, 'max_number': 64, 'loss': tensor(114.5503, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1480, 'max_number': 32, 'loss': tensor(75.8175, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1640, 'max_number': 64, 'loss': tensor(204.0686, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 133, 'accumulate_reward': 2020, 'max_number': 64, 'loss': tensor(159.3316, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(141.6617, grad_fn=<MseLossBackward0>)}\n",
      "500 1729.5\n",
      "{'rounds': 97, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(109.6262, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1980, 'max_number': 64, 'loss': tensor(122.3235, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1810, 'max_number': 64, 'loss': tensor(78.2412, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 118, 'accumulate_reward': 1970, 'max_number': 128, 'loss': tensor(126.5180, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 2270, 'max_number': 64, 'loss': tensor(135.1961, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1480, 'max_number': 64, 'loss': tensor(99.6779, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1870, 'max_number': 64, 'loss': tensor(150.4197, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1660, 'max_number': 32, 'loss': tensor(170.7267, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1590, 'max_number': 32, 'loss': tensor(156.4583, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 75, 'accumulate_reward': 1430, 'max_number': 32, 'loss': tensor(117.0943, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1510, 'max_number': 32, 'loss': tensor(112.6082, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 66, 'accumulate_reward': 1330, 'max_number': 32, 'loss': tensor(117.8722, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 117, 'accumulate_reward': 2160, 'max_number': 128, 'loss': tensor(124.9033, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1550, 'max_number': 64, 'loss': tensor(140.1160, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 152, 'accumulate_reward': 2000, 'max_number': 128, 'loss': tensor(146.2932, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1650, 'max_number': 32, 'loss': tensor(187.4195, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(130.5053, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 59, 'accumulate_reward': 1220, 'max_number': 32, 'loss': tensor(82.8724, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1540, 'max_number': 64, 'loss': tensor(83.5629, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1470, 'max_number': 32, 'loss': tensor(121.5459, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1560, 'max_number': 32, 'loss': tensor(137.4367, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(89.8463, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(97.2743, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 85, 'accumulate_reward': 1630, 'max_number': 32, 'loss': tensor(115.7600, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 75, 'accumulate_reward': 1600, 'max_number': 32, 'loss': tensor(114.9602, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 130, 'accumulate_reward': 2130, 'max_number': 64, 'loss': tensor(127.0168, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 2040, 'max_number': 64, 'loss': tensor(78.3489, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 131, 'accumulate_reward': 2090, 'max_number': 64, 'loss': tensor(157.0641, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 62, 'accumulate_reward': 1560, 'max_number': 16, 'loss': tensor(118.9011, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 122, 'accumulate_reward': 1950, 'max_number': 64, 'loss': tensor(96.0300, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 1770, 'max_number': 64, 'loss': tensor(113.5522, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 71, 'accumulate_reward': 1470, 'max_number': 32, 'loss': tensor(97.0713, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1510, 'max_number': 32, 'loss': tensor(140.7626, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 137, 'accumulate_reward': 1980, 'max_number': 64, 'loss': tensor(125.8883, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 170, 'accumulate_reward': 2570, 'max_number': 256, 'loss': tensor(124.0594, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1940, 'max_number': 64, 'loss': tensor(118.1255, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 1930, 'max_number': 128, 'loss': tensor(136.9013, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 60, 'accumulate_reward': 1390, 'max_number': 32, 'loss': tensor(128.5273, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 64, 'accumulate_reward': 1510, 'max_number': 32, 'loss': tensor(111.7284, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 1700, 'max_number': 64, 'loss': tensor(124.1092, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 165, 'accumulate_reward': 2300, 'max_number': 128, 'loss': tensor(117.0644, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(163.7201, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 133, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(105.9426, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1700, 'max_number': 64, 'loss': tensor(134.8043, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 128, 'accumulate_reward': 1970, 'max_number': 128, 'loss': tensor(103.5532, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(119.5334, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 90, 'accumulate_reward': 1870, 'max_number': 32, 'loss': tensor(94.7181, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 151, 'accumulate_reward': 2380, 'max_number': 128, 'loss': tensor(141.4893, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1610, 'max_number': 32, 'loss': tensor(109.7139, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 2020, 'max_number': 64, 'loss': tensor(166.6968, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1850, 'max_number': 128, 'loss': tensor(109.4627, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(119.5620, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 144, 'accumulate_reward': 1900, 'max_number': 128, 'loss': tensor(102.9797, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 139, 'accumulate_reward': 2080, 'max_number': 128, 'loss': tensor(112.5782, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 189, 'accumulate_reward': 2270, 'max_number': 256, 'loss': tensor(138.0278, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 152, 'accumulate_reward': 2060, 'max_number': 128, 'loss': tensor(115.0110, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 2070, 'max_number': 64, 'loss': tensor(115.4457, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(105.5562, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 136, 'accumulate_reward': 1980, 'max_number': 128, 'loss': tensor(133.7500, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 90, 'accumulate_reward': 1730, 'max_number': 32, 'loss': tensor(183.7157, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1810, 'max_number': 32, 'loss': tensor(181.6877, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 148, 'accumulate_reward': 1940, 'max_number': 128, 'loss': tensor(103.8361, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 180, 'accumulate_reward': 2470, 'max_number': 128, 'loss': tensor(156.2210, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1770, 'max_number': 64, 'loss': tensor(138.7000, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(168.8327, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 76, 'accumulate_reward': 1380, 'max_number': 32, 'loss': tensor(160.8642, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 2120, 'max_number': 64, 'loss': tensor(158.0533, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 136, 'accumulate_reward': 2090, 'max_number': 128, 'loss': tensor(113.4705, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1520, 'max_number': 32, 'loss': tensor(144.0390, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 157, 'accumulate_reward': 1950, 'max_number': 128, 'loss': tensor(124.8065, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 122, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(136.5074, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 175, 'accumulate_reward': 2300, 'max_number': 128, 'loss': tensor(150.2492, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1520, 'max_number': 32, 'loss': tensor(118.6193, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 71, 'accumulate_reward': 1550, 'max_number': 32, 'loss': tensor(117.2801, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 65, 'accumulate_reward': 1210, 'max_number': 32, 'loss': tensor(134.4543, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(126.8847, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1640, 'max_number': 32, 'loss': tensor(109.2624, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1850, 'max_number': 64, 'loss': tensor(145.4949, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(145.2899, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(120.9559, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1790, 'max_number': 64, 'loss': tensor(158.3143, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 1880, 'max_number': 64, 'loss': tensor(118.9571, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 138, 'accumulate_reward': 2180, 'max_number': 64, 'loss': tensor(164.6767, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(146.8538, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(134.9588, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 119, 'accumulate_reward': 2210, 'max_number': 64, 'loss': tensor(140.8247, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1550, 'max_number': 32, 'loss': tensor(126.6688, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 126, 'accumulate_reward': 1990, 'max_number': 128, 'loss': tensor(86.6067, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1260, 'max_number': 32, 'loss': tensor(97.9921, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(103.4498, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 1850, 'max_number': 128, 'loss': tensor(116.3118, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 119, 'accumulate_reward': 1980, 'max_number': 64, 'loss': tensor(104.1521, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1620, 'max_number': 64, 'loss': tensor(124.6781, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 148, 'accumulate_reward': 2060, 'max_number': 64, 'loss': tensor(127.4709, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(161.8337, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(124.7159, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 85, 'accumulate_reward': 1620, 'max_number': 32, 'loss': tensor(133.5535, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(119.7372, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1790, 'max_number': 64, 'loss': tensor(76.9974, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 56, 'accumulate_reward': 1340, 'max_number': 16, 'loss': tensor(143.1956, grad_fn=<MseLossBackward0>)}\n",
      "600 1797.4\n",
      "{'rounds': 65, 'accumulate_reward': 1400, 'max_number': 32, 'loss': tensor(147.2802, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1660, 'max_number': 32, 'loss': tensor(121.3780, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(107.3923, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(116.3015, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 140, 'accumulate_reward': 2290, 'max_number': 64, 'loss': tensor(106.7874, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 2050, 'max_number': 64, 'loss': tensor(139.7019, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 134, 'accumulate_reward': 1960, 'max_number': 64, 'loss': tensor(128.7846, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 237, 'accumulate_reward': 2360, 'max_number': 256, 'loss': tensor(112.4377, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 84, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(93.9608, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(128.1589, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1680, 'max_number': 32, 'loss': tensor(102.6865, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(128.9492, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 177, 'accumulate_reward': 2020, 'max_number': 128, 'loss': tensor(113.9168, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 2160, 'max_number': 128, 'loss': tensor(187.4547, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 155, 'accumulate_reward': 2110, 'max_number': 128, 'loss': tensor(134.1324, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 142, 'accumulate_reward': 2090, 'max_number': 64, 'loss': tensor(107.5101, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1510, 'max_number': 32, 'loss': tensor(122.8812, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 181, 'accumulate_reward': 2260, 'max_number': 128, 'loss': tensor(162.9542, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1310, 'max_number': 32, 'loss': tensor(122.0117, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 59, 'accumulate_reward': 1360, 'max_number': 32, 'loss': tensor(147.0770, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1570, 'max_number': 32, 'loss': tensor(141.5971, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 150, 'accumulate_reward': 2150, 'max_number': 128, 'loss': tensor(85.5170, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 67, 'accumulate_reward': 1480, 'max_number': 32, 'loss': tensor(106.4282, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(109.4791, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 192, 'accumulate_reward': 2410, 'max_number': 128, 'loss': tensor(125.1099, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 118, 'accumulate_reward': 1900, 'max_number': 64, 'loss': tensor(94.5222, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(104.6528, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(129.3090, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1640, 'max_number': 64, 'loss': tensor(99.8165, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 57, 'accumulate_reward': 1400, 'max_number': 32, 'loss': tensor(175.3491, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1810, 'max_number': 64, 'loss': tensor(116.6698, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1740, 'max_number': 128, 'loss': tensor(104.2311, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1550, 'max_number': 64, 'loss': tensor(134.6788, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 140, 'accumulate_reward': 1960, 'max_number': 128, 'loss': tensor(108.7133, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 138, 'accumulate_reward': 2120, 'max_number': 64, 'loss': tensor(106.9712, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(121.0489, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1910, 'max_number': 64, 'loss': tensor(100.4092, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 144, 'accumulate_reward': 2050, 'max_number': 64, 'loss': tensor(80.2109, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(75.8484, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(113.9067, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 190, 'accumulate_reward': 2200, 'max_number': 128, 'loss': tensor(120.1773, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(118.5060, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(167.7422, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(109.7719, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 154, 'accumulate_reward': 2120, 'max_number': 128, 'loss': tensor(122.0335, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(99.3619, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1440, 'max_number': 32, 'loss': tensor(95.6008, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(104.5345, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1570, 'max_number': 64, 'loss': tensor(86.8117, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 123, 'accumulate_reward': 1900, 'max_number': 64, 'loss': tensor(88.5660, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 84, 'accumulate_reward': 1430, 'max_number': 64, 'loss': tensor(130.8374, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 154, 'accumulate_reward': 1930, 'max_number': 128, 'loss': tensor(117.9410, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 118, 'accumulate_reward': 1790, 'max_number': 64, 'loss': tensor(168.1696, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 131, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(120.2002, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1790, 'max_number': 64, 'loss': tensor(146.6980, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1770, 'max_number': 64, 'loss': tensor(149.8200, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(111.9150, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 164, 'accumulate_reward': 2310, 'max_number': 128, 'loss': tensor(110.6552, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(105.1061, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1440, 'max_number': 32, 'loss': tensor(173.2895, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(111.6438, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1740, 'max_number': 32, 'loss': tensor(113.1741, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(109.1512, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 1990, 'max_number': 128, 'loss': tensor(116.3285, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(96.9292, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(154.2560, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 128, 'accumulate_reward': 1810, 'max_number': 128, 'loss': tensor(135.0640, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 188, 'accumulate_reward': 2030, 'max_number': 128, 'loss': tensor(115.6733, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 155, 'accumulate_reward': 2360, 'max_number': 128, 'loss': tensor(108.8291, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 93, 'accumulate_reward': 1410, 'max_number': 64, 'loss': tensor(119.1242, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 131, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(100.9119, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 135, 'accumulate_reward': 2180, 'max_number': 128, 'loss': tensor(95.2952, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(155.5819, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(120.2271, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 150, 'accumulate_reward': 2100, 'max_number': 128, 'loss': tensor(89.3945, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 180, 'accumulate_reward': 2340, 'max_number': 128, 'loss': tensor(120.4559, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1760, 'max_number': 128, 'loss': tensor(132.7368, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(128.1117, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1700, 'max_number': 64, 'loss': tensor(95.0421, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1880, 'max_number': 64, 'loss': tensor(124.4249, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1570, 'max_number': 64, 'loss': tensor(80.9273, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 118, 'accumulate_reward': 1800, 'max_number': 128, 'loss': tensor(127.5016, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1460, 'max_number': 32, 'loss': tensor(120.1891, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1880, 'max_number': 64, 'loss': tensor(119.4756, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 55, 'accumulate_reward': 1220, 'max_number': 32, 'loss': tensor(132.9751, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 1960, 'max_number': 64, 'loss': tensor(138.6464, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 69, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(107.9274, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1670, 'max_number': 32, 'loss': tensor(110.2594, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(118.5285, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(127.5215, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(145.7541, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 176, 'accumulate_reward': 2620, 'max_number': 128, 'loss': tensor(123.2932, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(134.1153, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1890, 'max_number': 64, 'loss': tensor(68.9335, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1620, 'max_number': 64, 'loss': tensor(97.7400, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 247, 'accumulate_reward': 2760, 'max_number': 256, 'loss': tensor(117.8094, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 129, 'accumulate_reward': 2050, 'max_number': 128, 'loss': tensor(103.6398, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(162.3399, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1460, 'max_number': 32, 'loss': tensor(174.3453, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 2140, 'max_number': 128, 'loss': tensor(86.1977, grad_fn=<MseLossBackward0>)}\n",
      "700 1813.6\n",
      "{'rounds': 130, 'accumulate_reward': 2160, 'max_number': 128, 'loss': tensor(73.4541, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 106, 'accumulate_reward': 1970, 'max_number': 64, 'loss': tensor(120.3430, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 122, 'accumulate_reward': 1850, 'max_number': 64, 'loss': tensor(138.2319, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1570, 'max_number': 64, 'loss': tensor(136.7314, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 183, 'accumulate_reward': 2430, 'max_number': 128, 'loss': tensor(70.2120, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1670, 'max_number': 32, 'loss': tensor(105.6486, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 118, 'accumulate_reward': 2080, 'max_number': 64, 'loss': tensor(109.0530, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(93.6355, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(105.5080, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 61, 'accumulate_reward': 1510, 'max_number': 32, 'loss': tensor(160.8487, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1700, 'max_number': 64, 'loss': tensor(98.1169, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1510, 'max_number': 64, 'loss': tensor(80.6877, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(156.5371, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(131.7436, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 161, 'accumulate_reward': 2380, 'max_number': 128, 'loss': tensor(57.7750, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1440, 'max_number': 32, 'loss': tensor(102.4232, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(108.4908, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 2050, 'max_number': 64, 'loss': tensor(164.5388, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 119, 'accumulate_reward': 1950, 'max_number': 64, 'loss': tensor(119.0721, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(121.2003, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 2000, 'max_number': 64, 'loss': tensor(104.7315, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 174, 'accumulate_reward': 2290, 'max_number': 128, 'loss': tensor(98.0633, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1570, 'max_number': 64, 'loss': tensor(128.2938, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 144, 'accumulate_reward': 1910, 'max_number': 128, 'loss': tensor(91.4632, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 85, 'accumulate_reward': 1380, 'max_number': 32, 'loss': tensor(103.5276, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 167, 'accumulate_reward': 2360, 'max_number': 64, 'loss': tensor(89.7280, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1750, 'max_number': 32, 'loss': tensor(108.6801, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(112.5170, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1600, 'max_number': 32, 'loss': tensor(167.3659, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 90, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(104.5273, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 71, 'accumulate_reward': 1650, 'max_number': 32, 'loss': tensor(118.1963, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 139, 'accumulate_reward': 2080, 'max_number': 64, 'loss': tensor(93.1014, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 127, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(97.9884, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(168.9384, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1940, 'max_number': 64, 'loss': tensor(105.6259, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 167, 'accumulate_reward': 2140, 'max_number': 64, 'loss': tensor(109.1601, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 2040, 'max_number': 64, 'loss': tensor(94.0309, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1640, 'max_number': 32, 'loss': tensor(129.0435, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 75, 'accumulate_reward': 1350, 'max_number': 32, 'loss': tensor(85.0012, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 62, 'accumulate_reward': 1360, 'max_number': 32, 'loss': tensor(179.6479, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(118.1078, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1900, 'max_number': 64, 'loss': tensor(108.7809, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 1810, 'max_number': 64, 'loss': tensor(114.6256, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 2100, 'max_number': 64, 'loss': tensor(71.1645, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 63, 'accumulate_reward': 1230, 'max_number': 32, 'loss': tensor(109.9953, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 117, 'accumulate_reward': 2090, 'max_number': 64, 'loss': tensor(133.7060, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 134, 'accumulate_reward': 2270, 'max_number': 64, 'loss': tensor(96.2030, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 134, 'accumulate_reward': 2130, 'max_number': 128, 'loss': tensor(135.3725, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 141, 'accumulate_reward': 2100, 'max_number': 64, 'loss': tensor(104.6679, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 127, 'accumulate_reward': 2110, 'max_number': 128, 'loss': tensor(115.1868, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 70, 'accumulate_reward': 1290, 'max_number': 32, 'loss': tensor(124.1015, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 188, 'accumulate_reward': 2510, 'max_number': 128, 'loss': tensor(75.6860, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 85, 'accumulate_reward': 1530, 'max_number': 64, 'loss': tensor(114.4797, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 155, 'accumulate_reward': 2040, 'max_number': 128, 'loss': tensor(71.2114, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 159, 'accumulate_reward': 2130, 'max_number': 128, 'loss': tensor(93.0845, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1370, 'max_number': 64, 'loss': tensor(117.1360, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 2040, 'max_number': 128, 'loss': tensor(125.3778, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 173, 'accumulate_reward': 2030, 'max_number': 128, 'loss': tensor(86.0922, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1510, 'max_number': 32, 'loss': tensor(184.5984, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 127, 'accumulate_reward': 2180, 'max_number': 64, 'loss': tensor(139.5364, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 135, 'accumulate_reward': 2010, 'max_number': 128, 'loss': tensor(134.0677, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 1980, 'max_number': 128, 'loss': tensor(147.8935, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 109, 'accumulate_reward': 2010, 'max_number': 64, 'loss': tensor(107.3738, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1870, 'max_number': 128, 'loss': tensor(131.2218, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 105, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(89.8395, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 99, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(153.4746, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 75, 'accumulate_reward': 1500, 'max_number': 64, 'loss': tensor(118.3691, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(98.7503, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 69, 'accumulate_reward': 1530, 'max_number': 32, 'loss': tensor(116.4951, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1630, 'max_number': 32, 'loss': tensor(108.4122, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1460, 'max_number': 32, 'loss': tensor(154.4198, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1650, 'max_number': 32, 'loss': tensor(114.0372, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 60, 'accumulate_reward': 1350, 'max_number': 16, 'loss': tensor(93.7854, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 76, 'accumulate_reward': 1340, 'max_number': 32, 'loss': tensor(126.2992, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1410, 'max_number': 64, 'loss': tensor(109.3325, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(155.6683, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1510, 'max_number': 32, 'loss': tensor(113.9259, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(123.1723, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 137, 'accumulate_reward': 1840, 'max_number': 128, 'loss': tensor(160.9249, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 85, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(105.9585, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1880, 'max_number': 64, 'loss': tensor(89.5680, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 146, 'accumulate_reward': 2090, 'max_number': 128, 'loss': tensor(135.5281, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 163, 'accumulate_reward': 2210, 'max_number': 128, 'loss': tensor(100.7036, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1500, 'max_number': 32, 'loss': tensor(115.7934, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(83.2273, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 135, 'accumulate_reward': 1960, 'max_number': 128, 'loss': tensor(119.5571, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 69, 'accumulate_reward': 1310, 'max_number': 32, 'loss': tensor(153.0845, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(64.3361, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1640, 'max_number': 64, 'loss': tensor(98.2162, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1810, 'max_number': 64, 'loss': tensor(99.5073, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 79, 'accumulate_reward': 1790, 'max_number': 32, 'loss': tensor(145.4758, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 117, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(134.3617, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 133, 'accumulate_reward': 2260, 'max_number': 128, 'loss': tensor(97.0671, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 123, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(114.6581, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 128, 'accumulate_reward': 1870, 'max_number': 128, 'loss': tensor(93.7299, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(149.1087, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 156, 'accumulate_reward': 2060, 'max_number': 128, 'loss': tensor(109.3361, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 121, 'accumulate_reward': 1760, 'max_number': 128, 'loss': tensor(114.4360, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(116.6146, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1510, 'max_number': 64, 'loss': tensor(110.3259, grad_fn=<MseLossBackward0>)}\n",
      "800 1796.6\n",
      "{'rounds': 105, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(149.3791, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 166, 'accumulate_reward': 1970, 'max_number': 128, 'loss': tensor(168.7888, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(101.7055, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 120, 'accumulate_reward': 1880, 'max_number': 128, 'loss': tensor(98.9013, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(89.4619, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 159, 'accumulate_reward': 2020, 'max_number': 128, 'loss': tensor(116.2822, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1970, 'max_number': 128, 'loss': tensor(119.0333, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 154, 'accumulate_reward': 2120, 'max_number': 64, 'loss': tensor(120.9110, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1790, 'max_number': 32, 'loss': tensor(110.5383, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1960, 'max_number': 64, 'loss': tensor(194.5961, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 1640, 'max_number': 64, 'loss': tensor(200.5213, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 119, 'accumulate_reward': 1940, 'max_number': 128, 'loss': tensor(78.5567, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 2290, 'max_number': 128, 'loss': tensor(120.6259, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 107, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(120.8151, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 85, 'accumulate_reward': 1730, 'max_number': 32, 'loss': tensor(113.1017, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 96, 'accumulate_reward': 1950, 'max_number': 32, 'loss': tensor(125.0959, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 131, 'accumulate_reward': 2030, 'max_number': 128, 'loss': tensor(57.5393, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 123, 'accumulate_reward': 1970, 'max_number': 64, 'loss': tensor(127.0736, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1540, 'max_number': 32, 'loss': tensor(147.6794, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 155, 'accumulate_reward': 2160, 'max_number': 128, 'loss': tensor(103.4361, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 60, 'accumulate_reward': 1190, 'max_number': 32, 'loss': tensor(97.6051, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1520, 'max_number': 64, 'loss': tensor(108.2134, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 122, 'accumulate_reward': 2060, 'max_number': 64, 'loss': tensor(90.0897, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(116.2774, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1490, 'max_number': 64, 'loss': tensor(114.7217, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 142, 'accumulate_reward': 1960, 'max_number': 64, 'loss': tensor(109.0411, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 141, 'accumulate_reward': 2150, 'max_number': 128, 'loss': tensor(89.0544, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1480, 'max_number': 32, 'loss': tensor(123.3550, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 146, 'accumulate_reward': 1920, 'max_number': 128, 'loss': tensor(119.1009, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 129, 'accumulate_reward': 2150, 'max_number': 64, 'loss': tensor(112.7479, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(114.2160, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1540, 'max_number': 64, 'loss': tensor(83.0075, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1630, 'max_number': 32, 'loss': tensor(135.7051, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1880, 'max_number': 64, 'loss': tensor(92.0679, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 75, 'accumulate_reward': 1690, 'max_number': 64, 'loss': tensor(141.1132, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1250, 'max_number': 32, 'loss': tensor(126.2360, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1580, 'max_number': 32, 'loss': tensor(112.6752, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1600, 'max_number': 32, 'loss': tensor(143.8163, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 84, 'accumulate_reward': 1490, 'max_number': 64, 'loss': tensor(98.9558, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 105, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(91.4315, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(116.3605, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 134, 'accumulate_reward': 1860, 'max_number': 128, 'loss': tensor(82.5434, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1760, 'max_number': 32, 'loss': tensor(127.7281, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 2110, 'max_number': 128, 'loss': tensor(145.5925, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 101, 'accumulate_reward': 1870, 'max_number': 64, 'loss': tensor(131.6102, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 133, 'accumulate_reward': 2290, 'max_number': 128, 'loss': tensor(144.6992, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 76, 'accumulate_reward': 1340, 'max_number': 32, 'loss': tensor(159.1806, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1600, 'max_number': 32, 'loss': tensor(88.6050, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 157, 'accumulate_reward': 2290, 'max_number': 128, 'loss': tensor(164.5221, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 2590, 'max_number': 32, 'loss': tensor(136.5933, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 84, 'accumulate_reward': 1630, 'max_number': 32, 'loss': tensor(134.1336, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 137, 'accumulate_reward': 2240, 'max_number': 128, 'loss': tensor(116.5146, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(82.9443, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 158, 'accumulate_reward': 2000, 'max_number': 128, 'loss': tensor(105.2233, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 2050, 'max_number': 64, 'loss': tensor(146.9564, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 126, 'accumulate_reward': 2030, 'max_number': 128, 'loss': tensor(119.9323, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1840, 'max_number': 32, 'loss': tensor(123.7914, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 129, 'accumulate_reward': 2080, 'max_number': 64, 'loss': tensor(114.3012, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 76, 'accumulate_reward': 1520, 'max_number': 32, 'loss': tensor(128.1420, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1480, 'max_number': 32, 'loss': tensor(125.0323, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 131, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(102.1669, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 123, 'accumulate_reward': 1960, 'max_number': 64, 'loss': tensor(168.7939, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 135, 'accumulate_reward': 2080, 'max_number': 64, 'loss': tensor(139.4200, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 70, 'accumulate_reward': 1400, 'max_number': 32, 'loss': tensor(116.5615, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(146.8734, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(127.5602, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1580, 'max_number': 32, 'loss': tensor(116.3680, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(105.6980, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 2130, 'max_number': 128, 'loss': tensor(159.1258, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 156, 'accumulate_reward': 2210, 'max_number': 64, 'loss': tensor(124.4229, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1440, 'max_number': 32, 'loss': tensor(115.5778, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 82, 'accumulate_reward': 1570, 'max_number': 32, 'loss': tensor(151.2621, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 172, 'accumulate_reward': 2370, 'max_number': 128, 'loss': tensor(139.0939, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 156, 'accumulate_reward': 2140, 'max_number': 128, 'loss': tensor(102.4226, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1730, 'max_number': 64, 'loss': tensor(87.8291, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 127, 'accumulate_reward': 1680, 'max_number': 128, 'loss': tensor(102.1257, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(124.1481, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(93.5701, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 93, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(101.2708, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1520, 'max_number': 64, 'loss': tensor(133.6180, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1390, 'max_number': 32, 'loss': tensor(107.4908, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 158, 'accumulate_reward': 2100, 'max_number': 128, 'loss': tensor(117.5384, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1560, 'max_number': 64, 'loss': tensor(130.8278, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1580, 'max_number': 64, 'loss': tensor(117.1541, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1940, 'max_number': 64, 'loss': tensor(136.9292, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 156, 'accumulate_reward': 2050, 'max_number': 128, 'loss': tensor(73.4984, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 177, 'accumulate_reward': 2280, 'max_number': 128, 'loss': tensor(127.3385, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 153, 'accumulate_reward': 2080, 'max_number': 128, 'loss': tensor(113.5324, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 1970, 'max_number': 64, 'loss': tensor(95.0982, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 167, 'accumulate_reward': 2330, 'max_number': 128, 'loss': tensor(110.3998, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 125, 'accumulate_reward': 1650, 'max_number': 128, 'loss': tensor(105.5805, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1460, 'max_number': 32, 'loss': tensor(87.9920, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 159, 'accumulate_reward': 2140, 'max_number': 128, 'loss': tensor(125.2491, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1630, 'max_number': 64, 'loss': tensor(131.5115, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 144, 'accumulate_reward': 2170, 'max_number': 128, 'loss': tensor(132.7092, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 2260, 'max_number': 128, 'loss': tensor(190.7068, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 92, 'accumulate_reward': 1600, 'max_number': 64, 'loss': tensor(166.1285, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 134, 'accumulate_reward': 1940, 'max_number': 128, 'loss': tensor(130.3413, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 116, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(88.6099, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 208, 'accumulate_reward': 2410, 'max_number': 256, 'loss': tensor(111.4990, grad_fn=<MseLossBackward0>)}\n",
      "900 1840.6\n",
      "{'rounds': 106, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(87.8202, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 153, 'accumulate_reward': 2050, 'max_number': 128, 'loss': tensor(122.3695, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 116, 'accumulate_reward': 1840, 'max_number': 64, 'loss': tensor(136.1467, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 100, 'accumulate_reward': 1560, 'max_number': 64, 'loss': tensor(150.9070, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 153, 'accumulate_reward': 1980, 'max_number': 128, 'loss': tensor(122.4010, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 81, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(77.0152, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1270, 'max_number': 32, 'loss': tensor(124.4859, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1770, 'max_number': 32, 'loss': tensor(105.8086, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 55, 'accumulate_reward': 1130, 'max_number': 32, 'loss': tensor(129.9140, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 85, 'accumulate_reward': 1610, 'max_number': 64, 'loss': tensor(81.1428, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1480, 'max_number': 32, 'loss': tensor(141.1505, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(111.6302, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 129, 'accumulate_reward': 1780, 'max_number': 64, 'loss': tensor(132.0008, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 98, 'accumulate_reward': 1940, 'max_number': 64, 'loss': tensor(127.4640, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(111.5112, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1350, 'max_number': 32, 'loss': tensor(97.2615, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1530, 'max_number': 32, 'loss': tensor(134.9480, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1420, 'max_number': 32, 'loss': tensor(134.5350, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 223, 'accumulate_reward': 2330, 'max_number': 256, 'loss': tensor(82.7652, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 91, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(104.3098, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 70, 'accumulate_reward': 1390, 'max_number': 32, 'loss': tensor(142.4351, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1690, 'max_number': 32, 'loss': tensor(129.3299, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 74, 'accumulate_reward': 1550, 'max_number': 32, 'loss': tensor(107.0676, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 115, 'accumulate_reward': 1700, 'max_number': 64, 'loss': tensor(113.7701, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 135, 'accumulate_reward': 2000, 'max_number': 128, 'loss': tensor(167.8813, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 83, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(118.4688, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 41, 'accumulate_reward': 1120, 'max_number': 16, 'loss': tensor(94.0891, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 123, 'accumulate_reward': 2060, 'max_number': 128, 'loss': tensor(118.6635, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 163, 'accumulate_reward': 2370, 'max_number': 128, 'loss': tensor(101.6620, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 104, 'accumulate_reward': 1820, 'max_number': 64, 'loss': tensor(101.9309, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 134, 'accumulate_reward': 1930, 'max_number': 64, 'loss': tensor(74.0301, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 110, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(119.3103, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1170, 'max_number': 32, 'loss': tensor(96.9484, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 118, 'accumulate_reward': 1760, 'max_number': 128, 'loss': tensor(221.9638, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(134.4160, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 140, 'accumulate_reward': 2130, 'max_number': 128, 'loss': tensor(162.8762, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 116, 'accumulate_reward': 1960, 'max_number': 64, 'loss': tensor(95.8432, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1360, 'max_number': 32, 'loss': tensor(116.4106, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 111, 'accumulate_reward': 1970, 'max_number': 128, 'loss': tensor(115.7166, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1800, 'max_number': 64, 'loss': tensor(98.4506, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 131, 'accumulate_reward': 1970, 'max_number': 64, 'loss': tensor(158.6551, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1860, 'max_number': 64, 'loss': tensor(113.4853, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1390, 'max_number': 32, 'loss': tensor(106.7394, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 62, 'accumulate_reward': 1430, 'max_number': 32, 'loss': tensor(130.7808, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1970, 'max_number': 64, 'loss': tensor(131.2963, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 145, 'accumulate_reward': 1910, 'max_number': 128, 'loss': tensor(140.9560, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 108, 'accumulate_reward': 1670, 'max_number': 64, 'loss': tensor(91.2421, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1540, 'max_number': 64, 'loss': tensor(104.0585, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 116, 'accumulate_reward': 1920, 'max_number': 64, 'loss': tensor(106.6654, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 76, 'accumulate_reward': 1450, 'max_number': 32, 'loss': tensor(134.3466, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1650, 'max_number': 64, 'loss': tensor(132.0473, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 54, 'accumulate_reward': 1220, 'max_number': 16, 'loss': tensor(128.1415, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 129, 'accumulate_reward': 1910, 'max_number': 128, 'loss': tensor(124.4134, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 102, 'accumulate_reward': 1680, 'max_number': 64, 'loss': tensor(61.2773, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1540, 'max_number': 32, 'loss': tensor(122.9605, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(119.0776, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 166, 'accumulate_reward': 2120, 'max_number': 128, 'loss': tensor(147.0926, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 1660, 'max_number': 64, 'loss': tensor(137.0838, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 72, 'accumulate_reward': 1430, 'max_number': 32, 'loss': tensor(150.5907, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 86, 'accumulate_reward': 1530, 'max_number': 64, 'loss': tensor(143.7388, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 184, 'accumulate_reward': 2570, 'max_number': 128, 'loss': tensor(102.2971, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1600, 'max_number': 32, 'loss': tensor(117.5532, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 71, 'accumulate_reward': 1420, 'max_number': 32, 'loss': tensor(74.8515, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1750, 'max_number': 64, 'loss': tensor(124.1678, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1650, 'max_number': 32, 'loss': tensor(109.2315, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 126, 'accumulate_reward': 1950, 'max_number': 64, 'loss': tensor(139.5106, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 94, 'accumulate_reward': 1830, 'max_number': 64, 'loss': tensor(149.7474, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1440, 'max_number': 32, 'loss': tensor(98.6021, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 95, 'accumulate_reward': 1980, 'max_number': 64, 'loss': tensor(154.0972, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 56, 'accumulate_reward': 1430, 'max_number': 32, 'loss': tensor(138.3882, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 87, 'accumulate_reward': 1660, 'max_number': 32, 'loss': tensor(90.7918, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1590, 'max_number': 32, 'loss': tensor(114.6702, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 63, 'accumulate_reward': 1400, 'max_number': 32, 'loss': tensor(102.7857, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 105, 'accumulate_reward': 1930, 'max_number': 64, 'loss': tensor(96.0253, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 112, 'accumulate_reward': 1720, 'max_number': 64, 'loss': tensor(101.0509, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 67, 'accumulate_reward': 1510, 'max_number': 32, 'loss': tensor(103.9971, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 124, 'accumulate_reward': 2010, 'max_number': 64, 'loss': tensor(156.7853, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1620, 'max_number': 32, 'loss': tensor(118.0712, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 178, 'accumulate_reward': 2120, 'max_number': 128, 'loss': tensor(93.5375, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 73, 'accumulate_reward': 1450, 'max_number': 32, 'loss': tensor(118.8843, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 1790, 'max_number': 64, 'loss': tensor(113.4349, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 103, 'accumulate_reward': 1590, 'max_number': 64, 'loss': tensor(134.2329, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 123, 'accumulate_reward': 2040, 'max_number': 128, 'loss': tensor(147.1319, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1710, 'max_number': 64, 'loss': tensor(172.9615, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 132, 'accumulate_reward': 1790, 'max_number': 64, 'loss': tensor(161.5120, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 59, 'accumulate_reward': 1200, 'max_number': 32, 'loss': tensor(96.9759, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 77, 'accumulate_reward': 1470, 'max_number': 64, 'loss': tensor(125.1335, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 114, 'accumulate_reward': 1810, 'max_number': 64, 'loss': tensor(112.4986, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 80, 'accumulate_reward': 1630, 'max_number': 32, 'loss': tensor(136.3447, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 89, 'accumulate_reward': 1640, 'max_number': 32, 'loss': tensor(137.3491, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 174, 'accumulate_reward': 2460, 'max_number': 128, 'loss': tensor(98.7298, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 137, 'accumulate_reward': 2110, 'max_number': 128, 'loss': tensor(137.1775, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 78, 'accumulate_reward': 1630, 'max_number': 32, 'loss': tensor(130.2323, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1760, 'max_number': 64, 'loss': tensor(125.2400, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 97, 'accumulate_reward': 1550, 'max_number': 64, 'loss': tensor(119.6810, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 68, 'accumulate_reward': 1500, 'max_number': 32, 'loss': tensor(100.2141, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 88, 'accumulate_reward': 1770, 'max_number': 32, 'loss': tensor(98.7519, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 70, 'accumulate_reward': 1490, 'max_number': 32, 'loss': tensor(83.7771, grad_fn=<MseLossBackward0>)}\n",
      "{'rounds': 113, 'accumulate_reward': 1740, 'max_number': 64, 'loss': tensor(114.8030, grad_fn=<MseLossBackward0>)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1460,\n",
       "  1060,\n",
       "  2180,\n",
       "  1970,\n",
       "  1770,\n",
       "  1430,\n",
       "  1500,\n",
       "  1890,\n",
       "  1410,\n",
       "  2020,\n",
       "  2020,\n",
       "  2030,\n",
       "  1900,\n",
       "  2090,\n",
       "  2040,\n",
       "  1960,\n",
       "  1600,\n",
       "  1890,\n",
       "  2150,\n",
       "  1610,\n",
       "  2070,\n",
       "  1490,\n",
       "  1880,\n",
       "  1560,\n",
       "  1720,\n",
       "  2000,\n",
       "  1840,\n",
       "  1500,\n",
       "  1220,\n",
       "  1550,\n",
       "  1740,\n",
       "  1530,\n",
       "  2020,\n",
       "  1590,\n",
       "  1450,\n",
       "  1810,\n",
       "  1680,\n",
       "  1790,\n",
       "  1290,\n",
       "  1940,\n",
       "  1990,\n",
       "  1360,\n",
       "  2050,\n",
       "  1540,\n",
       "  1510,\n",
       "  1910,\n",
       "  2420,\n",
       "  1900,\n",
       "  1630,\n",
       "  2150,\n",
       "  1680,\n",
       "  2160,\n",
       "  1640,\n",
       "  1790,\n",
       "  1350,\n",
       "  1650,\n",
       "  1700,\n",
       "  1880,\n",
       "  1650,\n",
       "  2300,\n",
       "  2120,\n",
       "  2190,\n",
       "  1760,\n",
       "  1730,\n",
       "  1910,\n",
       "  1950,\n",
       "  1250,\n",
       "  1840,\n",
       "  2310,\n",
       "  1530,\n",
       "  1900,\n",
       "  1580,\n",
       "  1530,\n",
       "  2210,\n",
       "  2040,\n",
       "  2190,\n",
       "  1200,\n",
       "  1900,\n",
       "  1370,\n",
       "  1550,\n",
       "  1740,\n",
       "  1640,\n",
       "  1360,\n",
       "  2320,\n",
       "  1430,\n",
       "  1250,\n",
       "  1670,\n",
       "  1600,\n",
       "  1670,\n",
       "  1340,\n",
       "  1720,\n",
       "  1670,\n",
       "  1620,\n",
       "  1940,\n",
       "  1770,\n",
       "  1860,\n",
       "  2290,\n",
       "  1170,\n",
       "  1690,\n",
       "  1730,\n",
       "  1700,\n",
       "  1500,\n",
       "  2020,\n",
       "  1960,\n",
       "  2080,\n",
       "  2030,\n",
       "  1980,\n",
       "  1390,\n",
       "  1870,\n",
       "  1490,\n",
       "  2120,\n",
       "  1790,\n",
       "  1390,\n",
       "  1890,\n",
       "  1490,\n",
       "  1820,\n",
       "  1650,\n",
       "  1860,\n",
       "  1100,\n",
       "  1470,\n",
       "  1280,\n",
       "  1520,\n",
       "  1780,\n",
       "  1770,\n",
       "  1780,\n",
       "  1760,\n",
       "  2120,\n",
       "  2420,\n",
       "  1590,\n",
       "  1760,\n",
       "  1820,\n",
       "  1690,\n",
       "  1580,\n",
       "  1460,\n",
       "  1770,\n",
       "  1480,\n",
       "  1380,\n",
       "  1860,\n",
       "  1470,\n",
       "  1500,\n",
       "  1890,\n",
       "  1680,\n",
       "  1710,\n",
       "  1660,\n",
       "  1910,\n",
       "  1890,\n",
       "  1580,\n",
       "  1540,\n",
       "  2070,\n",
       "  1390,\n",
       "  1590,\n",
       "  1410,\n",
       "  1710,\n",
       "  2050,\n",
       "  1360,\n",
       "  1580,\n",
       "  1670,\n",
       "  1830,\n",
       "  1950,\n",
       "  1750,\n",
       "  1430,\n",
       "  2070,\n",
       "  2210,\n",
       "  1810,\n",
       "  1430,\n",
       "  1740,\n",
       "  1890,\n",
       "  1230,\n",
       "  1320,\n",
       "  1270,\n",
       "  1420,\n",
       "  1550,\n",
       "  1620,\n",
       "  1350,\n",
       "  1620,\n",
       "  1740,\n",
       "  1750,\n",
       "  1480,\n",
       "  2120,\n",
       "  1380,\n",
       "  1660,\n",
       "  1500,\n",
       "  1220,\n",
       "  1680,\n",
       "  1870,\n",
       "  1660,\n",
       "  1830,\n",
       "  2040,\n",
       "  1500,\n",
       "  2160,\n",
       "  2010,\n",
       "  1810,\n",
       "  2060,\n",
       "  1760,\n",
       "  1890,\n",
       "  1570,\n",
       "  1860,\n",
       "  2050,\n",
       "  1510,\n",
       "  2160,\n",
       "  1260,\n",
       "  1870,\n",
       "  1860,\n",
       "  1820,\n",
       "  2080,\n",
       "  2090,\n",
       "  1970,\n",
       "  2370,\n",
       "  1670,\n",
       "  2170,\n",
       "  1520,\n",
       "  1470,\n",
       "  1440,\n",
       "  1730,\n",
       "  1840,\n",
       "  1600,\n",
       "  1500,\n",
       "  1750,\n",
       "  2480,\n",
       "  1740,\n",
       "  1920,\n",
       "  2110,\n",
       "  1710,\n",
       "  1870,\n",
       "  1950,\n",
       "  1750,\n",
       "  2270,\n",
       "  1870,\n",
       "  2040,\n",
       "  1810,\n",
       "  1580,\n",
       "  1350,\n",
       "  1810,\n",
       "  1920,\n",
       "  1910,\n",
       "  1740,\n",
       "  1600,\n",
       "  1950,\n",
       "  1810,\n",
       "  1630,\n",
       "  1760,\n",
       "  2350,\n",
       "  1470,\n",
       "  1530,\n",
       "  1340,\n",
       "  1680,\n",
       "  1750,\n",
       "  1770,\n",
       "  1700,\n",
       "  2120,\n",
       "  1510,\n",
       "  1800,\n",
       "  2050,\n",
       "  1760,\n",
       "  1780,\n",
       "  1430,\n",
       "  2170,\n",
       "  1260,\n",
       "  1640,\n",
       "  1800,\n",
       "  1760,\n",
       "  1900,\n",
       "  1780,\n",
       "  1830,\n",
       "  1810,\n",
       "  1330,\n",
       "  1740,\n",
       "  1900,\n",
       "  1880,\n",
       "  1920,\n",
       "  1730,\n",
       "  1930,\n",
       "  2070,\n",
       "  1550,\n",
       "  2270,\n",
       "  1170,\n",
       "  1730,\n",
       "  1780,\n",
       "  1170,\n",
       "  1560,\n",
       "  1590,\n",
       "  1690,\n",
       "  2190,\n",
       "  1610,\n",
       "  1580,\n",
       "  2080,\n",
       "  1940,\n",
       "  1650,\n",
       "  2070,\n",
       "  1110,\n",
       "  2580,\n",
       "  1560,\n",
       "  1830,\n",
       "  1220,\n",
       "  2000,\n",
       "  2110,\n",
       "  1900,\n",
       "  2080,\n",
       "  1960,\n",
       "  1990,\n",
       "  1840,\n",
       "  1780,\n",
       "  2270,\n",
       "  1720,\n",
       "  1950,\n",
       "  1640,\n",
       "  1720,\n",
       "  1560,\n",
       "  1370,\n",
       "  2070,\n",
       "  1690,\n",
       "  2110,\n",
       "  1870,\n",
       "  1290,\n",
       "  1650,\n",
       "  1520,\n",
       "  2250,\n",
       "  2130,\n",
       "  1580,\n",
       "  1710,\n",
       "  2120,\n",
       "  1780,\n",
       "  2050,\n",
       "  1920,\n",
       "  1980,\n",
       "  2000,\n",
       "  2070,\n",
       "  1380,\n",
       "  2020,\n",
       "  1680,\n",
       "  1950,\n",
       "  1450,\n",
       "  2150,\n",
       "  1920,\n",
       "  2150,\n",
       "  1460,\n",
       "  1660,\n",
       "  1870,\n",
       "  1690,\n",
       "  1510,\n",
       "  1960,\n",
       "  1720,\n",
       "  1890,\n",
       "  2090,\n",
       "  1590,\n",
       "  1650,\n",
       "  1780,\n",
       "  1820,\n",
       "  1840,\n",
       "  2000,\n",
       "  1660,\n",
       "  2150,\n",
       "  1770,\n",
       "  2530,\n",
       "  1640,\n",
       "  1700,\n",
       "  1840,\n",
       "  1520,\n",
       "  1930,\n",
       "  1820,\n",
       "  2120,\n",
       "  1740,\n",
       "  1740,\n",
       "  1860,\n",
       "  1580,\n",
       "  1610,\n",
       "  1980,\n",
       "  1740,\n",
       "  2200,\n",
       "  1200,\n",
       "  2060,\n",
       "  2320,\n",
       "  1670,\n",
       "  1970,\n",
       "  1940,\n",
       "  1550,\n",
       "  1690,\n",
       "  1740,\n",
       "  1700,\n",
       "  1720,\n",
       "  1780,\n",
       "  1690,\n",
       "  1470,\n",
       "  1780,\n",
       "  1570,\n",
       "  1900,\n",
       "  1510,\n",
       "  1690,\n",
       "  2000,\n",
       "  2060,\n",
       "  1800,\n",
       "  1760,\n",
       "  1550,\n",
       "  1840,\n",
       "  1900,\n",
       "  2190,\n",
       "  1690,\n",
       "  1430,\n",
       "  1890,\n",
       "  2060,\n",
       "  2280,\n",
       "  2360,\n",
       "  1350,\n",
       "  1710,\n",
       "  1370,\n",
       "  1600,\n",
       "  1300,\n",
       "  1630,\n",
       "  1380,\n",
       "  1710,\n",
       "  1820,\n",
       "  1840,\n",
       "  1720,\n",
       "  1690,\n",
       "  1570,\n",
       "  2030,\n",
       "  1680,\n",
       "  1840,\n",
       "  1410,\n",
       "  1440,\n",
       "  1140,\n",
       "  1680,\n",
       "  1920,\n",
       "  1390,\n",
       "  1620,\n",
       "  1930,\n",
       "  1890,\n",
       "  1980,\n",
       "  1880,\n",
       "  2010,\n",
       "  1680,\n",
       "  1830,\n",
       "  1860,\n",
       "  1720,\n",
       "  1600,\n",
       "  1680,\n",
       "  1580,\n",
       "  2510,\n",
       "  2160,\n",
       "  1350,\n",
       "  1740,\n",
       "  1730,\n",
       "  1590,\n",
       "  1990,\n",
       "  1600,\n",
       "  1790,\n",
       "  1760,\n",
       "  2650,\n",
       "  1580,\n",
       "  1850,\n",
       "  1820,\n",
       "  1690,\n",
       "  2170,\n",
       "  1310,\n",
       "  1550,\n",
       "  1760,\n",
       "  2220,\n",
       "  1550,\n",
       "  2200,\n",
       "  1770,\n",
       "  2050,\n",
       "  1760,\n",
       "  2000,\n",
       "  1590,\n",
       "  1620,\n",
       "  1390,\n",
       "  2220,\n",
       "  1920,\n",
       "  2070,\n",
       "  2330,\n",
       "  1610,\n",
       "  1820,\n",
       "  1510,\n",
       "  1980,\n",
       "  1520,\n",
       "  1560,\n",
       "  1250,\n",
       "  2410,\n",
       "  1280,\n",
       "  1620,\n",
       "  1710,\n",
       "  1550,\n",
       "  1680,\n",
       "  1420,\n",
       "  1840,\n",
       "  1560,\n",
       "  1520,\n",
       "  1830,\n",
       "  1960,\n",
       "  1680,\n",
       "  1640,\n",
       "  1300,\n",
       "  1910,\n",
       "  1690,\n",
       "  1640,\n",
       "  1090,\n",
       "  1510,\n",
       "  1480,\n",
       "  1640,\n",
       "  2020,\n",
       "  1590,\n",
       "  1830,\n",
       "  1980,\n",
       "  1810,\n",
       "  1970,\n",
       "  2270,\n",
       "  1480,\n",
       "  1870,\n",
       "  1660,\n",
       "  1590,\n",
       "  1430,\n",
       "  1510,\n",
       "  1330,\n",
       "  2160,\n",
       "  1550,\n",
       "  2000,\n",
       "  1650,\n",
       "  1780,\n",
       "  1220,\n",
       "  1540,\n",
       "  1470,\n",
       "  1560,\n",
       "  1800,\n",
       "  1650,\n",
       "  1630,\n",
       "  1600,\n",
       "  2130,\n",
       "  2040,\n",
       "  2090,\n",
       "  1560,\n",
       "  1950,\n",
       "  1770,\n",
       "  1470,\n",
       "  1510,\n",
       "  1980,\n",
       "  2570,\n",
       "  1940,\n",
       "  1930,\n",
       "  1390,\n",
       "  1510,\n",
       "  1700,\n",
       "  2300,\n",
       "  1730,\n",
       "  1890,\n",
       "  1700,\n",
       "  1970,\n",
       "  1730,\n",
       "  1870,\n",
       "  2380,\n",
       "  1610,\n",
       "  2020,\n",
       "  1850,\n",
       "  1740,\n",
       "  1900,\n",
       "  2080,\n",
       "  2270,\n",
       "  2060,\n",
       "  2070,\n",
       "  1890,\n",
       "  1980,\n",
       "  1730,\n",
       "  1810,\n",
       "  1940,\n",
       "  2470,\n",
       "  1770,\n",
       "  1590,\n",
       "  1380,\n",
       "  2120,\n",
       "  2090,\n",
       "  1520,\n",
       "  1950,\n",
       "  1760,\n",
       "  2300,\n",
       "  1520,\n",
       "  1550,\n",
       "  1210,\n",
       "  1690,\n",
       "  1640,\n",
       "  1850,\n",
       "  1740,\n",
       "  1650,\n",
       "  1790,\n",
       "  1880,\n",
       "  2180,\n",
       "  1750,\n",
       "  1830,\n",
       "  2210,\n",
       "  1550,\n",
       "  1990,\n",
       "  1260,\n",
       "  1740,\n",
       "  1850,\n",
       "  1980,\n",
       "  1620,\n",
       "  2060,\n",
       "  1610,\n",
       "  1760,\n",
       "  1620,\n",
       "  1730,\n",
       "  1790,\n",
       "  1340,\n",
       "  1400,\n",
       "  1660,\n",
       "  1710,\n",
       "  1610,\n",
       "  2290,\n",
       "  2050,\n",
       "  1960,\n",
       "  2360,\n",
       "  1650,\n",
       "  1670,\n",
       "  1680,\n",
       "  1890,\n",
       "  2020,\n",
       "  2160,\n",
       "  2110,\n",
       "  2090,\n",
       "  1510,\n",
       "  2260,\n",
       "  1310,\n",
       "  1360,\n",
       "  1570,\n",
       "  2150,\n",
       "  1480,\n",
       "  1670,\n",
       "  2410,\n",
       "  1900,\n",
       "  1750,\n",
       "  1690,\n",
       "  1640,\n",
       "  1400,\n",
       "  1810,\n",
       "  1740,\n",
       "  1550,\n",
       "  1960,\n",
       "  2120,\n",
       "  1720,\n",
       "  1910,\n",
       "  2050,\n",
       "  1690,\n",
       "  1610,\n",
       "  2200,\n",
       "  1780,\n",
       "  1750,\n",
       "  1590,\n",
       "  2120,\n",
       "  1660,\n",
       "  1440,\n",
       "  1660,\n",
       "  1570,\n",
       "  1900,\n",
       "  1430,\n",
       "  1930,\n",
       "  1790,\n",
       "  1730,\n",
       "  1790,\n",
       "  1770,\n",
       "  1840,\n",
       "  2310,\n",
       "  1710,\n",
       "  1440,\n",
       "  1720,\n",
       "  1740,\n",
       "  1750,\n",
       "  1990,\n",
       "  1610,\n",
       "  1840,\n",
       "  1810,\n",
       "  2030,\n",
       "  2360,\n",
       "  1410,\n",
       "  1750,\n",
       "  2180,\n",
       "  1800,\n",
       "  1780,\n",
       "  2100,\n",
       "  2340,\n",
       "  1760,\n",
       "  1670,\n",
       "  1700,\n",
       "  1880,\n",
       "  1570,\n",
       "  1800,\n",
       "  1460,\n",
       "  1880,\n",
       "  1220,\n",
       "  1960,\n",
       "  1690,\n",
       "  1670,\n",
       "  1680,\n",
       "  1670,\n",
       "  1610,\n",
       "  2620,\n",
       "  1690,\n",
       "  1890,\n",
       "  1620,\n",
       "  2760,\n",
       "  2050,\n",
       "  1720,\n",
       "  1460,\n",
       "  2140,\n",
       "  2160,\n",
       "  1970,\n",
       "  1850,\n",
       "  1570,\n",
       "  2430,\n",
       "  1670,\n",
       "  2080,\n",
       "  1800,\n",
       "  1660,\n",
       "  1510,\n",
       "  1700,\n",
       "  1510,\n",
       "  1710,\n",
       "  1660,\n",
       "  2380,\n",
       "  1440,\n",
       "  1690,\n",
       "  2050,\n",
       "  1950,\n",
       "  1720,\n",
       "  2000,\n",
       "  2290,\n",
       "  1570,\n",
       "  1910,\n",
       "  1380,\n",
       "  2360,\n",
       "  1750,\n",
       "  1720,\n",
       "  1600,\n",
       "  1680,\n",
       "  1650,\n",
       "  2080,\n",
       "  1840,\n",
       "  1750,\n",
       "  1940,\n",
       "  2140,\n",
       "  2040,\n",
       "  1640,\n",
       "  1350,\n",
       "  1360,\n",
       "  1650,\n",
       "  1900,\n",
       "  1810,\n",
       "  2100,\n",
       "  1230,\n",
       "  2090,\n",
       "  2270,\n",
       "  2130,\n",
       "  2100,\n",
       "  2110,\n",
       "  1290,\n",
       "  2510,\n",
       "  1530,\n",
       "  2040,\n",
       "  2130,\n",
       "  1370,\n",
       "  2040,\n",
       "  2030,\n",
       "  1510,\n",
       "  2180,\n",
       "  2010,\n",
       "  1980,\n",
       "  2010,\n",
       "  1870,\n",
       "  1610,\n",
       "  1690,\n",
       "  1500,\n",
       "  1690,\n",
       "  1530,\n",
       "  1630,\n",
       "  1460,\n",
       "  1650,\n",
       "  1350,\n",
       "  1340,\n",
       "  1410,\n",
       "  1580,\n",
       "  1510,\n",
       "  1830,\n",
       "  1840,\n",
       "  1690,\n",
       "  1880,\n",
       "  2090,\n",
       "  2210,\n",
       "  1500,\n",
       "  1800,\n",
       "  1960,\n",
       "  1310,\n",
       "  1730,\n",
       "  1640,\n",
       "  1810,\n",
       "  1790,\n",
       "  1730,\n",
       "  2260,\n",
       "  1590,\n",
       "  1870,\n",
       "  1750,\n",
       "  2060,\n",
       "  1760,\n",
       "  1650,\n",
       "  1510,\n",
       "  1820,\n",
       "  1970,\n",
       "  1580,\n",
       "  1880,\n",
       "  1830,\n",
       "  2020,\n",
       "  1970,\n",
       "  2120,\n",
       "  1790,\n",
       "  1960,\n",
       "  1640,\n",
       "  1940,\n",
       "  2290,\n",
       "  1820,\n",
       "  1730,\n",
       "  1950,\n",
       "  2030,\n",
       "  1970,\n",
       "  1540,\n",
       "  2160,\n",
       "  1190,\n",
       "  1520,\n",
       "  2060,\n",
       "  1710,\n",
       "  1490,\n",
       "  1960,\n",
       "  2150,\n",
       "  1480,\n",
       "  1920,\n",
       "  2150,\n",
       "  1760,\n",
       "  1540,\n",
       "  1630,\n",
       "  1880,\n",
       "  1690,\n",
       "  1250,\n",
       "  1580,\n",
       "  1600,\n",
       "  1490,\n",
       "  1750,\n",
       "  1610,\n",
       "  1860,\n",
       "  1760,\n",
       "  2110,\n",
       "  1870,\n",
       "  2290,\n",
       "  1340,\n",
       "  1600,\n",
       "  2290,\n",
       "  2590,\n",
       "  1630,\n",
       "  2240,\n",
       "  1740,\n",
       "  2000,\n",
       "  2050,\n",
       "  2030,\n",
       "  1840,\n",
       "  2080,\n",
       "  1520,\n",
       "  1480,\n",
       "  1820,\n",
       "  1960,\n",
       "  2080,\n",
       "  1400,\n",
       "  1680,\n",
       "  1800,\n",
       "  1580,\n",
       "  1800,\n",
       "  2130,\n",
       "  2210,\n",
       "  1440,\n",
       "  1570,\n",
       "  2370,\n",
       "  2140,\n",
       "  1730,\n",
       "  1680,\n",
       "  1740,\n",
       "  1610,\n",
       "  1800,\n",
       "  1520,\n",
       "  1390,\n",
       "  2100,\n",
       "  1560,\n",
       "  1580,\n",
       "  1940,\n",
       "  2050,\n",
       "  2280,\n",
       "  2080,\n",
       "  1970,\n",
       "  2330,\n",
       "  1650,\n",
       "  1460,\n",
       "  2140,\n",
       "  1630,\n",
       "  2170,\n",
       "  2260,\n",
       "  1600,\n",
       "  1940,\n",
       "  1720,\n",
       "  2410,\n",
       "  1710,\n",
       "  2050,\n",
       "  1840,\n",
       "  1560,\n",
       "  1980,\n",
       "  1670,\n",
       "  1270,\n",
       "  1770,\n",
       "  1130,\n",
       "  1610,\n",
       "  1480,\n",
       "  1800,\n",
       "  1780,\n",
       "  1940,\n",
       "  1820,\n",
       "  1350,\n",
       "  1530,\n",
       "  1420,\n",
       "  2330,\n",
       "  1690,\n",
       "  1390,\n",
       "  1690,\n",
       "  1550,\n",
       "  1700,\n",
       "  2000,\n",
       "  1650,\n",
       "  1120,\n",
       "  2060,\n",
       "  2370,\n",
       "  1820,\n",
       "  1930,\n",
       "  1740,\n",
       "  1170,\n",
       "  1760,\n",
       "  1760,\n",
       "  2130,\n",
       "  1960,\n",
       "  1360,\n",
       "  1970,\n",
       "  1800,\n",
       "  1970,\n",
       "  1860,\n",
       "  1390,\n",
       "  1430,\n",
       "  1970,\n",
       "  1910,\n",
       "  1670,\n",
       "  1540,\n",
       "  1920,\n",
       "  1450,\n",
       "  1650,\n",
       "  1220,\n",
       "  1910,\n",
       "  1680,\n",
       "  1540,\n",
       "  1750,\n",
       "  2120,\n",
       "  1660,\n",
       "  1430,\n",
       "  1530,\n",
       "  2570,\n",
       "  1600,\n",
       "  1420,\n",
       "  1750,\n",
       "  1650,\n",
       "  1950,\n",
       "  1830,\n",
       "  1440,\n",
       "  1980,\n",
       "  1430,\n",
       "  1660,\n",
       "  1590,\n",
       "  1400,\n",
       "  1930,\n",
       "  1720,\n",
       "  1510,\n",
       "  2010,\n",
       "  1620,\n",
       "  2120,\n",
       "  1450,\n",
       "  1790,\n",
       "  1590,\n",
       "  2040,\n",
       "  1710,\n",
       "  1790,\n",
       "  1200,\n",
       "  1470,\n",
       "  1810,\n",
       "  1630,\n",
       "  1640,\n",
       "  2460,\n",
       "  2110,\n",
       "  1630,\n",
       "  1760,\n",
       "  1550,\n",
       "  1500,\n",
       "  1770,\n",
       "  1490,\n",
       "  1740],\n",
       " [75,\n",
       "  57,\n",
       "  168,\n",
       "  145,\n",
       "  126,\n",
       "  92,\n",
       "  80,\n",
       "  115,\n",
       "  95,\n",
       "  159,\n",
       "  144,\n",
       "  132,\n",
       "  133,\n",
       "  158,\n",
       "  150,\n",
       "  145,\n",
       "  101,\n",
       "  134,\n",
       "  154,\n",
       "  108,\n",
       "  176,\n",
       "  97,\n",
       "  114,\n",
       "  121,\n",
       "  104,\n",
       "  150,\n",
       "  108,\n",
       "  92,\n",
       "  73,\n",
       "  96,\n",
       "  153,\n",
       "  102,\n",
       "  146,\n",
       "  99,\n",
       "  101,\n",
       "  113,\n",
       "  107,\n",
       "  113,\n",
       "  80,\n",
       "  132,\n",
       "  137,\n",
       "  78,\n",
       "  178,\n",
       "  92,\n",
       "  94,\n",
       "  120,\n",
       "  153,\n",
       "  151,\n",
       "  112,\n",
       "  139,\n",
       "  119,\n",
       "  149,\n",
       "  102,\n",
       "  120,\n",
       "  85,\n",
       "  113,\n",
       "  114,\n",
       "  124,\n",
       "  82,\n",
       "  203,\n",
       "  155,\n",
       "  144,\n",
       "  107,\n",
       "  137,\n",
       "  131,\n",
       "  124,\n",
       "  68,\n",
       "  124,\n",
       "  148,\n",
       "  84,\n",
       "  149,\n",
       "  106,\n",
       "  82,\n",
       "  169,\n",
       "  168,\n",
       "  166,\n",
       "  57,\n",
       "  156,\n",
       "  65,\n",
       "  72,\n",
       "  113,\n",
       "  106,\n",
       "  69,\n",
       "  156,\n",
       "  66,\n",
       "  70,\n",
       "  114,\n",
       "  93,\n",
       "  82,\n",
       "  65,\n",
       "  80,\n",
       "  93,\n",
       "  73,\n",
       "  133,\n",
       "  89,\n",
       "  113,\n",
       "  175,\n",
       "  55,\n",
       "  101,\n",
       "  129,\n",
       "  108,\n",
       "  60,\n",
       "  106,\n",
       "  135,\n",
       "  136,\n",
       "  144,\n",
       "  119,\n",
       "  91,\n",
       "  95,\n",
       "  86,\n",
       "  140,\n",
       "  104,\n",
       "  72,\n",
       "  112,\n",
       "  79,\n",
       "  86,\n",
       "  90,\n",
       "  80,\n",
       "  48,\n",
       "  77,\n",
       "  64,\n",
       "  59,\n",
       "  108,\n",
       "  91,\n",
       "  92,\n",
       "  106,\n",
       "  118,\n",
       "  172,\n",
       "  88,\n",
       "  107,\n",
       "  109,\n",
       "  97,\n",
       "  96,\n",
       "  76,\n",
       "  90,\n",
       "  58,\n",
       "  65,\n",
       "  94,\n",
       "  73,\n",
       "  78,\n",
       "  100,\n",
       "  114,\n",
       "  82,\n",
       "  95,\n",
       "  104,\n",
       "  117,\n",
       "  89,\n",
       "  88,\n",
       "  136,\n",
       "  65,\n",
       "  104,\n",
       "  83,\n",
       "  117,\n",
       "  129,\n",
       "  86,\n",
       "  89,\n",
       "  78,\n",
       "  96,\n",
       "  126,\n",
       "  91,\n",
       "  61,\n",
       "  165,\n",
       "  125,\n",
       "  94,\n",
       "  75,\n",
       "  102,\n",
       "  104,\n",
       "  52,\n",
       "  64,\n",
       "  51,\n",
       "  110,\n",
       "  86,\n",
       "  89,\n",
       "  68,\n",
       "  97,\n",
       "  103,\n",
       "  111,\n",
       "  76,\n",
       "  159,\n",
       "  79,\n",
       "  100,\n",
       "  80,\n",
       "  58,\n",
       "  91,\n",
       "  89,\n",
       "  111,\n",
       "  125,\n",
       "  116,\n",
       "  70,\n",
       "  142,\n",
       "  109,\n",
       "  87,\n",
       "  139,\n",
       "  104,\n",
       "  88,\n",
       "  109,\n",
       "  100,\n",
       "  98,\n",
       "  108,\n",
       "  141,\n",
       "  66,\n",
       "  112,\n",
       "  120,\n",
       "  97,\n",
       "  160,\n",
       "  132,\n",
       "  115,\n",
       "  165,\n",
       "  84,\n",
       "  133,\n",
       "  82,\n",
       "  91,\n",
       "  72,\n",
       "  89,\n",
       "  97,\n",
       "  103,\n",
       "  77,\n",
       "  101,\n",
       "  225,\n",
       "  108,\n",
       "  158,\n",
       "  162,\n",
       "  98,\n",
       "  129,\n",
       "  133,\n",
       "  100,\n",
       "  144,\n",
       "  98,\n",
       "  114,\n",
       "  90,\n",
       "  87,\n",
       "  64,\n",
       "  94,\n",
       "  155,\n",
       "  135,\n",
       "  107,\n",
       "  73,\n",
       "  116,\n",
       "  88,\n",
       "  81,\n",
       "  82,\n",
       "  174,\n",
       "  78,\n",
       "  92,\n",
       "  61,\n",
       "  95,\n",
       "  89,\n",
       "  88,\n",
       "  100,\n",
       "  137,\n",
       "  100,\n",
       "  152,\n",
       "  123,\n",
       "  124,\n",
       "  121,\n",
       "  81,\n",
       "  185,\n",
       "  64,\n",
       "  109,\n",
       "  105,\n",
       "  104,\n",
       "  112,\n",
       "  130,\n",
       "  114,\n",
       "  94,\n",
       "  68,\n",
       "  99,\n",
       "  116,\n",
       "  103,\n",
       "  130,\n",
       "  108,\n",
       "  104,\n",
       "  159,\n",
       "  92,\n",
       "  148,\n",
       "  47,\n",
       "  71,\n",
       "  92,\n",
       "  66,\n",
       "  88,\n",
       "  107,\n",
       "  90,\n",
       "  187,\n",
       "  82,\n",
       "  102,\n",
       "  125,\n",
       "  102,\n",
       "  89,\n",
       "  152,\n",
       "  40,\n",
       "  304,\n",
       "  101,\n",
       "  144,\n",
       "  60,\n",
       "  138,\n",
       "  163,\n",
       "  124,\n",
       "  172,\n",
       "  147,\n",
       "  150,\n",
       "  100,\n",
       "  97,\n",
       "  178,\n",
       "  103,\n",
       "  104,\n",
       "  88,\n",
       "  91,\n",
       "  76,\n",
       "  82,\n",
       "  128,\n",
       "  84,\n",
       "  121,\n",
       "  116,\n",
       "  69,\n",
       "  107,\n",
       "  87,\n",
       "  125,\n",
       "  112,\n",
       "  98,\n",
       "  108,\n",
       "  111,\n",
       "  76,\n",
       "  157,\n",
       "  117,\n",
       "  103,\n",
       "  109,\n",
       "  167,\n",
       "  83,\n",
       "  126,\n",
       "  89,\n",
       "  121,\n",
       "  95,\n",
       "  162,\n",
       "  127,\n",
       "  131,\n",
       "  79,\n",
       "  92,\n",
       "  122,\n",
       "  99,\n",
       "  96,\n",
       "  122,\n",
       "  108,\n",
       "  91,\n",
       "  133,\n",
       "  110,\n",
       "  78,\n",
       "  102,\n",
       "  89,\n",
       "  109,\n",
       "  122,\n",
       "  82,\n",
       "  163,\n",
       "  110,\n",
       "  164,\n",
       "  94,\n",
       "  98,\n",
       "  110,\n",
       "  74,\n",
       "  118,\n",
       "  81,\n",
       "  99,\n",
       "  97,\n",
       "  104,\n",
       "  112,\n",
       "  85,\n",
       "  75,\n",
       "  121,\n",
       "  124,\n",
       "  145,\n",
       "  43,\n",
       "  111,\n",
       "  166,\n",
       "  114,\n",
       "  124,\n",
       "  150,\n",
       "  84,\n",
       "  75,\n",
       "  113,\n",
       "  98,\n",
       "  87,\n",
       "  115,\n",
       "  127,\n",
       "  61,\n",
       "  98,\n",
       "  102,\n",
       "  99,\n",
       "  73,\n",
       "  114,\n",
       "  125,\n",
       "  165,\n",
       "  102,\n",
       "  112,\n",
       "  62,\n",
       "  106,\n",
       "  113,\n",
       "  196,\n",
       "  89,\n",
       "  65,\n",
       "  171,\n",
       "  186,\n",
       "  155,\n",
       "  154,\n",
       "  71,\n",
       "  110,\n",
       "  65,\n",
       "  82,\n",
       "  63,\n",
       "  88,\n",
       "  67,\n",
       "  88,\n",
       "  123,\n",
       "  111,\n",
       "  90,\n",
       "  91,\n",
       "  79,\n",
       "  125,\n",
       "  97,\n",
       "  96,\n",
       "  72,\n",
       "  77,\n",
       "  47,\n",
       "  122,\n",
       "  159,\n",
       "  58,\n",
       "  91,\n",
       "  118,\n",
       "  134,\n",
       "  188,\n",
       "  119,\n",
       "  183,\n",
       "  79,\n",
       "  97,\n",
       "  109,\n",
       "  101,\n",
       "  87,\n",
       "  81,\n",
       "  79,\n",
       "  185,\n",
       "  138,\n",
       "  82,\n",
       "  110,\n",
       "  113,\n",
       "  69,\n",
       "  136,\n",
       "  79,\n",
       "  121,\n",
       "  120,\n",
       "  263,\n",
       "  78,\n",
       "  110,\n",
       "  125,\n",
       "  81,\n",
       "  138,\n",
       "  60,\n",
       "  73,\n",
       "  80,\n",
       "  142,\n",
       "  69,\n",
       "  113,\n",
       "  132,\n",
       "  117,\n",
       "  96,\n",
       "  145,\n",
       "  77,\n",
       "  87,\n",
       "  67,\n",
       "  149,\n",
       "  150,\n",
       "  101,\n",
       "  170,\n",
       "  73,\n",
       "  99,\n",
       "  93,\n",
       "  129,\n",
       "  78,\n",
       "  73,\n",
       "  72,\n",
       "  186,\n",
       "  52,\n",
       "  68,\n",
       "  98,\n",
       "  83,\n",
       "  81,\n",
       "  72,\n",
       "  126,\n",
       "  95,\n",
       "  80,\n",
       "  107,\n",
       "  134,\n",
       "  83,\n",
       "  69,\n",
       "  52,\n",
       "  132,\n",
       "  95,\n",
       "  88,\n",
       "  53,\n",
       "  82,\n",
       "  78,\n",
       "  99,\n",
       "  133,\n",
       "  82,\n",
       "  97,\n",
       "  96,\n",
       "  102,\n",
       "  118,\n",
       "  120,\n",
       "  81,\n",
       "  106,\n",
       "  81,\n",
       "  89,\n",
       "  75,\n",
       "  81,\n",
       "  66,\n",
       "  117,\n",
       "  81,\n",
       "  152,\n",
       "  77,\n",
       "  113,\n",
       "  59,\n",
       "  74,\n",
       "  81,\n",
       "  80,\n",
       "  102,\n",
       "  97,\n",
       "  85,\n",
       "  75,\n",
       "  130,\n",
       "  112,\n",
       "  131,\n",
       "  62,\n",
       "  122,\n",
       "  111,\n",
       "  71,\n",
       "  73,\n",
       "  137,\n",
       "  170,\n",
       "  112,\n",
       "  145,\n",
       "  60,\n",
       "  64,\n",
       "  109,\n",
       "  165,\n",
       "  104,\n",
       "  133,\n",
       "  91,\n",
       "  128,\n",
       "  121,\n",
       "  90,\n",
       "  151,\n",
       "  87,\n",
       "  111,\n",
       "  124,\n",
       "  99,\n",
       "  144,\n",
       "  139,\n",
       "  189,\n",
       "  152,\n",
       "  145,\n",
       "  115,\n",
       "  136,\n",
       "  90,\n",
       "  100,\n",
       "  148,\n",
       "  180,\n",
       "  99,\n",
       "  104,\n",
       "  76,\n",
       "  106,\n",
       "  136,\n",
       "  79,\n",
       "  157,\n",
       "  122,\n",
       "  175,\n",
       "  79,\n",
       "  71,\n",
       "  65,\n",
       "  89,\n",
       "  80,\n",
       "  102,\n",
       "  89,\n",
       "  96,\n",
       "  104,\n",
       "  111,\n",
       "  138,\n",
       "  99,\n",
       "  120,\n",
       "  119,\n",
       "  82,\n",
       "  126,\n",
       "  74,\n",
       "  94,\n",
       "  145,\n",
       "  119,\n",
       "  89,\n",
       "  148,\n",
       "  96,\n",
       "  98,\n",
       "  85,\n",
       "  108,\n",
       "  96,\n",
       "  56,\n",
       "  65,\n",
       "  74,\n",
       "  96,\n",
       "  96,\n",
       "  140,\n",
       "  106,\n",
       "  134,\n",
       "  237,\n",
       "  84,\n",
       "  74,\n",
       "  81,\n",
       "  120,\n",
       "  177,\n",
       "  145,\n",
       "  155,\n",
       "  142,\n",
       "  82,\n",
       "  181,\n",
       "  74,\n",
       "  59,\n",
       "  78,\n",
       "  150,\n",
       "  67,\n",
       "  82,\n",
       "  192,\n",
       "  118,\n",
       "  115,\n",
       "  97,\n",
       "  101,\n",
       "  57,\n",
       "  100,\n",
       "  115,\n",
       "  73,\n",
       "  140,\n",
       "  138,\n",
       "  114,\n",
       "  106,\n",
       "  144,\n",
       "  101,\n",
       "  77,\n",
       "  190,\n",
       "  106,\n",
       "  114,\n",
       "  87,\n",
       "  154,\n",
       "  106,\n",
       "  77,\n",
       "  94,\n",
       "  89,\n",
       "  123,\n",
       "  84,\n",
       "  154,\n",
       "  118,\n",
       "  131,\n",
       "  108,\n",
       "  98,\n",
       "  92,\n",
       "  164,\n",
       "  92,\n",
       "  72,\n",
       "  98,\n",
       "  101,\n",
       "  121,\n",
       "  145,\n",
       "  112,\n",
       "  120,\n",
       "  128,\n",
       "  188,\n",
       "  155,\n",
       "  93,\n",
       "  131,\n",
       "  135,\n",
       "  102,\n",
       "  120,\n",
       "  150,\n",
       "  180,\n",
       "  115,\n",
       "  106,\n",
       "  102,\n",
       "  114,\n",
       "  97,\n",
       "  118,\n",
       "  68,\n",
       "  103,\n",
       "  55,\n",
       "  125,\n",
       "  69,\n",
       "  80,\n",
       "  104,\n",
       "  113,\n",
       "  89,\n",
       "  176,\n",
       "  81,\n",
       "  110,\n",
       "  78,\n",
       "  247,\n",
       "  129,\n",
       "  109,\n",
       "  73,\n",
       "  132,\n",
       "  130,\n",
       "  106,\n",
       "  122,\n",
       "  99,\n",
       "  183,\n",
       "  87,\n",
       "  118,\n",
       "  108,\n",
       "  99,\n",
       "  61,\n",
       "  92,\n",
       "  82,\n",
       "  111,\n",
       "  101,\n",
       "  161,\n",
       "  88,\n",
       "  89,\n",
       "  120,\n",
       "  119,\n",
       "  100,\n",
       "  102,\n",
       "  174,\n",
       "  104,\n",
       "  144,\n",
       "  85,\n",
       "  167,\n",
       "  83,\n",
       "  95,\n",
       "  89,\n",
       "  90,\n",
       "  71,\n",
       "  139,\n",
       "  127,\n",
       "  108,\n",
       "  101,\n",
       "  167,\n",
       "  112,\n",
       "  79,\n",
       "  75,\n",
       "  62,\n",
       "  99,\n",
       "  99,\n",
       "  111,\n",
       "  104,\n",
       "  63,\n",
       "  117,\n",
       "  134,\n",
       "  134,\n",
       "  141,\n",
       "  127,\n",
       "  70,\n",
       "  188,\n",
       "  85,\n",
       "  155,\n",
       "  159,\n",
       "  83,\n",
       "  115,\n",
       "  173,\n",
       "  74,\n",
       "  127,\n",
       "  135,\n",
       "  125,\n",
       "  109,\n",
       "  115,\n",
       "  105,\n",
       "  99,\n",
       "  75,\n",
       "  87,\n",
       "  69,\n",
       "  80,\n",
       "  83,\n",
       "  89,\n",
       "  60,\n",
       "  76,\n",
       "  77,\n",
       "  100,\n",
       "  73,\n",
       "  121,\n",
       "  137,\n",
       "  85,\n",
       "  115,\n",
       "  146,\n",
       "  163,\n",
       "  74,\n",
       "  103,\n",
       "  135,\n",
       "  69,\n",
       "  88,\n",
       "  91,\n",
       "  112,\n",
       "  79,\n",
       "  117,\n",
       "  133,\n",
       "  123,\n",
       "  128,\n",
       "  91,\n",
       "  156,\n",
       "  121,\n",
       "  91,\n",
       "  73,\n",
       "  105,\n",
       "  166,\n",
       "  77,\n",
       "  120,\n",
       "  110,\n",
       "  159,\n",
       "  114,\n",
       "  154,\n",
       "  88,\n",
       "  115,\n",
       "  111,\n",
       "  119,\n",
       "  132,\n",
       "  107,\n",
       "  85,\n",
       "  96,\n",
       "  131,\n",
       "  123,\n",
       "  72,\n",
       "  155,\n",
       "  60,\n",
       "  102,\n",
       "  122,\n",
       "  104,\n",
       "  91,\n",
       "  142,\n",
       "  141,\n",
       "  74,\n",
       "  146,\n",
       "  129,\n",
       "  100,\n",
       "  98,\n",
       "  81,\n",
       "  97,\n",
       "  75,\n",
       "  68,\n",
       "  74,\n",
       "  78,\n",
       "  84,\n",
       "  105,\n",
       "  89,\n",
       "  134,\n",
       "  87,\n",
       "  125,\n",
       "  101,\n",
       "  133,\n",
       "  76,\n",
       "  83,\n",
       "  157,\n",
       "  114,\n",
       "  84,\n",
       "  137,\n",
       "  125,\n",
       "  158,\n",
       "  145,\n",
       "  126,\n",
       "  78,\n",
       "  129,\n",
       "  76,\n",
       "  68,\n",
       "  131,\n",
       "  123,\n",
       "  135,\n",
       "  70,\n",
       "  124,\n",
       "  112,\n",
       "  83,\n",
       "  114,\n",
       "  132,\n",
       "  156,\n",
       "  77,\n",
       "  82,\n",
       "  172,\n",
       "  156,\n",
       "  88,\n",
       "  127,\n",
       "  91,\n",
       "  83,\n",
       "  93,\n",
       "  91,\n",
       "  80,\n",
       "  158,\n",
       "  103,\n",
       "  100,\n",
       "  124,\n",
       "  156,\n",
       "  177,\n",
       "  153,\n",
       "  125,\n",
       "  167,\n",
       "  125,\n",
       "  68,\n",
       "  159,\n",
       "  98,\n",
       "  144,\n",
       "  95,\n",
       "  92,\n",
       "  134,\n",
       "  116,\n",
       "  208,\n",
       "  106,\n",
       "  153,\n",
       "  116,\n",
       "  100,\n",
       "  153,\n",
       "  81,\n",
       "  68,\n",
       "  78,\n",
       "  55,\n",
       "  85,\n",
       "  73,\n",
       "  113,\n",
       "  129,\n",
       "  98,\n",
       "  102,\n",
       "  73,\n",
       "  74,\n",
       "  73,\n",
       "  223,\n",
       "  91,\n",
       "  70,\n",
       "  94,\n",
       "  74,\n",
       "  115,\n",
       "  135,\n",
       "  83,\n",
       "  41,\n",
       "  123,\n",
       "  163,\n",
       "  104,\n",
       "  134,\n",
       "  110,\n",
       "  72,\n",
       "  118,\n",
       "  87,\n",
       "  140,\n",
       "  116,\n",
       "  72,\n",
       "  111,\n",
       "  103,\n",
       "  131,\n",
       "  113,\n",
       "  78,\n",
       "  62,\n",
       "  97,\n",
       "  145,\n",
       "  108,\n",
       "  102,\n",
       "  116,\n",
       "  76,\n",
       "  102,\n",
       "  54,\n",
       "  129,\n",
       "  102,\n",
       "  87,\n",
       "  95,\n",
       "  166,\n",
       "  124,\n",
       "  72,\n",
       "  86,\n",
       "  184,\n",
       "  89,\n",
       "  71,\n",
       "  78,\n",
       "  89,\n",
       "  126,\n",
       "  94,\n",
       "  87,\n",
       "  95,\n",
       "  56,\n",
       "  87,\n",
       "  73,\n",
       "  63,\n",
       "  105,\n",
       "  112,\n",
       "  67,\n",
       "  124,\n",
       "  88,\n",
       "  178,\n",
       "  73,\n",
       "  132,\n",
       "  103,\n",
       "  123,\n",
       "  97,\n",
       "  132,\n",
       "  59,\n",
       "  77,\n",
       "  114,\n",
       "  80,\n",
       "  89,\n",
       "  174,\n",
       "  137,\n",
       "  78,\n",
       "  113,\n",
       "  97,\n",
       "  68,\n",
       "  88,\n",
       "  70,\n",
       "  113])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(agent, n_episodes=1000, max_time_step=1000, eps_start=1.0, eps_end=0.05, eps_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58.216633, 56.67393 , 55.787964, 56.341194], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.q_value(np.array([[0,0,2,0],[0,0,2,0],[0,0,2,0],[0,0,2,0]])).cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.act(np.array([[0,0,2,0],[0,0,2,0],[0,0,2,0],[0,0,2,0]]), eps=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f972118ac7c6a56642233e9551f2790bbdf3f6ed0ba1febcedad4f4ce41f7f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
