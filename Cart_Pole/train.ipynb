{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gym\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "from collections import deque\n",
    "from typing import Optional, Iterable\n",
    "import random\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda'if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recorder import Recorder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay_buffer import ReplayBuffer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import QNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE         = 100\n",
    "BATCH_SIZE          = 64\n",
    "GAMMA               = 0.99  # discount factor\n",
    "TAU                 = 0.05   # soft update of target parameter\n",
    "LEARNING_RATE       = 1e-2\n",
    "UPDATE_EVERY        = 10    # how often to update the local\n",
    "TARGET_UPDATE_EVERY = 50    # how often to update the target\n",
    "FRAME_LENGTH        = 3    # how long\n",
    "RESIZED_WIDTH       = 240 \n",
    "RESIZED_HEIGHT      = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Agent import Agent\n",
    "agent = Agent(FRAME_LENGTH, 2, LEARNING_RATE, BUFFER_SIZE, BATCH_SIZE, GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(3, 3))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=52992, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.qnetwork_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfelissi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\user/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\Desktop\\py-practice\\machine_learning\\codebase---machine-learning\\Cart_Pole\\wandb\\run-20230223_223252-x2bcr2tf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/felissi/cart-pole/runs/x2bcr2tf' target=\"_blank\">lively-flower-21</a></strong> to <a href='https://wandb.ai/felissi/cart-pole' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/felissi/cart-pole' target=\"_blank\">https://wandb.ai/felissi/cart-pole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/felissi/cart-pole/runs/x2bcr2tf' target=\"_blank\">https://wandb.ai/felissi/cart-pole/runs/x2bcr2tf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/felissi/cart-pole/runs/x2bcr2tf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1c8ce8cfa30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../.wandb.yaml', 'r') as f:\n",
    "    key = yaml.safe_load(f.read())['key']\n",
    "wandb.login(key=key)\n",
    "wandb.init(project=\"cart-pole\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(\n",
    "    dict(\n",
    "        BUFFER_SIZE         = BUFFER_SIZE         ,     \n",
    "        BATCH_SIZE          = BATCH_SIZE          ,\n",
    "        GAMMA               = GAMMA               ,\n",
    "        TAU                 = TAU                 ,\n",
    "        LEARNING_RATE       = LEARNING_RATE       ,\n",
    "        UPDATE_EVERY        = UPDATE_EVERY        ,\n",
    "        TARGET_UPDATE_EVERY = TARGET_UPDATE_EVERY ,\n",
    "        FRAME_LENGTH        = FRAME_LENGTH        ,\n",
    "        RESIZED_WIDTH       = RESIZED_WIDTH       ,\n",
    "        RESIZED_HEIGHT      = RESIZED_HEIGHT\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(agent.qnetwork_local, log='all', log_freq=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent: Agent, n_episodes, max_time_step, eps_start, eps_end, eps_decay):\n",
    "    scores = []\n",
    "    num_rounds = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    eps = eps_start\n",
    "    env = gym.make('CartPole-v1',render_mode='rgb_array')\n",
    "    recorder = Recorder(maxlen=FRAME_LENGTH)\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        env.reset()\n",
    "        # Get first FRAME_LENGTH frames\n",
    "        for _ in range(FRAME_LENGTH):\n",
    "            env.step(random.choice([0,1]))\n",
    "            image : np.ndarray = env.render()\n",
    "            recorder.append(preprocess_image(image, RESIZED_WIDTH, RESIZED_HEIGHT))\n",
    "            cv.waitKey(25)\n",
    "            cv.imshow('',image)\n",
    "        state = recorder.numpy()\n",
    "        accumulate_reward = 0\n",
    "        rounds = 0\n",
    "        for time_step in range(max_time_step):\n",
    "            cv.waitKey(25)\n",
    "            cv.imshow('',image)\n",
    "            action_values = agent.q_value(state, eps)\n",
    "            action = agent.decide(action_values, eps)\n",
    "            \n",
    "            _, reward, done, _ , _ = env.step(action)\n",
    "            if done:\n",
    "                reward = -1\n",
    "            image : np.ndarray = env.render()\n",
    "            recorder.append(preprocess_image(image, RESIZED_WIDTH, RESIZED_HEIGHT))\n",
    "            next_state = recorder.numpy()\n",
    "\n",
    "\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            \"\"\" === this step has finished === \"\"\"\n",
    "            wandb.log({'action':action, 'reward': reward, 'eps': eps})\n",
    "            wandb.log({f'action_values[{i}]':q for i, q in enumerate(action_values.cpu().numpy().flatten()) })\n",
    "            \"\"\" === next iteration === \"\"\"\n",
    "            state = next_state\n",
    "            accumulate_reward += reward\n",
    "            rounds += 1\n",
    "            if done:\n",
    "                wandb.log({'rounds':rounds,'accumulate_reward':accumulate_reward})\n",
    "                print({'episode': episode,'agent.time_step': agent.time_step, 'rounds':rounds,'accumulate_reward':accumulate_reward})\n",
    "                break\n",
    "        if episode % UPDATE_EVERY == 0 and len(agent.memory) > BATCH_SIZE:\n",
    "            loss = agent.learn_from_experience()\n",
    "            wandb.log({'loss':loss})\n",
    "            print({'loss':loss})\n",
    "        if episode % TARGET_UPDATE_EVERY == 0:\n",
    "            agent.soft_update()\n",
    "        scores_window.append(accumulate_reward)\n",
    "        scores.append(accumulate_reward)\n",
    "        num_rounds.append(rounds)\n",
    "        eps = max(eps_end, eps*eps_decay)\n",
    "        if episode % 100 == 0:\n",
    "            print(episode, np.mean(scores_window))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pt')\n",
    "    return scores, num_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': 0, 'agent.time_step': 20, 'rounds': 20, 'accumulate_reward': 18.0}\n",
      "0 18.0\n",
      "{'episode': 1, 'agent.time_step': 36, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 2, 'agent.time_step': 55, 'rounds': 19, 'accumulate_reward': 17.0}\n",
      "{'episode': 3, 'agent.time_step': 64, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 4, 'agent.time_step': 75, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 5, 'agent.time_step': 85, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 6, 'agent.time_step': 142, 'rounds': 57, 'accumulate_reward': 55.0}\n",
      "{'episode': 7, 'agent.time_step': 148, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 8, 'agent.time_step': 177, 'rounds': 29, 'accumulate_reward': 27.0}\n",
      "{'episode': 9, 'agent.time_step': 193, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 10, 'agent.time_step': 217, 'rounds': 24, 'accumulate_reward': 22.0}\n",
      "(q_current, q_targets): (tensor([[0.1068],\n",
      "        [0.0708],\n",
      "        [0.0896],\n",
      "        [0.6709],\n",
      "        [0.6845],\n",
      "        [0.6754],\n",
      "        [0.6946],\n",
      "        [0.0828],\n",
      "        [0.6953],\n",
      "        [0.0978],\n",
      "        [0.6364],\n",
      "        [0.1033],\n",
      "        [0.7053],\n",
      "        [0.6881],\n",
      "        [0.7024],\n",
      "        [0.0608],\n",
      "        [0.6966],\n",
      "        [0.0432],\n",
      "        [0.7171],\n",
      "        [0.7157],\n",
      "        [0.6615],\n",
      "        [0.6520],\n",
      "        [0.0365],\n",
      "        [0.7328],\n",
      "        [0.6309],\n",
      "        [0.0833],\n",
      "        [0.1005],\n",
      "        [0.6502],\n",
      "        [0.0603],\n",
      "        [0.0938],\n",
      "        [0.1082],\n",
      "        [0.0709],\n",
      "        [0.1167],\n",
      "        [0.0609],\n",
      "        [0.6305],\n",
      "        [0.7030],\n",
      "        [0.6423],\n",
      "        [0.6349],\n",
      "        [0.6972],\n",
      "        [0.7037],\n",
      "        [0.5837],\n",
      "        [0.0805],\n",
      "        [0.0728],\n",
      "        [0.0473],\n",
      "        [0.0519],\n",
      "        [0.0628],\n",
      "        [0.6632],\n",
      "        [0.7074],\n",
      "        [0.0842],\n",
      "        [0.6636],\n",
      "        [0.1050],\n",
      "        [0.1085],\n",
      "        [0.0914],\n",
      "        [0.0441],\n",
      "        [0.0967],\n",
      "        [0.0704],\n",
      "        [0.1159],\n",
      "        [0.0760],\n",
      "        [0.0694],\n",
      "        [0.1096],\n",
      "        [0.1473],\n",
      "        [0.6796],\n",
      "        [0.6507],\n",
      "        [0.6416]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.9413],\n",
      "        [ 0.9379],\n",
      "        [ 0.9184],\n",
      "        [ 0.9368],\n",
      "        [ 0.9236],\n",
      "        [ 0.9608],\n",
      "        [ 0.9261],\n",
      "        [ 0.9231],\n",
      "        [ 0.9192],\n",
      "        [ 0.8923],\n",
      "        [ 0.8619],\n",
      "        [ 0.8712],\n",
      "        [ 0.9327],\n",
      "        [ 0.9458],\n",
      "        [ 0.9423],\n",
      "        [ 0.9367],\n",
      "        [ 0.9336],\n",
      "        [ 0.8715],\n",
      "        [ 0.9769],\n",
      "        [ 0.9318],\n",
      "        [ 0.8199],\n",
      "        [ 0.8694],\n",
      "        [ 0.9198],\n",
      "        [ 0.9610],\n",
      "        [ 0.9097],\n",
      "        [ 0.9375],\n",
      "        [ 0.9019],\n",
      "        [ 0.8430],\n",
      "        [ 0.8830],\n",
      "        [ 0.8957],\n",
      "        [ 0.9238],\n",
      "        [ 0.9423],\n",
      "        [ 0.9293],\n",
      "        [ 0.8701],\n",
      "        [ 0.9109],\n",
      "        [ 0.9290],\n",
      "        [ 0.9083],\n",
      "        [ 0.8953],\n",
      "        [ 0.9698],\n",
      "        [ 0.8923],\n",
      "        [-1.0000],\n",
      "        [ 0.9248],\n",
      "        [ 0.9502],\n",
      "        [ 0.8757],\n",
      "        [ 0.9495],\n",
      "        [ 0.9421],\n",
      "        [ 0.9570],\n",
      "        [ 0.9361],\n",
      "        [ 0.8931],\n",
      "        [ 0.9305],\n",
      "        [ 0.9104],\n",
      "        [ 0.9072],\n",
      "        [ 0.9467],\n",
      "        [ 0.9222],\n",
      "        [ 0.9383],\n",
      "        [ 0.9262],\n",
      "        [ 0.9288],\n",
      "        [ 0.9255],\n",
      "        [ 0.9433],\n",
      "        [ 0.8835],\n",
      "        [ 0.8489],\n",
      "        [-1.0000],\n",
      "        [ 0.9425],\n",
      "        [ 0.8889]], device='cuda:0'))\n",
      "{'loss': tensor(0.2329, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 11, 'agent.time_step': 245, 'rounds': 28, 'accumulate_reward': 26.0}\n",
      "{'episode': 12, 'agent.time_step': 260, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 13, 'agent.time_step': 269, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 14, 'agent.time_step': 296, 'rounds': 27, 'accumulate_reward': 25.0}\n",
      "{'episode': 15, 'agent.time_step': 306, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 16, 'agent.time_step': 313, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 17, 'agent.time_step': 323, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 18, 'agent.time_step': 347, 'rounds': 24, 'accumulate_reward': 22.0}\n",
      "{'episode': 19, 'agent.time_step': 373, 'rounds': 26, 'accumulate_reward': 24.0}\n",
      "{'episode': 20, 'agent.time_step': 382, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "(q_current, q_targets): (tensor([[127910.2812],\n",
      "        [810431.7500],\n",
      "        [127929.1562],\n",
      "        [810209.3750],\n",
      "        [810348.9375],\n",
      "        [810125.3750],\n",
      "        [127901.7656],\n",
      "        [810046.2500],\n",
      "        [809693.2500],\n",
      "        [127935.9141],\n",
      "        [810997.6250],\n",
      "        [810544.1875],\n",
      "        [127898.0547],\n",
      "        [127921.7344],\n",
      "        [127849.8281],\n",
      "        [810242.6875],\n",
      "        [810425.8750],\n",
      "        [810465.6875],\n",
      "        [810751.3750],\n",
      "        [810358.8125],\n",
      "        [810501.8750],\n",
      "        [810101.9375],\n",
      "        [810466.3750],\n",
      "        [810518.6250],\n",
      "        [127900.7891],\n",
      "        [127913.5938],\n",
      "        [810699.8750],\n",
      "        [127920.0469],\n",
      "        [810848.6250],\n",
      "        [127859.3281],\n",
      "        [810758.0000],\n",
      "        [127916.8594],\n",
      "        [810066.0625],\n",
      "        [810823.8125],\n",
      "        [811192.0000],\n",
      "        [810996.8750],\n",
      "        [811159.5625],\n",
      "        [127908.3750],\n",
      "        [810177.5625],\n",
      "        [810325.4375],\n",
      "        [810400.3750],\n",
      "        [127902.1406],\n",
      "        [810441.1875],\n",
      "        [810172.4375],\n",
      "        [810580.6250],\n",
      "        [810163.3750],\n",
      "        [127891.8750],\n",
      "        [127910.2812],\n",
      "        [810971.8750],\n",
      "        [810826.7500],\n",
      "        [810098.0625],\n",
      "        [809989.6250],\n",
      "        [810711.9375],\n",
      "        [810925.8750],\n",
      "        [810514.9375],\n",
      "        [810181.6250],\n",
      "        [810484.0625],\n",
      "        [127846.1406],\n",
      "        [127963.2031],\n",
      "        [811216.8125],\n",
      "        [810400.1250],\n",
      "        [127905.8281],\n",
      "        [810670.3750],\n",
      "        [811134.5625]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.3830],\n",
      "        [ 0.3652],\n",
      "        [ 0.4142],\n",
      "        [ 0.4018],\n",
      "        [ 0.3595],\n",
      "        [ 0.3996],\n",
      "        [ 0.3764],\n",
      "        [ 0.4313],\n",
      "        [ 0.4013],\n",
      "        [ 0.3280],\n",
      "        [ 0.3617],\n",
      "        [-1.0000],\n",
      "        [ 0.3974],\n",
      "        [ 0.3968],\n",
      "        [ 0.4058],\n",
      "        [ 0.4209],\n",
      "        [ 0.3460],\n",
      "        [ 0.3106],\n",
      "        [ 0.3663],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.3981],\n",
      "        [ 0.3834],\n",
      "        [ 0.3538],\n",
      "        [ 0.3944],\n",
      "        [-1.0000],\n",
      "        [ 0.3709],\n",
      "        [ 0.3054],\n",
      "        [ 0.3282],\n",
      "        [ 0.3689],\n",
      "        [ 0.3209],\n",
      "        [ 0.3983],\n",
      "        [ 0.4043],\n",
      "        [ 0.3555],\n",
      "        [ 0.3599],\n",
      "        [ 0.3338],\n",
      "        [ 0.3739],\n",
      "        [ 0.3123],\n",
      "        [ 0.3725],\n",
      "        [ 0.2871],\n",
      "        [ 0.3793],\n",
      "        [-1.0000],\n",
      "        [ 0.3880],\n",
      "        [ 0.3895],\n",
      "        [ 0.3181],\n",
      "        [ 0.3926],\n",
      "        [ 0.3940],\n",
      "        [ 0.3652],\n",
      "        [ 0.3610],\n",
      "        [ 0.3134],\n",
      "        [ 0.3872],\n",
      "        [ 0.3798],\n",
      "        [ 0.3491],\n",
      "        [ 0.3476],\n",
      "        [ 0.3229],\n",
      "        [ 0.3955],\n",
      "        [ 0.3315],\n",
      "        [ 0.3928],\n",
      "        [ 0.3322],\n",
      "        [ 0.3404],\n",
      "        [ 0.4073],\n",
      "        [-1.0000],\n",
      "        [ 0.3258],\n",
      "        [ 0.3515]], device='cuda:0'))\n",
      "{'loss': tensor(607864.0625, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 21, 'agent.time_step': 404, 'rounds': 22, 'accumulate_reward': 20.0}\n",
      "{'episode': 22, 'agent.time_step': 451, 'rounds': 47, 'accumulate_reward': 45.0}\n",
      "{'episode': 23, 'agent.time_step': 464, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 24, 'agent.time_step': 478, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 25, 'agent.time_step': 497, 'rounds': 19, 'accumulate_reward': 17.0}\n",
      "{'episode': 26, 'agent.time_step': 510, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 27, 'agent.time_step': 523, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 28, 'agent.time_step': 535, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 29, 'agent.time_step': 548, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 30, 'agent.time_step': 562, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "(q_current, q_targets): (tensor([[-111.4925],\n",
      "        [-111.6827],\n",
      "        [-383.0032],\n",
      "        [-383.0633],\n",
      "        [-111.3663],\n",
      "        [-111.5550],\n",
      "        [-111.6142],\n",
      "        [-383.0430],\n",
      "        [-383.4666],\n",
      "        [-111.4870],\n",
      "        [-383.2232],\n",
      "        [-111.5735],\n",
      "        [-111.7180],\n",
      "        [-111.6461],\n",
      "        [-383.1942],\n",
      "        [-382.8887],\n",
      "        [-111.9324],\n",
      "        [-111.5697],\n",
      "        [-111.5676],\n",
      "        [-383.3697],\n",
      "        [-382.9596],\n",
      "        [-111.6574],\n",
      "        [-383.3868],\n",
      "        [-111.5130],\n",
      "        [-111.2647],\n",
      "        [-111.5273],\n",
      "        [-111.7870],\n",
      "        [-111.4993],\n",
      "        [-111.4824],\n",
      "        [-111.4805],\n",
      "        [-111.5132],\n",
      "        [-383.6916],\n",
      "        [-382.9632],\n",
      "        [-382.8158],\n",
      "        [-111.6769],\n",
      "        [-382.9997],\n",
      "        [-111.5339],\n",
      "        [-111.4724],\n",
      "        [-382.9579],\n",
      "        [-111.3995],\n",
      "        [-111.4642],\n",
      "        [-111.6841],\n",
      "        [-383.2052],\n",
      "        [-111.6382],\n",
      "        [-111.4412],\n",
      "        [-111.5023],\n",
      "        [-383.0294],\n",
      "        [-111.2008],\n",
      "        [-383.0187],\n",
      "        [-383.3933],\n",
      "        [-111.8316],\n",
      "        [-111.5812],\n",
      "        [-111.4100],\n",
      "        [-111.7256],\n",
      "        [-382.9894],\n",
      "        [-383.0143],\n",
      "        [-111.6951],\n",
      "        [-111.4669],\n",
      "        [-111.4569],\n",
      "        [-383.1939],\n",
      "        [-383.3900],\n",
      "        [-383.4273],\n",
      "        [-383.4891],\n",
      "        [-111.4156]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8590],\n",
      "        [ 0.9213],\n",
      "        [-1.0000],\n",
      "        [ 0.8882],\n",
      "        [ 0.9091],\n",
      "        [ 0.9053],\n",
      "        [ 0.9182],\n",
      "        [ 0.9104],\n",
      "        [ 0.9005],\n",
      "        [ 0.8659],\n",
      "        [ 0.9022],\n",
      "        [ 0.9236],\n",
      "        [ 0.9022],\n",
      "        [ 0.8938],\n",
      "        [ 0.8947],\n",
      "        [ 0.9198],\n",
      "        [ 0.9348],\n",
      "        [ 0.9085],\n",
      "        [ 0.8920],\n",
      "        [ 0.8958],\n",
      "        [ 0.9212],\n",
      "        [ 0.9348],\n",
      "        [ 0.9249],\n",
      "        [ 0.9027],\n",
      "        [ 0.8754],\n",
      "        [-1.0000],\n",
      "        [ 0.8752],\n",
      "        [ 0.9453],\n",
      "        [ 0.8982],\n",
      "        [ 0.9184],\n",
      "        [-1.0000],\n",
      "        [ 0.9370],\n",
      "        [ 0.9056],\n",
      "        [ 0.9165],\n",
      "        [ 0.9389],\n",
      "        [ 0.8903],\n",
      "        [ 0.9131],\n",
      "        [ 0.9029],\n",
      "        [ 0.9275],\n",
      "        [ 0.8716],\n",
      "        [ 0.8791],\n",
      "        [ 0.8568],\n",
      "        [ 0.9440],\n",
      "        [ 0.8366],\n",
      "        [ 0.9092],\n",
      "        [ 0.9443],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.9092],\n",
      "        [-1.0000],\n",
      "        [ 0.9119],\n",
      "        [ 0.8996],\n",
      "        [-1.0000],\n",
      "        [ 0.9354],\n",
      "        [ 0.8662],\n",
      "        [ 0.9064],\n",
      "        [ 0.9202],\n",
      "        [ 0.9018],\n",
      "        [ 0.9243],\n",
      "        [ 0.8821],\n",
      "        [ 0.9252],\n",
      "        [ 0.9432],\n",
      "        [ 0.8996],\n",
      "        [ 0.9436]], device='cuda:0'))\n",
      "{'loss': tensor(217.8498, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 31, 'agent.time_step': 578, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 32, 'agent.time_step': 590, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 33, 'agent.time_step': 609, 'rounds': 19, 'accumulate_reward': 17.0}\n",
      "{'episode': 34, 'agent.time_step': 626, 'rounds': 17, 'accumulate_reward': 15.0}\n",
      "{'episode': 35, 'agent.time_step': 647, 'rounds': 21, 'accumulate_reward': 19.0}\n",
      "{'episode': 36, 'agent.time_step': 668, 'rounds': 21, 'accumulate_reward': 19.0}\n",
      "{'episode': 37, 'agent.time_step': 691, 'rounds': 23, 'accumulate_reward': 21.0}\n",
      "{'episode': 38, 'agent.time_step': 710, 'rounds': 19, 'accumulate_reward': 17.0}\n",
      "{'episode': 39, 'agent.time_step': 723, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 40, 'agent.time_step': 742, 'rounds': 19, 'accumulate_reward': 17.0}\n",
      "(q_current, q_targets): (tensor([[63.8992],\n",
      "        [63.8573],\n",
      "        [63.8131],\n",
      "        [63.8244],\n",
      "        [63.8325],\n",
      "        [63.8102],\n",
      "        [63.8608],\n",
      "        [63.9021],\n",
      "        [63.9256],\n",
      "        [ 3.6279],\n",
      "        [63.9256],\n",
      "        [63.8415],\n",
      "        [63.8532],\n",
      "        [63.7942],\n",
      "        [ 3.6935],\n",
      "        [63.9184],\n",
      "        [ 3.6784],\n",
      "        [ 3.6447],\n",
      "        [63.8291],\n",
      "        [63.8121],\n",
      "        [63.8280],\n",
      "        [63.8215],\n",
      "        [ 3.6447],\n",
      "        [63.9205],\n",
      "        [ 3.6290],\n",
      "        [63.8379],\n",
      "        [63.8351],\n",
      "        [63.8432],\n",
      "        [63.8683],\n",
      "        [ 3.6793],\n",
      "        [ 3.6887],\n",
      "        [63.9527],\n",
      "        [ 3.6510],\n",
      "        [ 3.6681],\n",
      "        [63.8217],\n",
      "        [63.8090],\n",
      "        [ 3.6504],\n",
      "        [ 3.6492],\n",
      "        [63.8116],\n",
      "        [ 3.6452],\n",
      "        [63.9105],\n",
      "        [ 3.6521],\n",
      "        [ 3.6206],\n",
      "        [ 3.6860],\n",
      "        [ 3.6482],\n",
      "        [63.8244],\n",
      "        [ 3.6599],\n",
      "        [63.8404],\n",
      "        [ 3.6660],\n",
      "        [ 3.6728],\n",
      "        [ 3.6504],\n",
      "        [63.8258],\n",
      "        [63.8451],\n",
      "        [ 3.6377],\n",
      "        [63.9076],\n",
      "        [ 3.6410],\n",
      "        [ 3.6742],\n",
      "        [63.8764],\n",
      "        [ 3.6427],\n",
      "        [63.8165],\n",
      "        [63.8898],\n",
      "        [ 3.6619],\n",
      "        [63.8429],\n",
      "        [63.8266]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8686],\n",
      "        [ 0.9268],\n",
      "        [ 0.9259],\n",
      "        [ 0.8981],\n",
      "        [ 0.9428],\n",
      "        [ 0.9166],\n",
      "        [ 0.9819],\n",
      "        [ 0.9240],\n",
      "        [ 0.8967],\n",
      "        [ 0.8306],\n",
      "        [ 0.8490],\n",
      "        [ 0.9328],\n",
      "        [-1.0000],\n",
      "        [ 0.9057],\n",
      "        [ 0.9180],\n",
      "        [ 0.8642],\n",
      "        [ 0.9264],\n",
      "        [ 0.7979],\n",
      "        [ 0.8301],\n",
      "        [ 0.9303],\n",
      "        [ 0.9504],\n",
      "        [ 0.8947],\n",
      "        [ 0.7942],\n",
      "        [ 0.8501],\n",
      "        [ 0.9171],\n",
      "        [ 0.9316],\n",
      "        [ 0.9279],\n",
      "        [ 0.8932],\n",
      "        [ 0.8624],\n",
      "        [ 0.9270],\n",
      "        [ 0.9328],\n",
      "        [ 0.8592],\n",
      "        [-1.0000],\n",
      "        [ 0.9233],\n",
      "        [ 0.9197],\n",
      "        [ 0.9374],\n",
      "        [ 0.9316],\n",
      "        [ 0.8929],\n",
      "        [ 0.9321],\n",
      "        [ 0.9192],\n",
      "        [ 0.8822],\n",
      "        [ 0.9004],\n",
      "        [ 0.8495],\n",
      "        [ 0.9295],\n",
      "        [ 0.9048],\n",
      "        [ 0.9316],\n",
      "        [ 0.9282],\n",
      "        [ 0.9011],\n",
      "        [-1.0000],\n",
      "        [ 0.9251],\n",
      "        [ 0.9362],\n",
      "        [ 0.9316],\n",
      "        [ 0.9049],\n",
      "        [ 0.9327],\n",
      "        [ 0.8566],\n",
      "        [ 0.8311],\n",
      "        [ 0.9143],\n",
      "        [ 0.8516],\n",
      "        [ 0.8477],\n",
      "        [ 0.8253],\n",
      "        [ 0.9528],\n",
      "        [ 0.9229],\n",
      "        [ 0.9523],\n",
      "        [ 0.8524]], device='cuda:0'))\n",
      "{'loss': tensor(38.0873, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 41, 'agent.time_step': 754, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 42, 'agent.time_step': 763, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 43, 'agent.time_step': 775, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 44, 'agent.time_step': 789, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 45, 'agent.time_step': 805, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 46, 'agent.time_step': 814, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 47, 'agent.time_step': 841, 'rounds': 27, 'accumulate_reward': 25.0}\n",
      "{'episode': 48, 'agent.time_step': 854, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 49, 'agent.time_step': 862, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 50, 'agent.time_step': 870, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[-5.8808],\n",
      "        [-5.8782],\n",
      "        [-9.8650],\n",
      "        [-5.8693],\n",
      "        [-9.9166],\n",
      "        [-9.8828],\n",
      "        [-5.8911],\n",
      "        [-9.8687],\n",
      "        [-9.8793],\n",
      "        [-9.8223],\n",
      "        [-5.8275],\n",
      "        [-5.8524],\n",
      "        [-5.8714],\n",
      "        [-5.8877],\n",
      "        [-9.8617],\n",
      "        [-9.8954],\n",
      "        [-9.8709],\n",
      "        [-5.9148],\n",
      "        [-5.8833],\n",
      "        [-5.9026],\n",
      "        [-5.8943],\n",
      "        [-5.9077],\n",
      "        [-9.8656],\n",
      "        [-9.8391],\n",
      "        [-9.8756],\n",
      "        [-5.8808],\n",
      "        [-5.8669],\n",
      "        [-9.8690],\n",
      "        [-5.8666],\n",
      "        [-9.8223],\n",
      "        [-9.8561],\n",
      "        [-5.8540],\n",
      "        [-5.8836],\n",
      "        [-9.9145],\n",
      "        [-5.8595],\n",
      "        [-5.8548],\n",
      "        [-5.8612],\n",
      "        [-9.8629],\n",
      "        [-5.8644],\n",
      "        [-5.8848],\n",
      "        [-5.8848],\n",
      "        [-5.8953],\n",
      "        [-5.8311],\n",
      "        [-5.8757],\n",
      "        [-5.8335],\n",
      "        [-5.8606],\n",
      "        [-5.8275],\n",
      "        [-5.8585],\n",
      "        [-5.8738],\n",
      "        [-5.8296],\n",
      "        [-9.8791],\n",
      "        [-5.8867],\n",
      "        [-5.8747],\n",
      "        [-5.8715],\n",
      "        [-5.8432],\n",
      "        [-5.8548],\n",
      "        [-5.8827],\n",
      "        [-5.9025],\n",
      "        [-9.9241],\n",
      "        [-5.8437],\n",
      "        [-9.8493],\n",
      "        [-9.8924],\n",
      "        [-5.8626],\n",
      "        [-5.8759]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[-1.0000],\n",
      "        [ 0.3412],\n",
      "        [ 0.4021],\n",
      "        [ 0.4104],\n",
      "        [ 0.3695],\n",
      "        [ 0.3274],\n",
      "        [ 0.3926],\n",
      "        [ 0.3072],\n",
      "        [ 0.4191],\n",
      "        [ 0.3891],\n",
      "        [ 0.3870],\n",
      "        [ 0.3909],\n",
      "        [ 0.3439],\n",
      "        [ 0.4179],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.3178],\n",
      "        [ 0.4048],\n",
      "        [ 0.3781],\n",
      "        [-1.0000],\n",
      "        [ 0.3293],\n",
      "        [-1.0000],\n",
      "        [ 0.3112],\n",
      "        [ 0.4272],\n",
      "        [ 0.3192],\n",
      "        [ 0.3417],\n",
      "        [ 0.3651],\n",
      "        [ 0.3887],\n",
      "        [ 0.3443],\n",
      "        [ 0.4011],\n",
      "        [ 0.3093],\n",
      "        [ 0.3161],\n",
      "        [ 0.3191],\n",
      "        [-1.0000],\n",
      "        [ 0.3674],\n",
      "        [ 0.3777],\n",
      "        [ 0.3207],\n",
      "        [ 0.3472],\n",
      "        [ 0.3229],\n",
      "        [ 0.3663],\n",
      "        [ 0.3377],\n",
      "        [ 0.3259],\n",
      "        [ 0.4014],\n",
      "        [ 0.3110],\n",
      "        [ 0.3963],\n",
      "        [ 0.3363],\n",
      "        [ 0.3860],\n",
      "        [ 0.3880],\n",
      "        [ 0.4052],\n",
      "        [ 0.3936],\n",
      "        [ 0.3012],\n",
      "        [-1.0000],\n",
      "        [ 0.3272],\n",
      "        [ 0.3985],\n",
      "        [ 0.3140],\n",
      "        [ 0.3551],\n",
      "        [ 0.3223],\n",
      "        [ 0.3308],\n",
      "        [ 0.3593],\n",
      "        [ 0.4230],\n",
      "        [ 0.3964],\n",
      "        [ 0.3491],\n",
      "        [ 0.3483],\n",
      "        [ 0.4128]], device='cuda:0'))\n",
      "{'loss': tensor(6.8955, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 51, 'agent.time_step': 889, 'rounds': 19, 'accumulate_reward': 17.0}\n",
      "{'episode': 52, 'agent.time_step': 901, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 53, 'agent.time_step': 915, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 54, 'agent.time_step': 924, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 55, 'agent.time_step': 954, 'rounds': 30, 'accumulate_reward': 28.0}\n",
      "{'episode': 56, 'agent.time_step': 964, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 57, 'agent.time_step': 983, 'rounds': 19, 'accumulate_reward': 17.0}\n",
      "{'episode': 58, 'agent.time_step': 992, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 59, 'agent.time_step': 1000, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 60, 'agent.time_step': 1011, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "(q_current, q_targets): (tensor([[-9.3797],\n",
      "        [ 7.4739],\n",
      "        [ 7.4539],\n",
      "        [ 7.4757],\n",
      "        [ 7.4927],\n",
      "        [-9.4203],\n",
      "        [ 7.4590],\n",
      "        [-9.4051],\n",
      "        [ 7.4386],\n",
      "        [ 7.4480],\n",
      "        [-9.3255],\n",
      "        [ 7.4123],\n",
      "        [ 7.4378],\n",
      "        [-9.3631],\n",
      "        [-9.3856],\n",
      "        [-9.3649],\n",
      "        [ 7.3965],\n",
      "        [ 7.4805],\n",
      "        [ 7.4283],\n",
      "        [ 7.4443],\n",
      "        [ 7.4392],\n",
      "        [ 7.4506],\n",
      "        [ 7.4042],\n",
      "        [ 7.4404],\n",
      "        [ 7.4588],\n",
      "        [ 7.4865],\n",
      "        [ 7.4260],\n",
      "        [ 7.5036],\n",
      "        [ 7.4293],\n",
      "        [ 7.4639],\n",
      "        [-9.3589],\n",
      "        [-9.4098],\n",
      "        [ 7.4196],\n",
      "        [ 7.4596],\n",
      "        [ 7.4342],\n",
      "        [ 7.4107],\n",
      "        [ 7.4441],\n",
      "        [-9.4096],\n",
      "        [ 7.4337],\n",
      "        [ 7.3918],\n",
      "        [ 7.4638],\n",
      "        [ 7.4556],\n",
      "        [ 7.4374],\n",
      "        [-9.3760],\n",
      "        [ 7.4812],\n",
      "        [ 7.4264],\n",
      "        [ 7.4483],\n",
      "        [-9.3997],\n",
      "        [ 7.4584],\n",
      "        [ 7.4104],\n",
      "        [ 7.4699],\n",
      "        [ 7.3854],\n",
      "        [-9.3692],\n",
      "        [ 7.4915],\n",
      "        [-9.3898],\n",
      "        [-9.4015],\n",
      "        [ 7.4086],\n",
      "        [ 7.4601],\n",
      "        [ 7.4803],\n",
      "        [-9.3792],\n",
      "        [ 7.4335],\n",
      "        [ 7.4410],\n",
      "        [-9.3431],\n",
      "        [ 7.4246]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7250],\n",
      "        [ 0.7127],\n",
      "        [ 0.6939],\n",
      "        [ 0.7361],\n",
      "        [ 0.6977],\n",
      "        [ 0.7096],\n",
      "        [ 0.6918],\n",
      "        [ 0.7333],\n",
      "        [ 0.7396],\n",
      "        [ 0.7353],\n",
      "        [ 0.6833],\n",
      "        [ 0.7362],\n",
      "        [ 0.7410],\n",
      "        [ 0.7120],\n",
      "        [ 0.7377],\n",
      "        [ 0.7285],\n",
      "        [ 0.7341],\n",
      "        [ 0.7246],\n",
      "        [ 0.6713],\n",
      "        [ 0.7035],\n",
      "        [ 0.7274],\n",
      "        [-1.0000],\n",
      "        [ 0.7303],\n",
      "        [ 0.7343],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.7319],\n",
      "        [ 0.7266],\n",
      "        [ 0.7393],\n",
      "        [ 0.7753],\n",
      "        [ 0.7474],\n",
      "        [ 0.7030],\n",
      "        [ 0.7469],\n",
      "        [ 0.7312],\n",
      "        [ 0.7263],\n",
      "        [ 0.7377],\n",
      "        [ 0.7403],\n",
      "        [ 0.7179],\n",
      "        [ 0.7418],\n",
      "        [ 0.7330],\n",
      "        [ 0.7316],\n",
      "        [ 0.7180],\n",
      "        [ 0.7321],\n",
      "        [ 0.7277],\n",
      "        [-1.0000],\n",
      "        [ 0.7171],\n",
      "        [ 0.7327],\n",
      "        [ 0.7425],\n",
      "        [ 0.6772],\n",
      "        [ 0.7428],\n",
      "        [ 0.6950],\n",
      "        [ 0.6885],\n",
      "        [ 0.7012],\n",
      "        [ 0.6935],\n",
      "        [ 0.7316],\n",
      "        [ 0.7660],\n",
      "        [ 0.7320],\n",
      "        [ 0.6915],\n",
      "        [ 0.7127],\n",
      "        [ 0.7257],\n",
      "        [ 0.7355],\n",
      "        [ 0.7391],\n",
      "        [ 0.7486],\n",
      "        [ 0.7292]], device='cuda:0'))\n",
      "{'loss': tensor(7.2286, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 61, 'agent.time_step': 1036, 'rounds': 25, 'accumulate_reward': 23.0}\n",
      "{'episode': 62, 'agent.time_step': 1052, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 63, 'agent.time_step': 1061, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 64, 'agent.time_step': 1072, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 65, 'agent.time_step': 1082, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 66, 'agent.time_step': 1094, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 67, 'agent.time_step': 1102, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 68, 'agent.time_step': 1111, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 69, 'agent.time_step': 1129, 'rounds': 18, 'accumulate_reward': 16.0}\n",
      "{'episode': 70, 'agent.time_step': 1143, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "(q_current, q_targets): (tensor([[-0.5474],\n",
      "        [ 0.7179],\n",
      "        [ 0.4056],\n",
      "        [ 0.6725],\n",
      "        [ 0.3762],\n",
      "        [-0.0270],\n",
      "        [-0.1216],\n",
      "        [ 0.7077],\n",
      "        [-0.7514],\n",
      "        [ 0.3823],\n",
      "        [-0.0379],\n",
      "        [ 0.7478],\n",
      "        [ 0.4019],\n",
      "        [-0.6456],\n",
      "        [-0.4134],\n",
      "        [-0.0279],\n",
      "        [ 0.1809],\n",
      "        [-0.3373],\n",
      "        [ 1.3222],\n",
      "        [ 0.5223],\n",
      "        [ 0.3566],\n",
      "        [ 0.6201],\n",
      "        [ 0.0634],\n",
      "        [ 0.0845],\n",
      "        [ 0.2343],\n",
      "        [ 0.2431],\n",
      "        [ 0.7719],\n",
      "        [ 0.0309],\n",
      "        [-0.0225],\n",
      "        [ 0.8061],\n",
      "        [-0.0151],\n",
      "        [ 0.9255],\n",
      "        [-0.0222],\n",
      "        [ 0.5477],\n",
      "        [-0.3104],\n",
      "        [ 0.5953],\n",
      "        [ 0.7836],\n",
      "        [ 0.1458],\n",
      "        [ 0.0845],\n",
      "        [-0.0957],\n",
      "        [-0.0302],\n",
      "        [ 0.0654],\n",
      "        [-0.0219],\n",
      "        [-0.1687],\n",
      "        [-0.0229],\n",
      "        [ 0.8854],\n",
      "        [ 1.0199],\n",
      "        [ 0.1876],\n",
      "        [ 0.6248],\n",
      "        [-0.0205],\n",
      "        [ 0.2531],\n",
      "        [ 0.5742],\n",
      "        [ 0.0230],\n",
      "        [ 0.0471],\n",
      "        [-0.2193],\n",
      "        [-1.9999],\n",
      "        [ 0.1779],\n",
      "        [ 0.2479],\n",
      "        [ 0.5903],\n",
      "        [-0.0238],\n",
      "        [ 0.3017],\n",
      "        [-0.6264],\n",
      "        [-0.3287],\n",
      "        [ 0.1834]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8775],\n",
      "        [ 0.8077],\n",
      "        [ 0.8127],\n",
      "        [ 0.8624],\n",
      "        [ 0.8429],\n",
      "        [ 0.7979],\n",
      "        [ 0.7985],\n",
      "        [-1.0000],\n",
      "        [ 0.8655],\n",
      "        [ 0.8278],\n",
      "        [ 0.8196],\n",
      "        [ 0.8381],\n",
      "        [ 0.8509],\n",
      "        [ 0.7874],\n",
      "        [ 0.8635],\n",
      "        [ 0.8364],\n",
      "        [-1.0000],\n",
      "        [ 0.8537],\n",
      "        [ 0.8300],\n",
      "        [ 0.8375],\n",
      "        [ 0.8709],\n",
      "        [ 0.8593],\n",
      "        [ 0.8513],\n",
      "        [ 0.8375],\n",
      "        [ 0.8453],\n",
      "        [ 0.8757],\n",
      "        [ 0.8839],\n",
      "        [ 0.8255],\n",
      "        [ 0.8317],\n",
      "        [ 0.8591],\n",
      "        [ 0.8555],\n",
      "        [ 0.7964],\n",
      "        [ 0.8057],\n",
      "        [ 0.8439],\n",
      "        [ 0.8220],\n",
      "        [ 0.8045],\n",
      "        [ 0.8677],\n",
      "        [ 0.8414],\n",
      "        [ 0.8413],\n",
      "        [ 0.7979],\n",
      "        [ 0.8109],\n",
      "        [ 0.8136],\n",
      "        [ 0.7947],\n",
      "        [ 0.8053],\n",
      "        [ 0.8193],\n",
      "        [-1.0000],\n",
      "        [ 0.8759],\n",
      "        [ 0.8209],\n",
      "        [ 0.8837],\n",
      "        [ 0.7939],\n",
      "        [ 0.8806],\n",
      "        [ 0.8245],\n",
      "        [ 0.8319],\n",
      "        [ 0.8574],\n",
      "        [ 0.8402],\n",
      "        [ 0.8491],\n",
      "        [ 0.8514],\n",
      "        [ 0.7723],\n",
      "        [ 0.8827],\n",
      "        [ 0.7936],\n",
      "        [ 0.8412],\n",
      "        [ 0.8044],\n",
      "        [-1.0000],\n",
      "        [ 0.8177]], device='cuda:0'))\n",
      "{'loss': tensor(0.3501, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 71, 'agent.time_step': 1153, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 72, 'agent.time_step': 1160, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 73, 'agent.time_step': 1175, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 74, 'agent.time_step': 1182, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 75, 'agent.time_step': 1189, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 76, 'agent.time_step': 1199, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 77, 'agent.time_step': 1206, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 78, 'agent.time_step': 1217, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 79, 'agent.time_step': 1224, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 80, 'agent.time_step': 1237, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "(q_current, q_targets): (tensor([[-0.1310],\n",
      "        [ 0.0796],\n",
      "        [ 0.4937],\n",
      "        [ 0.5600],\n",
      "        [ 0.3056],\n",
      "        [ 0.4584],\n",
      "        [ 0.7575],\n",
      "        [ 0.0619],\n",
      "        [ 0.0677],\n",
      "        [ 0.5553],\n",
      "        [ 0.1379],\n",
      "        [ 0.1167],\n",
      "        [ 0.1578],\n",
      "        [ 0.0700],\n",
      "        [ 0.0186],\n",
      "        [ 0.4631],\n",
      "        [ 0.1515],\n",
      "        [ 0.1196],\n",
      "        [ 0.0436],\n",
      "        [ 0.7549],\n",
      "        [ 0.6928],\n",
      "        [-0.5900],\n",
      "        [ 0.0241],\n",
      "        [ 0.2034],\n",
      "        [ 0.0268],\n",
      "        [-0.2175],\n",
      "        [-0.1124],\n",
      "        [ 1.0908],\n",
      "        [ 0.2110],\n",
      "        [ 0.1206],\n",
      "        [ 0.2498],\n",
      "        [ 0.0348],\n",
      "        [ 0.6009],\n",
      "        [ 0.0179],\n",
      "        [ 0.2591],\n",
      "        [ 0.3401],\n",
      "        [ 0.0607],\n",
      "        [ 0.1623],\n",
      "        [ 0.6163],\n",
      "        [ 0.7214],\n",
      "        [-0.1179],\n",
      "        [ 0.1939],\n",
      "        [ 0.0224],\n",
      "        [ 0.6590],\n",
      "        [ 0.1966],\n",
      "        [ 0.3345],\n",
      "        [ 0.4130],\n",
      "        [ 0.8893],\n",
      "        [ 0.1543],\n",
      "        [ 0.4676],\n",
      "        [ 0.0325],\n",
      "        [ 0.1086],\n",
      "        [ 0.0906],\n",
      "        [ 0.2127],\n",
      "        [-0.2689],\n",
      "        [ 0.1777],\n",
      "        [ 0.9069],\n",
      "        [ 0.1924],\n",
      "        [ 0.6989],\n",
      "        [ 0.7504],\n",
      "        [ 0.9168],\n",
      "        [ 0.1518],\n",
      "        [ 0.2045],\n",
      "        [ 0.0086]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7985],\n",
      "        [ 0.8148],\n",
      "        [ 0.8230],\n",
      "        [ 0.8062],\n",
      "        [ 0.8376],\n",
      "        [ 0.8319],\n",
      "        [ 0.7842],\n",
      "        [ 0.8104],\n",
      "        [ 0.8095],\n",
      "        [ 0.8015],\n",
      "        [ 0.8219],\n",
      "        [ 0.8109],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.8366],\n",
      "        [ 0.8075],\n",
      "        [ 0.8400],\n",
      "        [ 0.7430],\n",
      "        [ 0.8632],\n",
      "        [ 0.7675],\n",
      "        [ 0.8415],\n",
      "        [ 0.8571],\n",
      "        [ 0.8491],\n",
      "        [-1.0000],\n",
      "        [ 0.7925],\n",
      "        [ 0.8589],\n",
      "        [ 0.8572],\n",
      "        [-1.0000],\n",
      "        [ 0.8562],\n",
      "        [ 0.8274],\n",
      "        [ 0.8538],\n",
      "        [ 0.8600],\n",
      "        [ 0.7576],\n",
      "        [ 0.8548],\n",
      "        [ 0.8308],\n",
      "        [ 0.8403],\n",
      "        [ 0.8519],\n",
      "        [ 0.8523],\n",
      "        [ 0.8233],\n",
      "        [ 0.7496],\n",
      "        [ 0.8277],\n",
      "        [ 0.8385],\n",
      "        [ 0.8321],\n",
      "        [ 0.8409],\n",
      "        [ 0.8400],\n",
      "        [ 0.8376],\n",
      "        [ 0.8471],\n",
      "        [-1.0000],\n",
      "        [ 0.8086],\n",
      "        [ 0.8343],\n",
      "        [ 0.8371],\n",
      "        [ 0.8122],\n",
      "        [ 0.8060],\n",
      "        [-1.0000],\n",
      "        [ 0.8545],\n",
      "        [ 0.8177],\n",
      "        [ 0.8817],\n",
      "        [ 0.8511],\n",
      "        [ 0.8556],\n",
      "        [ 0.8123],\n",
      "        [ 0.7947],\n",
      "        [ 0.8078],\n",
      "        [ 0.7494],\n",
      "        [-1.0000]], device='cuda:0'))\n",
      "{'loss': tensor(0.2838, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 81, 'agent.time_step': 1246, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 82, 'agent.time_step': 1258, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 83, 'agent.time_step': 1272, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 84, 'agent.time_step': 1279, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 85, 'agent.time_step': 1288, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 86, 'agent.time_step': 1298, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 87, 'agent.time_step': 1306, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 88, 'agent.time_step': 1314, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 89, 'agent.time_step': 1328, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 90, 'agent.time_step': 1337, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "(q_current, q_targets): (tensor([[ 0.3239],\n",
      "        [ 0.2126],\n",
      "        [ 1.0337],\n",
      "        [ 0.2051],\n",
      "        [ 1.0085],\n",
      "        [ 0.3427],\n",
      "        [ 0.3756],\n",
      "        [-0.3103],\n",
      "        [ 0.1865],\n",
      "        [ 0.1778],\n",
      "        [-0.4037],\n",
      "        [ 0.4273],\n",
      "        [ 0.1625],\n",
      "        [ 0.3239],\n",
      "        [ 0.5128],\n",
      "        [ 0.3185],\n",
      "        [ 0.8592],\n",
      "        [ 0.3260],\n",
      "        [ 1.2807],\n",
      "        [ 0.3293],\n",
      "        [ 0.5960],\n",
      "        [ 0.3674],\n",
      "        [-0.3260],\n",
      "        [ 0.1847],\n",
      "        [ 0.4041],\n",
      "        [ 0.6669],\n",
      "        [ 0.8679],\n",
      "        [ 0.3043],\n",
      "        [ 0.3821],\n",
      "        [ 0.7716],\n",
      "        [ 0.2884],\n",
      "        [ 0.5335],\n",
      "        [ 0.7864],\n",
      "        [ 0.3359],\n",
      "        [-0.4422],\n",
      "        [ 0.6216],\n",
      "        [ 0.3108],\n",
      "        [ 0.6133],\n",
      "        [ 0.1836],\n",
      "        [-0.3893],\n",
      "        [ 0.6396],\n",
      "        [ 0.5907],\n",
      "        [ 0.5715],\n",
      "        [-0.3165],\n",
      "        [ 0.7804],\n",
      "        [ 0.1945],\n",
      "        [ 0.5404],\n",
      "        [ 1.0922],\n",
      "        [ 0.5795],\n",
      "        [ 0.3710],\n",
      "        [ 0.5907],\n",
      "        [ 0.6265],\n",
      "        [ 0.6833],\n",
      "        [ 0.6742],\n",
      "        [ 0.7762],\n",
      "        [-0.5151],\n",
      "        [-0.2291],\n",
      "        [ 0.1630],\n",
      "        [-0.3334],\n",
      "        [-0.1715],\n",
      "        [ 0.1572],\n",
      "        [ 0.1786],\n",
      "        [ 0.5757],\n",
      "        [ 0.6734]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8610],\n",
      "        [ 0.8439],\n",
      "        [ 0.8358],\n",
      "        [ 0.8743],\n",
      "        [-1.0000],\n",
      "        [ 0.8303],\n",
      "        [ 0.8225],\n",
      "        [ 0.8461],\n",
      "        [ 0.8956],\n",
      "        [ 0.8679],\n",
      "        [ 0.8533],\n",
      "        [ 0.8430],\n",
      "        [ 0.8717],\n",
      "        [-1.0000],\n",
      "        [ 0.8797],\n",
      "        [ 0.8488],\n",
      "        [ 0.8588],\n",
      "        [ 0.8446],\n",
      "        [ 0.8607],\n",
      "        [ 0.8610],\n",
      "        [ 0.8715],\n",
      "        [ 0.8306],\n",
      "        [ 0.8628],\n",
      "        [ 0.7558],\n",
      "        [ 0.8931],\n",
      "        [ 0.8305],\n",
      "        [ 0.8552],\n",
      "        [ 0.8469],\n",
      "        [ 0.8484],\n",
      "        [ 0.8441],\n",
      "        [ 0.8569],\n",
      "        [ 0.8773],\n",
      "        [ 0.8211],\n",
      "        [ 0.8474],\n",
      "        [-1.0000],\n",
      "        [ 0.8808],\n",
      "        [ 0.8781],\n",
      "        [ 0.8512],\n",
      "        [ 0.8537],\n",
      "        [ 0.8546],\n",
      "        [-1.0000],\n",
      "        [ 0.8671],\n",
      "        [ 0.8308],\n",
      "        [ 0.9084],\n",
      "        [ 0.8078],\n",
      "        [ 0.8159],\n",
      "        [ 0.8512],\n",
      "        [ 0.8439],\n",
      "        [ 0.8159],\n",
      "        [-1.0000],\n",
      "        [ 0.8331],\n",
      "        [ 0.8666],\n",
      "        [ 0.8426],\n",
      "        [ 0.8782],\n",
      "        [ 0.8884],\n",
      "        [-1.0000],\n",
      "        [ 0.8830],\n",
      "        [ 0.8534],\n",
      "        [ 0.8747],\n",
      "        [ 0.8666],\n",
      "        [ 0.8700],\n",
      "        [ 0.8605],\n",
      "        [ 0.8113],\n",
      "        [-1.0000]], device='cuda:0'))\n",
      "{'loss': tensor(0.2523, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 91, 'agent.time_step': 1355, 'rounds': 18, 'accumulate_reward': 16.0}\n",
      "{'episode': 92, 'agent.time_step': 1367, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 93, 'agent.time_step': 1390, 'rounds': 23, 'accumulate_reward': 21.0}\n",
      "{'episode': 94, 'agent.time_step': 1408, 'rounds': 18, 'accumulate_reward': 16.0}\n",
      "{'episode': 95, 'agent.time_step': 1423, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 96, 'agent.time_step': 1439, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 97, 'agent.time_step': 1448, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 98, 'agent.time_step': 1458, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 99, 'agent.time_step': 1479, 'rounds': 21, 'accumulate_reward': 19.0}\n",
      "{'episode': 100, 'agent.time_step': 1487, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[ 1.1643],\n",
      "        [ 1.0885],\n",
      "        [ 1.1836],\n",
      "        [ 0.6766],\n",
      "        [-0.5248],\n",
      "        [-0.4130],\n",
      "        [ 1.1832],\n",
      "        [ 0.7076],\n",
      "        [ 1.2178],\n",
      "        [-0.4910],\n",
      "        [ 1.0413],\n",
      "        [-0.4030],\n",
      "        [-0.6545],\n",
      "        [ 1.7309],\n",
      "        [ 0.9479],\n",
      "        [-0.4710],\n",
      "        [-0.4174],\n",
      "        [ 1.1529],\n",
      "        [ 0.9125],\n",
      "        [ 0.9262],\n",
      "        [ 1.1389],\n",
      "        [ 1.7403],\n",
      "        [ 1.2241],\n",
      "        [ 0.7093],\n",
      "        [ 1.3797],\n",
      "        [ 1.3583],\n",
      "        [ 1.0711],\n",
      "        [ 1.0932],\n",
      "        [ 1.3760],\n",
      "        [ 0.9034],\n",
      "        [ 1.6018],\n",
      "        [ 1.1656],\n",
      "        [ 0.9659],\n",
      "        [ 1.3641],\n",
      "        [ 0.8317],\n",
      "        [ 0.9037],\n",
      "        [ 1.5397],\n",
      "        [ 1.5148],\n",
      "        [-0.4835],\n",
      "        [ 1.3069],\n",
      "        [ 0.9621],\n",
      "        [ 1.2477],\n",
      "        [ 1.4272],\n",
      "        [-0.4607],\n",
      "        [ 0.7061],\n",
      "        [ 1.1284],\n",
      "        [ 1.2415],\n",
      "        [ 0.9438],\n",
      "        [ 0.8869],\n",
      "        [ 1.3708],\n",
      "        [-0.5403],\n",
      "        [ 1.0703],\n",
      "        [ 1.2183],\n",
      "        [ 1.1340],\n",
      "        [ 1.1638],\n",
      "        [ 1.2591],\n",
      "        [-0.5202],\n",
      "        [-0.2777],\n",
      "        [ 1.0998],\n",
      "        [ 1.1458],\n",
      "        [ 1.5032],\n",
      "        [ 1.4371],\n",
      "        [ 1.5733],\n",
      "        [ 1.4341]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.9055],\n",
      "        [-1.0000],\n",
      "        [ 0.7942],\n",
      "        [ 0.8948],\n",
      "        [ 0.7818],\n",
      "        [-1.0000],\n",
      "        [ 0.8078],\n",
      "        [ 0.8256],\n",
      "        [ 0.8714],\n",
      "        [ 0.7805],\n",
      "        [ 0.7554],\n",
      "        [ 0.8473],\n",
      "        [ 0.8219],\n",
      "        [ 0.8279],\n",
      "        [ 0.8796],\n",
      "        [ 0.8689],\n",
      "        [ 0.8319],\n",
      "        [ 0.8485],\n",
      "        [ 0.8717],\n",
      "        [ 0.8533],\n",
      "        [ 0.8107],\n",
      "        [ 0.8193],\n",
      "        [-1.0000],\n",
      "        [ 0.8249],\n",
      "        [ 0.8623],\n",
      "        [ 0.8005],\n",
      "        [ 0.8017],\n",
      "        [ 0.8649],\n",
      "        [ 0.7458],\n",
      "        [ 0.8571],\n",
      "        [ 0.8020],\n",
      "        [ 0.8485],\n",
      "        [ 0.8608],\n",
      "        [ 0.8193],\n",
      "        [ 0.8727],\n",
      "        [ 0.8540],\n",
      "        [ 0.8310],\n",
      "        [ 0.8594],\n",
      "        [ 0.8587],\n",
      "        [ 0.8467],\n",
      "        [ 0.8609],\n",
      "        [ 0.8549],\n",
      "        [ 0.8492],\n",
      "        [-1.0000],\n",
      "        [ 0.8276],\n",
      "        [ 0.8359],\n",
      "        [ 0.8839],\n",
      "        [ 0.8150],\n",
      "        [ 0.8488],\n",
      "        [ 0.8594],\n",
      "        [ 0.8548],\n",
      "        [ 0.7365],\n",
      "        [ 0.8638],\n",
      "        [ 0.8250],\n",
      "        [ 0.8133],\n",
      "        [-1.0000],\n",
      "        [ 0.8602],\n",
      "        [ 0.8627],\n",
      "        [ 0.8330],\n",
      "        [ 0.8160],\n",
      "        [ 0.8248],\n",
      "        [ 0.8628],\n",
      "        [ 0.8176],\n",
      "        [-1.0000]], device='cuda:0'))\n",
      "{'loss': tensor(0.3107, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "100 12.67\n",
      "{'episode': 101, 'agent.time_step': 1503, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 102, 'agent.time_step': 1514, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 103, 'agent.time_step': 1527, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 104, 'agent.time_step': 1540, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 105, 'agent.time_step': 1550, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 106, 'agent.time_step': 1557, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 107, 'agent.time_step': 1564, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 108, 'agent.time_step': 1571, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 109, 'agent.time_step': 1583, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 110, 'agent.time_step': 1593, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "(q_current, q_targets): (tensor([[ 0.5025],\n",
      "        [ 0.3515],\n",
      "        [-0.2700],\n",
      "        [ 0.3531],\n",
      "        [ 0.4263],\n",
      "        [ 0.2536],\n",
      "        [ 0.3921],\n",
      "        [ 0.3059],\n",
      "        [ 0.3446],\n",
      "        [-0.3750],\n",
      "        [ 0.3207],\n",
      "        [ 0.3059],\n",
      "        [-0.2195],\n",
      "        [ 0.3771],\n",
      "        [ 0.1564],\n",
      "        [ 0.3627],\n",
      "        [ 0.5286],\n",
      "        [ 0.5123],\n",
      "        [-0.2421],\n",
      "        [ 0.3729],\n",
      "        [ 0.5352],\n",
      "        [ 0.5230],\n",
      "        [ 0.2886],\n",
      "        [ 0.4895],\n",
      "        [ 0.5728],\n",
      "        [ 0.4669],\n",
      "        [ 0.4399],\n",
      "        [-0.1245],\n",
      "        [ 0.4815],\n",
      "        [ 0.2473],\n",
      "        [ 0.3000],\n",
      "        [ 0.6607],\n",
      "        [ 0.4573],\n",
      "        [ 0.4871],\n",
      "        [ 0.2997],\n",
      "        [ 0.4792],\n",
      "        [-0.2428],\n",
      "        [ 0.5124],\n",
      "        [ 0.6545],\n",
      "        [ 0.4306],\n",
      "        [ 0.3490],\n",
      "        [ 0.4507],\n",
      "        [ 0.4282],\n",
      "        [ 0.4395],\n",
      "        [ 0.4317],\n",
      "        [ 0.7217],\n",
      "        [ 0.6108],\n",
      "        [-0.2141],\n",
      "        [ 0.5055],\n",
      "        [ 0.5761],\n",
      "        [ 0.4145],\n",
      "        [ 0.4182],\n",
      "        [ 0.4184],\n",
      "        [ 0.3494],\n",
      "        [ 0.4614],\n",
      "        [ 0.6944],\n",
      "        [ 0.5623],\n",
      "        [ 0.4915],\n",
      "        [ 0.5430],\n",
      "        [ 0.4797],\n",
      "        [ 0.4871],\n",
      "        [ 0.4667],\n",
      "        [ 0.1820],\n",
      "        [ 0.2313]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7484],\n",
      "        [ 0.8240],\n",
      "        [ 0.8156],\n",
      "        [-1.0000],\n",
      "        [ 0.8513],\n",
      "        [ 0.7706],\n",
      "        [ 0.7716],\n",
      "        [ 0.7947],\n",
      "        [-1.0000],\n",
      "        [ 0.8417],\n",
      "        [ 0.8217],\n",
      "        [ 0.7963],\n",
      "        [ 0.8054],\n",
      "        [ 0.8064],\n",
      "        [-1.0000],\n",
      "        [ 0.8085],\n",
      "        [ 0.7620],\n",
      "        [ 0.8226],\n",
      "        [ 0.8342],\n",
      "        [ 0.8072],\n",
      "        [ 0.8388],\n",
      "        [ 0.7731],\n",
      "        [ 0.8322],\n",
      "        [ 0.8012],\n",
      "        [ 0.8311],\n",
      "        [ 0.8317],\n",
      "        [ 0.8243],\n",
      "        [-1.0000],\n",
      "        [ 0.8184],\n",
      "        [-1.0000],\n",
      "        [ 0.8363],\n",
      "        [ 0.8174],\n",
      "        [ 0.8212],\n",
      "        [ 0.8399],\n",
      "        [-1.0000],\n",
      "        [ 0.8393],\n",
      "        [ 0.8201],\n",
      "        [ 0.8052],\n",
      "        [ 0.8283],\n",
      "        [ 0.8527],\n",
      "        [ 0.8036],\n",
      "        [ 0.8417],\n",
      "        [ 0.8113],\n",
      "        [ 0.7685],\n",
      "        [ 0.8378],\n",
      "        [ 0.8408],\n",
      "        [ 0.8328],\n",
      "        [-1.0000],\n",
      "        [ 0.8361],\n",
      "        [ 0.8432],\n",
      "        [ 0.8104],\n",
      "        [-1.0000],\n",
      "        [ 0.8452],\n",
      "        [ 0.8387],\n",
      "        [ 0.7633],\n",
      "        [ 0.8130],\n",
      "        [ 0.8442],\n",
      "        [ 0.8209],\n",
      "        [ 0.8136],\n",
      "        [ 0.8055],\n",
      "        [ 0.8421],\n",
      "        [ 0.8551],\n",
      "        [-1.0000],\n",
      "        [ 0.7614]], device='cuda:0'))\n",
      "{'loss': tensor(0.1975, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 111, 'agent.time_step': 1608, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 112, 'agent.time_step': 1616, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 113, 'agent.time_step': 1624, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 114, 'agent.time_step': 1633, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 115, 'agent.time_step': 1647, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 116, 'agent.time_step': 1655, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 117, 'agent.time_step': 1662, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 118, 'agent.time_step': 1669, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 119, 'agent.time_step': 1684, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 120, 'agent.time_step': 1692, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[-0.0452],\n",
      "        [ 0.2194],\n",
      "        [ 0.2218],\n",
      "        [ 0.1224],\n",
      "        [ 0.3101],\n",
      "        [ 0.1875],\n",
      "        [ 0.4016],\n",
      "        [ 0.3267],\n",
      "        [ 0.2723],\n",
      "        [ 0.2572],\n",
      "        [ 0.2736],\n",
      "        [-0.1682],\n",
      "        [ 0.2763],\n",
      "        [ 0.2306],\n",
      "        [ 0.2790],\n",
      "        [ 0.1169],\n",
      "        [ 0.2814],\n",
      "        [ 0.2285],\n",
      "        [ 0.2400],\n",
      "        [ 0.1882],\n",
      "        [ 0.2066],\n",
      "        [ 0.2255],\n",
      "        [ 0.1861],\n",
      "        [ 0.2508],\n",
      "        [ 0.3202],\n",
      "        [ 0.1588],\n",
      "        [ 0.1895],\n",
      "        [ 0.1192],\n",
      "        [ 0.1777],\n",
      "        [ 0.3127],\n",
      "        [ 0.2174],\n",
      "        [ 0.1631],\n",
      "        [ 0.2076],\n",
      "        [ 0.3054],\n",
      "        [ 0.2692],\n",
      "        [ 0.1647],\n",
      "        [ 0.2537],\n",
      "        [-0.1395],\n",
      "        [ 0.3492],\n",
      "        [ 0.2237],\n",
      "        [-0.0750],\n",
      "        [ 0.1686],\n",
      "        [ 0.1958],\n",
      "        [ 0.3142],\n",
      "        [ 0.3136],\n",
      "        [ 0.2861],\n",
      "        [ 0.1864],\n",
      "        [ 0.1969],\n",
      "        [ 0.2036],\n",
      "        [ 0.2107],\n",
      "        [ 0.2369],\n",
      "        [ 0.2797],\n",
      "        [ 0.2256],\n",
      "        [ 0.2790],\n",
      "        [ 0.2443],\n",
      "        [ 0.3355],\n",
      "        [ 0.1909],\n",
      "        [ 0.2481],\n",
      "        [ 0.2978],\n",
      "        [ 0.2736],\n",
      "        [ 0.2672],\n",
      "        [ 0.2045],\n",
      "        [ 0.2515],\n",
      "        [ 0.3062]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[-1.0000],\n",
      "        [ 0.8244],\n",
      "        [ 0.8333],\n",
      "        [-1.0000],\n",
      "        [ 0.8092],\n",
      "        [ 0.7825],\n",
      "        [ 0.7847],\n",
      "        [ 0.8301],\n",
      "        [ 0.7887],\n",
      "        [ 0.7720],\n",
      "        [ 0.8285],\n",
      "        [ 0.8449],\n",
      "        [ 0.8079],\n",
      "        [ 0.8501],\n",
      "        [ 0.7844],\n",
      "        [-1.0000],\n",
      "        [ 0.8485],\n",
      "        [ 0.8386],\n",
      "        [ 0.8242],\n",
      "        [-1.0000],\n",
      "        [ 0.8563],\n",
      "        [ 0.8222],\n",
      "        [ 0.8151],\n",
      "        [ 0.7786],\n",
      "        [ 0.8372],\n",
      "        [ 0.8261],\n",
      "        [ 0.8426],\n",
      "        [ 0.7650],\n",
      "        [ 0.8231],\n",
      "        [ 0.8457],\n",
      "        [ 0.7889],\n",
      "        [ 0.8473],\n",
      "        [ 0.7697],\n",
      "        [ 0.8067],\n",
      "        [ 0.8504],\n",
      "        [ 0.8266],\n",
      "        [ 0.8118],\n",
      "        [-1.0000],\n",
      "        [ 0.7617],\n",
      "        [ 0.8328],\n",
      "        [ 0.8271],\n",
      "        [ 0.8327],\n",
      "        [ 0.7782],\n",
      "        [ 0.7994],\n",
      "        [ 0.8389],\n",
      "        [-1.0000],\n",
      "        [ 0.7639],\n",
      "        [ 0.8422],\n",
      "        [ 0.8239],\n",
      "        [ 0.8412],\n",
      "        [-1.0000],\n",
      "        [ 0.7836],\n",
      "        [-1.0000],\n",
      "        [ 0.7712],\n",
      "        [ 0.8587],\n",
      "        [ 0.8438],\n",
      "        [ 0.8340],\n",
      "        [ 0.7975],\n",
      "        [ 0.7981],\n",
      "        [ 0.8334],\n",
      "        [ 0.8489],\n",
      "        [ 0.8042],\n",
      "        [ 0.8415],\n",
      "        [ 0.7600]], device='cuda:0'))\n",
      "{'loss': tensor(0.2310, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 121, 'agent.time_step': 1703, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 122, 'agent.time_step': 1711, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 123, 'agent.time_step': 1721, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 124, 'agent.time_step': 1733, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 125, 'agent.time_step': 1741, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 126, 'agent.time_step': 1748, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 127, 'agent.time_step': 1758, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 128, 'agent.time_step': 1766, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 129, 'agent.time_step': 1778, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 130, 'agent.time_step': 1796, 'rounds': 18, 'accumulate_reward': 16.0}\n",
      "(q_current, q_targets): (tensor([[ 0.8046],\n",
      "        [ 0.2192],\n",
      "        [ 0.2836],\n",
      "        [ 0.3660],\n",
      "        [ 0.2327],\n",
      "        [ 0.3187],\n",
      "        [ 0.3946],\n",
      "        [ 0.2703],\n",
      "        [ 0.4015],\n",
      "        [ 0.2501],\n",
      "        [-0.1222],\n",
      "        [ 0.2123],\n",
      "        [ 0.2693],\n",
      "        [ 0.5968],\n",
      "        [ 0.2326],\n",
      "        [ 0.5651],\n",
      "        [ 0.6889],\n",
      "        [ 0.3207],\n",
      "        [ 0.8642],\n",
      "        [ 0.2936],\n",
      "        [ 0.3055],\n",
      "        [ 0.2771],\n",
      "        [ 0.5456],\n",
      "        [ 0.2929],\n",
      "        [ 0.2584],\n",
      "        [-0.1000],\n",
      "        [-0.1048],\n",
      "        [ 0.3191],\n",
      "        [ 0.2844],\n",
      "        [ 0.3288],\n",
      "        [ 0.2588],\n",
      "        [ 0.2236],\n",
      "        [ 0.3114],\n",
      "        [ 0.3790],\n",
      "        [ 0.2619],\n",
      "        [ 0.1732],\n",
      "        [ 0.2635],\n",
      "        [ 0.2605],\n",
      "        [-0.1036],\n",
      "        [-0.1128],\n",
      "        [-0.1054],\n",
      "        [ 0.2118],\n",
      "        [ 0.3109],\n",
      "        [-0.1082],\n",
      "        [ 0.3075],\n",
      "        [ 0.2356],\n",
      "        [ 0.2589],\n",
      "        [ 0.5179],\n",
      "        [ 0.2525],\n",
      "        [-0.1219],\n",
      "        [ 0.3308],\n",
      "        [ 0.2930],\n",
      "        [ 0.3044],\n",
      "        [ 0.2906],\n",
      "        [ 0.2755],\n",
      "        [ 0.2816],\n",
      "        [ 0.2468],\n",
      "        [ 0.2544],\n",
      "        [ 0.2900],\n",
      "        [-0.1046],\n",
      "        [ 0.3547],\n",
      "        [-0.1092],\n",
      "        [ 0.2682],\n",
      "        [ 0.2419]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8029],\n",
      "        [ 0.8488],\n",
      "        [ 0.8727],\n",
      "        [ 0.8300],\n",
      "        [ 0.8641],\n",
      "        [-1.0000],\n",
      "        [ 0.7330],\n",
      "        [ 0.8183],\n",
      "        [ 0.8154],\n",
      "        [ 0.7903],\n",
      "        [-1.0000],\n",
      "        [ 0.7823],\n",
      "        [ 0.8367],\n",
      "        [ 0.7461],\n",
      "        [ 0.8050],\n",
      "        [-1.0000],\n",
      "        [ 0.8423],\n",
      "        [ 0.8181],\n",
      "        [ 0.8541],\n",
      "        [ 0.7874],\n",
      "        [ 0.8564],\n",
      "        [ 0.8222],\n",
      "        [ 0.7585],\n",
      "        [ 0.7681],\n",
      "        [ 0.7738],\n",
      "        [ 0.8435],\n",
      "        [ 0.7901],\n",
      "        [ 0.7980],\n",
      "        [-1.0000],\n",
      "        [ 0.8491],\n",
      "        [ 0.8122],\n",
      "        [ 0.7922],\n",
      "        [ 0.8333],\n",
      "        [ 0.8362],\n",
      "        [ 0.7741],\n",
      "        [ 0.7411],\n",
      "        [ 0.7939],\n",
      "        [ 0.8380],\n",
      "        [ 0.8281],\n",
      "        [ 0.8443],\n",
      "        [ 0.8074],\n",
      "        [ 0.7729],\n",
      "        [ 0.8458],\n",
      "        [ 0.8219],\n",
      "        [ 0.8059],\n",
      "        [ 0.8374],\n",
      "        [ 0.8165],\n",
      "        [ 0.8450],\n",
      "        [ 0.8334],\n",
      "        [ 0.8420],\n",
      "        [ 0.7749],\n",
      "        [ 0.8192],\n",
      "        [ 0.8364],\n",
      "        [ 0.8081],\n",
      "        [-1.0000],\n",
      "        [ 0.8203],\n",
      "        [ 0.8171],\n",
      "        [ 0.8447],\n",
      "        [ 0.7932],\n",
      "        [ 0.8309],\n",
      "        [ 0.8288],\n",
      "        [ 0.8087],\n",
      "        [-1.0000],\n",
      "        [ 0.7941]], device='cuda:0'))\n",
      "{'loss': tensor(0.2301, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 131, 'agent.time_step': 1811, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 132, 'agent.time_step': 1822, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 133, 'agent.time_step': 1830, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 134, 'agent.time_step': 1840, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 135, 'agent.time_step': 1846, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 136, 'agent.time_step': 1856, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 137, 'agent.time_step': 1871, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 138, 'agent.time_step': 1881, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 139, 'agent.time_step': 1894, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 140, 'agent.time_step': 1908, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "(q_current, q_targets): (tensor([[ 0.5747],\n",
      "        [-0.0788],\n",
      "        [ 0.4030],\n",
      "        [ 0.7709],\n",
      "        [ 0.5096],\n",
      "        [ 0.5586],\n",
      "        [ 0.6107],\n",
      "        [ 0.4798],\n",
      "        [ 0.4782],\n",
      "        [ 0.5419],\n",
      "        [ 0.4801],\n",
      "        [ 3.3115],\n",
      "        [ 0.6322],\n",
      "        [-0.0816],\n",
      "        [ 0.5868],\n",
      "        [ 0.4297],\n",
      "        [ 0.5816],\n",
      "        [ 0.4829],\n",
      "        [ 1.7346],\n",
      "        [ 0.4781],\n",
      "        [ 1.1217],\n",
      "        [-0.0629],\n",
      "        [ 0.5248],\n",
      "        [ 0.5187],\n",
      "        [ 1.2808],\n",
      "        [ 0.4834],\n",
      "        [ 0.4862],\n",
      "        [ 0.7357],\n",
      "        [ 0.6134],\n",
      "        [ 0.4688],\n",
      "        [ 0.5933],\n",
      "        [ 0.9876],\n",
      "        [ 0.5428],\n",
      "        [ 0.8288],\n",
      "        [ 0.4748],\n",
      "        [ 2.3894],\n",
      "        [ 0.5444],\n",
      "        [ 0.6138],\n",
      "        [-0.0787],\n",
      "        [-0.1378],\n",
      "        [ 0.5781],\n",
      "        [ 1.6954],\n",
      "        [ 0.4774],\n",
      "        [ 1.3189],\n",
      "        [ 0.4782],\n",
      "        [ 1.3355],\n",
      "        [ 0.5590],\n",
      "        [ 0.5088],\n",
      "        [ 0.5637],\n",
      "        [ 0.5315],\n",
      "        [ 0.5508],\n",
      "        [ 0.7051],\n",
      "        [-0.0739],\n",
      "        [ 0.9176],\n",
      "        [ 0.5202],\n",
      "        [ 1.3355],\n",
      "        [ 0.4832],\n",
      "        [ 0.5431],\n",
      "        [ 2.4705],\n",
      "        [ 1.1351],\n",
      "        [ 0.5012],\n",
      "        [ 0.4679],\n",
      "        [ 0.5173],\n",
      "        [-0.0850]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8324],\n",
      "        [ 0.8263],\n",
      "        [-1.0000],\n",
      "        [ 0.8462],\n",
      "        [ 0.8428],\n",
      "        [ 0.8278],\n",
      "        [ 0.8319],\n",
      "        [ 0.8152],\n",
      "        [ 0.8124],\n",
      "        [ 0.8200],\n",
      "        [ 0.8312],\n",
      "        [ 0.8511],\n",
      "        [ 0.8317],\n",
      "        [ 0.8282],\n",
      "        [ 0.8511],\n",
      "        [ 0.8198],\n",
      "        [ 0.8283],\n",
      "        [ 0.8203],\n",
      "        [ 0.7602],\n",
      "        [ 0.8321],\n",
      "        [ 0.8481],\n",
      "        [ 0.7871],\n",
      "        [ 0.8417],\n",
      "        [ 0.7837],\n",
      "        [ 0.7565],\n",
      "        [ 0.8151],\n",
      "        [-1.0000],\n",
      "        [ 0.8026],\n",
      "        [ 0.8126],\n",
      "        [ 0.7830],\n",
      "        [ 0.7974],\n",
      "        [ 0.8410],\n",
      "        [ 0.8389],\n",
      "        [ 0.8297],\n",
      "        [ 0.8339],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.8409],\n",
      "        [ 0.8403],\n",
      "        [ 0.8538],\n",
      "        [ 0.8465],\n",
      "        [ 0.7907],\n",
      "        [ 0.8539],\n",
      "        [ 0.8052],\n",
      "        [ 0.8192],\n",
      "        [ 0.8381],\n",
      "        [ 0.8330],\n",
      "        [ 0.8372],\n",
      "        [ 0.7613],\n",
      "        [ 0.8474],\n",
      "        [ 0.8210],\n",
      "        [ 0.7532],\n",
      "        [ 0.8315],\n",
      "        [ 0.7867],\n",
      "        [ 0.7629],\n",
      "        [ 0.8405],\n",
      "        [ 0.7869],\n",
      "        [ 0.7720],\n",
      "        [-1.0000],\n",
      "        [ 0.8463],\n",
      "        [ 0.7616],\n",
      "        [ 0.8422],\n",
      "        [ 0.7743],\n",
      "        [ 0.8154]], device='cuda:0'))\n",
      "{'loss': tensor(0.2622, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 141, 'agent.time_step': 1926, 'rounds': 18, 'accumulate_reward': 16.0}\n",
      "{'episode': 142, 'agent.time_step': 1934, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 143, 'agent.time_step': 1945, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 144, 'agent.time_step': 1953, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 145, 'agent.time_step': 1960, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 146, 'agent.time_step': 1967, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 147, 'agent.time_step': 1978, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 148, 'agent.time_step': 1990, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 149, 'agent.time_step': 2003, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 150, 'agent.time_step': 2012, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "(q_current, q_targets): (tensor([[ 0.7288],\n",
      "        [ 0.9384],\n",
      "        [ 0.7895],\n",
      "        [-0.0141],\n",
      "        [ 0.8237],\n",
      "        [ 0.9989],\n",
      "        [ 0.8577],\n",
      "        [ 0.8359],\n",
      "        [ 0.8098],\n",
      "        [ 1.0049],\n",
      "        [-0.0096],\n",
      "        [ 2.0149],\n",
      "        [ 0.7959],\n",
      "        [ 0.8340],\n",
      "        [ 0.8998],\n",
      "        [ 0.9428],\n",
      "        [ 0.4908],\n",
      "        [ 0.7253],\n",
      "        [-0.0315],\n",
      "        [ 0.8927],\n",
      "        [ 0.8501],\n",
      "        [-0.0096],\n",
      "        [ 0.8972],\n",
      "        [ 0.7819],\n",
      "        [-0.0122],\n",
      "        [ 0.8165],\n",
      "        [ 0.7385],\n",
      "        [ 0.8140],\n",
      "        [ 0.8856],\n",
      "        [ 0.7953],\n",
      "        [ 0.7088],\n",
      "        [ 0.7763],\n",
      "        [ 1.0505],\n",
      "        [ 0.8331],\n",
      "        [ 0.8165],\n",
      "        [ 0.7895],\n",
      "        [ 0.8183],\n",
      "        [ 0.8445],\n",
      "        [ 0.8007],\n",
      "        [-0.0195],\n",
      "        [ 0.7552],\n",
      "        [ 0.1640],\n",
      "        [ 0.6606],\n",
      "        [ 0.8294],\n",
      "        [ 0.7414],\n",
      "        [ 0.8007],\n",
      "        [ 0.7881],\n",
      "        [ 0.6686],\n",
      "        [ 1.0156],\n",
      "        [-0.0082],\n",
      "        [ 0.7826],\n",
      "        [ 0.8319],\n",
      "        [ 0.9109],\n",
      "        [ 0.7476],\n",
      "        [ 0.9317],\n",
      "        [-0.0859],\n",
      "        [-0.0127],\n",
      "        [ 0.8495],\n",
      "        [ 0.8465],\n",
      "        [ 0.7904],\n",
      "        [-0.0137],\n",
      "        [ 0.8409],\n",
      "        [ 0.9415],\n",
      "        [ 0.7416]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8064],\n",
      "        [ 0.7988],\n",
      "        [ 0.8346],\n",
      "        [-1.0000],\n",
      "        [ 0.8089],\n",
      "        [ 0.8397],\n",
      "        [ 0.8451],\n",
      "        [ 0.8395],\n",
      "        [ 0.8265],\n",
      "        [ 0.8392],\n",
      "        [ 0.7712],\n",
      "        [ 0.7287],\n",
      "        [ 0.8059],\n",
      "        [ 0.7904],\n",
      "        [ 0.7468],\n",
      "        [ 0.8190],\n",
      "        [ 0.7734],\n",
      "        [ 0.8218],\n",
      "        [ 0.8159],\n",
      "        [ 0.7367],\n",
      "        [ 0.7980],\n",
      "        [ 0.8453],\n",
      "        [ 0.8251],\n",
      "        [ 0.7991],\n",
      "        [ 0.8316],\n",
      "        [ 0.8072],\n",
      "        [ 0.8109],\n",
      "        [ 0.8256],\n",
      "        [ 0.8337],\n",
      "        [ 0.8211],\n",
      "        [-1.0000],\n",
      "        [ 0.8241],\n",
      "        [ 0.7652],\n",
      "        [ 0.8057],\n",
      "        [ 0.7928],\n",
      "        [ 0.8436],\n",
      "        [-1.0000],\n",
      "        [ 0.8556],\n",
      "        [ 0.8402],\n",
      "        [ 0.8466],\n",
      "        [ 0.8136],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.8033],\n",
      "        [ 0.8142],\n",
      "        [ 0.8414],\n",
      "        [ 0.8008],\n",
      "        [-1.0000],\n",
      "        [ 0.8405],\n",
      "        [ 0.8121],\n",
      "        [-1.0000],\n",
      "        [ 0.8403],\n",
      "        [ 0.8496],\n",
      "        [ 0.8040],\n",
      "        [ 0.8484],\n",
      "        [ 0.8446],\n",
      "        [ 0.8336],\n",
      "        [ 0.8426],\n",
      "        [ 0.8253],\n",
      "        [ 0.8291],\n",
      "        [ 0.8382],\n",
      "        [ 0.8435],\n",
      "        [ 0.8520],\n",
      "        [ 0.8506]], device='cuda:0'))\n",
      "{'loss': tensor(0.1802, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 151, 'agent.time_step': 2026, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 152, 'agent.time_step': 2036, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 153, 'agent.time_step': 2048, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 154, 'agent.time_step': 2058, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 155, 'agent.time_step': 2068, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 156, 'agent.time_step': 2076, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 157, 'agent.time_step': 2087, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 158, 'agent.time_step': 2099, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 159, 'agent.time_step': 2111, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 160, 'agent.time_step': 2117, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "(q_current, q_targets): (tensor([[1.0384],\n",
      "        [0.9581],\n",
      "        [1.0405],\n",
      "        [1.0926],\n",
      "        [0.9917],\n",
      "        [1.0048],\n",
      "        [1.0125],\n",
      "        [0.8148],\n",
      "        [1.0417],\n",
      "        [0.9684],\n",
      "        [1.0003],\n",
      "        [1.0265],\n",
      "        [0.8986],\n",
      "        [1.0584],\n",
      "        [0.4444],\n",
      "        [1.0920],\n",
      "        [1.0342],\n",
      "        [0.0923],\n",
      "        [0.6342],\n",
      "        [0.7696],\n",
      "        [0.8899],\n",
      "        [0.7630],\n",
      "        [1.0810],\n",
      "        [1.0854],\n",
      "        [1.0318],\n",
      "        [1.0337],\n",
      "        [0.5000],\n",
      "        [0.5868],\n",
      "        [0.9621],\n",
      "        [0.9885],\n",
      "        [0.9829],\n",
      "        [1.1583],\n",
      "        [1.0665],\n",
      "        [1.0038],\n",
      "        [1.0342],\n",
      "        [0.7164],\n",
      "        [0.9704],\n",
      "        [1.0567],\n",
      "        [1.0229],\n",
      "        [0.8741],\n",
      "        [1.0240],\n",
      "        [0.8383],\n",
      "        [0.9684],\n",
      "        [0.9570],\n",
      "        [0.9973],\n",
      "        [1.0761],\n",
      "        [0.9891],\n",
      "        [1.1023],\n",
      "        [0.9666],\n",
      "        [0.5518],\n",
      "        [0.9258],\n",
      "        [0.8654],\n",
      "        [0.9275],\n",
      "        [1.0417],\n",
      "        [0.9809],\n",
      "        [0.7919],\n",
      "        [1.1720],\n",
      "        [0.1026],\n",
      "        [0.1058],\n",
      "        [0.9391],\n",
      "        [0.0941],\n",
      "        [1.0214],\n",
      "        [0.9635],\n",
      "        [1.0053]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 1.0100],\n",
      "        [ 0.9800],\n",
      "        [ 0.9853],\n",
      "        [ 0.9951],\n",
      "        [ 0.9938],\n",
      "        [ 0.9863],\n",
      "        [ 0.9875],\n",
      "        [ 0.9340],\n",
      "        [ 0.9333],\n",
      "        [-1.0000],\n",
      "        [ 0.9939],\n",
      "        [ 0.9361],\n",
      "        [ 0.9854],\n",
      "        [ 1.0188],\n",
      "        [ 0.9415],\n",
      "        [ 1.0000],\n",
      "        [ 0.9290],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.9849],\n",
      "        [ 0.9879],\n",
      "        [ 0.9597],\n",
      "        [ 1.0048],\n",
      "        [ 0.9910],\n",
      "        [ 0.9756],\n",
      "        [ 0.9882],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.9812],\n",
      "        [ 0.9841],\n",
      "        [-1.0000],\n",
      "        [ 0.9942],\n",
      "        [ 1.0039],\n",
      "        [ 0.9797],\n",
      "        [ 0.9320],\n",
      "        [-1.0000],\n",
      "        [ 1.0150],\n",
      "        [ 1.0015],\n",
      "        [ 0.9696],\n",
      "        [ 0.9821],\n",
      "        [ 0.9786],\n",
      "        [ 0.9619],\n",
      "        [ 1.0130],\n",
      "        [ 0.9288],\n",
      "        [ 0.9380],\n",
      "        [ 0.9952],\n",
      "        [ 1.0114],\n",
      "        [ 0.9911],\n",
      "        [ 0.9982],\n",
      "        [ 0.9325],\n",
      "        [ 1.0119],\n",
      "        [ 1.0175],\n",
      "        [ 0.9878],\n",
      "        [ 1.0070],\n",
      "        [ 0.9950],\n",
      "        [-1.0000],\n",
      "        [ 1.0023],\n",
      "        [ 0.9670],\n",
      "        [ 0.9638],\n",
      "        [ 0.9757],\n",
      "        [ 0.9515],\n",
      "        [ 1.0131],\n",
      "        [ 1.0094],\n",
      "        [ 0.9211]], device='cuda:0'))\n",
      "{'loss': tensor(0.1682, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 161, 'agent.time_step': 2124, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 162, 'agent.time_step': 2132, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 163, 'agent.time_step': 2143, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 164, 'agent.time_step': 2156, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 165, 'agent.time_step': 2164, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 166, 'agent.time_step': 2170, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 167, 'agent.time_step': 2184, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 168, 'agent.time_step': 2198, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 169, 'agent.time_step': 2206, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 170, 'agent.time_step': 2213, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "(q_current, q_targets): (tensor([[ 0.9916],\n",
      "        [ 0.8724],\n",
      "        [ 0.9381],\n",
      "        [ 0.9081],\n",
      "        [ 0.8781],\n",
      "        [ 0.6849],\n",
      "        [ 0.9504],\n",
      "        [ 0.0612],\n",
      "        [ 0.8871],\n",
      "        [ 0.9919],\n",
      "        [ 0.1692],\n",
      "        [ 1.0778],\n",
      "        [ 0.1979],\n",
      "        [ 0.9032],\n",
      "        [ 1.0974],\n",
      "        [ 1.0321],\n",
      "        [ 0.1852],\n",
      "        [ 0.9307],\n",
      "        [ 0.1838],\n",
      "        [ 0.9043],\n",
      "        [ 1.1071],\n",
      "        [ 0.2097],\n",
      "        [ 0.1879],\n",
      "        [ 0.1936],\n",
      "        [ 0.9126],\n",
      "        [ 0.9701],\n",
      "        [ 0.9846],\n",
      "        [ 0.9982],\n",
      "        [ 1.0187],\n",
      "        [ 0.8045],\n",
      "        [ 1.0231],\n",
      "        [ 0.1837],\n",
      "        [ 1.0375],\n",
      "        [ 0.9773],\n",
      "        [ 0.6200],\n",
      "        [ 0.8910],\n",
      "        [ 0.9847],\n",
      "        [ 1.0030],\n",
      "        [-0.0167],\n",
      "        [ 0.1793],\n",
      "        [ 0.9156],\n",
      "        [ 0.9559],\n",
      "        [ 0.9546],\n",
      "        [ 0.1780],\n",
      "        [ 1.1672],\n",
      "        [ 0.8752],\n",
      "        [ 0.9828],\n",
      "        [ 0.9533],\n",
      "        [ 0.9505],\n",
      "        [ 0.2201],\n",
      "        [ 0.9688],\n",
      "        [ 0.9747],\n",
      "        [ 0.9040],\n",
      "        [ 1.0235],\n",
      "        [ 0.9395],\n",
      "        [ 0.9620],\n",
      "        [ 0.1930],\n",
      "        [ 0.9932],\n",
      "        [ 1.0280],\n",
      "        [ 0.9950],\n",
      "        [ 0.9540],\n",
      "        [ 0.9809],\n",
      "        [ 1.0725],\n",
      "        [ 0.9520]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.9993],\n",
      "        [ 0.9943],\n",
      "        [ 1.0130],\n",
      "        [-1.0000],\n",
      "        [ 1.0011],\n",
      "        [ 0.9529],\n",
      "        [ 0.9560],\n",
      "        [-1.0000],\n",
      "        [ 1.0003],\n",
      "        [ 0.9914],\n",
      "        [-1.0000],\n",
      "        [ 0.9980],\n",
      "        [ 0.9871],\n",
      "        [ 1.0006],\n",
      "        [ 0.9797],\n",
      "        [ 0.9883],\n",
      "        [ 0.9762],\n",
      "        [ 0.9535],\n",
      "        [ 0.9908],\n",
      "        [ 0.9898],\n",
      "        [ 0.9788],\n",
      "        [-1.0000],\n",
      "        [ 0.9914],\n",
      "        [ 0.9697],\n",
      "        [ 0.9923],\n",
      "        [ 0.9640],\n",
      "        [ 0.9558],\n",
      "        [ 1.0010],\n",
      "        [ 1.0001],\n",
      "        [ 0.9898],\n",
      "        [ 0.9980],\n",
      "        [ 0.9578],\n",
      "        [ 1.0005],\n",
      "        [ 0.9710],\n",
      "        [ 0.9688],\n",
      "        [ 0.9757],\n",
      "        [ 1.0138],\n",
      "        [ 0.9822],\n",
      "        [-1.0000],\n",
      "        [ 0.9805],\n",
      "        [ 0.9935],\n",
      "        [-1.0000],\n",
      "        [ 0.9865],\n",
      "        [-1.0000],\n",
      "        [ 0.9644],\n",
      "        [ 0.9909],\n",
      "        [ 1.0090],\n",
      "        [ 0.9545],\n",
      "        [ 0.9552],\n",
      "        [ 0.9807],\n",
      "        [ 0.9800],\n",
      "        [ 0.9905],\n",
      "        [ 1.0092],\n",
      "        [ 0.9975],\n",
      "        [-1.0000],\n",
      "        [ 0.9908],\n",
      "        [ 1.0030],\n",
      "        [ 0.9925],\n",
      "        [ 0.9970],\n",
      "        [ 0.9882],\n",
      "        [ 0.9852],\n",
      "        [ 0.9696],\n",
      "        [ 0.9947],\n",
      "        [ 0.9807]], device='cuda:0'))\n",
      "{'loss': tensor(0.1630, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 171, 'agent.time_step': 2221, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 172, 'agent.time_step': 2235, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 173, 'agent.time_step': 2244, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 174, 'agent.time_step': 2253, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 175, 'agent.time_step': 2282, 'rounds': 29, 'accumulate_reward': 27.0}\n",
      "{'episode': 176, 'agent.time_step': 2294, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 177, 'agent.time_step': 2306, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 178, 'agent.time_step': 2312, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 179, 'agent.time_step': 2327, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 180, 'agent.time_step': 2334, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "(q_current, q_targets): (tensor([[0.9067],\n",
      "        [0.7035],\n",
      "        [0.3071],\n",
      "        [0.3083],\n",
      "        [0.8285],\n",
      "        [0.1610],\n",
      "        [0.3112],\n",
      "        [0.8844],\n",
      "        [0.8520],\n",
      "        [0.8488],\n",
      "        [0.8748],\n",
      "        [0.9461],\n",
      "        [0.8505],\n",
      "        [0.2980],\n",
      "        [0.9247],\n",
      "        [0.3196],\n",
      "        [0.3189],\n",
      "        [0.9764],\n",
      "        [0.9042],\n",
      "        [0.8872],\n",
      "        [0.8499],\n",
      "        [0.7142],\n",
      "        [0.8397],\n",
      "        [0.8436],\n",
      "        [0.8812],\n",
      "        [0.8973],\n",
      "        [0.8364],\n",
      "        [0.9256],\n",
      "        [0.8914],\n",
      "        [0.8584],\n",
      "        [0.8828],\n",
      "        [0.9029],\n",
      "        [0.8500],\n",
      "        [0.8530],\n",
      "        [0.9364],\n",
      "        [0.8440],\n",
      "        [0.9608],\n",
      "        [0.1112],\n",
      "        [0.5935],\n",
      "        [0.3132],\n",
      "        [0.8779],\n",
      "        [0.8638],\n",
      "        [0.9267],\n",
      "        [0.9099],\n",
      "        [0.9263],\n",
      "        [0.8628],\n",
      "        [0.2959],\n",
      "        [0.8980],\n",
      "        [0.8513],\n",
      "        [0.8760],\n",
      "        [0.9562],\n",
      "        [0.9964],\n",
      "        [1.0609],\n",
      "        [0.8626],\n",
      "        [0.4834],\n",
      "        [0.5469],\n",
      "        [0.8585],\n",
      "        [0.9031],\n",
      "        [0.9082],\n",
      "        [0.7337],\n",
      "        [0.3385],\n",
      "        [0.9646],\n",
      "        [0.8571],\n",
      "        [0.9004]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.9777],\n",
      "        [ 0.8761],\n",
      "        [ 0.9789],\n",
      "        [ 0.9524],\n",
      "        [ 0.9888],\n",
      "        [ 0.9200],\n",
      "        [ 0.9503],\n",
      "        [ 0.9980],\n",
      "        [ 0.9641],\n",
      "        [ 0.9951],\n",
      "        [ 1.0158],\n",
      "        [ 0.9563],\n",
      "        [ 0.9531],\n",
      "        [ 0.9700],\n",
      "        [ 0.9663],\n",
      "        [ 0.9542],\n",
      "        [-1.0000],\n",
      "        [ 0.9736],\n",
      "        [ 0.9642],\n",
      "        [ 0.9899],\n",
      "        [ 0.9435],\n",
      "        [ 0.9376],\n",
      "        [ 0.9563],\n",
      "        [ 0.9808],\n",
      "        [ 1.0111],\n",
      "        [ 0.9594],\n",
      "        [ 0.9916],\n",
      "        [ 0.9865],\n",
      "        [ 0.9740],\n",
      "        [ 0.9628],\n",
      "        [ 0.9555],\n",
      "        [ 0.9619],\n",
      "        [ 0.9756],\n",
      "        [ 0.9538],\n",
      "        [ 0.9746],\n",
      "        [ 0.9911],\n",
      "        [ 0.9904],\n",
      "        [ 0.9093],\n",
      "        [ 0.9077],\n",
      "        [ 0.9553],\n",
      "        [ 1.0122],\n",
      "        [ 0.9179],\n",
      "        [ 0.9948],\n",
      "        [ 0.9733],\n",
      "        [ 0.9971],\n",
      "        [ 0.9547],\n",
      "        [ 0.9889],\n",
      "        [ 0.9553],\n",
      "        [ 0.9082],\n",
      "        [-1.0000],\n",
      "        [ 0.9730],\n",
      "        [ 0.9828],\n",
      "        [ 0.9988],\n",
      "        [ 0.9403],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 1.0139],\n",
      "        [ 0.9927],\n",
      "        [ 0.9933],\n",
      "        [-1.0000],\n",
      "        [ 0.9929],\n",
      "        [ 0.9887],\n",
      "        [ 0.9639],\n",
      "        [ 0.9633]], device='cuda:0'))\n",
      "{'loss': tensor(0.1263, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 181, 'agent.time_step': 2347, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 182, 'agent.time_step': 2363, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 183, 'agent.time_step': 2374, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 184, 'agent.time_step': 2385, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 185, 'agent.time_step': 2406, 'rounds': 21, 'accumulate_reward': 19.0}\n",
      "{'episode': 186, 'agent.time_step': 2420, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 187, 'agent.time_step': 2429, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 188, 'agent.time_step': 2441, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 189, 'agent.time_step': 2450, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 190, 'agent.time_step': 2466, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "(q_current, q_targets): (tensor([[ 0.9248],\n",
      "        [ 0.9182],\n",
      "        [ 0.9037],\n",
      "        [ 0.3914],\n",
      "        [ 0.9355],\n",
      "        [ 0.9172],\n",
      "        [ 0.3892],\n",
      "        [ 0.7510],\n",
      "        [ 0.9652],\n",
      "        [ 0.8845],\n",
      "        [ 0.7430],\n",
      "        [ 0.9248],\n",
      "        [ 0.5840],\n",
      "        [ 0.9211],\n",
      "        [ 0.9153],\n",
      "        [ 0.8888],\n",
      "        [ 0.9320],\n",
      "        [ 0.9950],\n",
      "        [ 0.8942],\n",
      "        [ 0.9118],\n",
      "        [ 0.8654],\n",
      "        [ 0.9192],\n",
      "        [ 0.3227],\n",
      "        [ 0.8172],\n",
      "        [ 0.9172],\n",
      "        [ 0.9945],\n",
      "        [-0.1266],\n",
      "        [ 0.9902],\n",
      "        [ 1.0353],\n",
      "        [ 0.8839],\n",
      "        [ 1.0450],\n",
      "        [ 0.9549],\n",
      "        [ 0.8398],\n",
      "        [ 0.9172],\n",
      "        [ 0.9439],\n",
      "        [ 0.9109],\n",
      "        [ 0.9174],\n",
      "        [ 1.0166],\n",
      "        [ 0.9060],\n",
      "        [ 0.4031],\n",
      "        [ 1.0072],\n",
      "        [ 0.7367],\n",
      "        [ 0.9742],\n",
      "        [ 0.9259],\n",
      "        [ 0.9063],\n",
      "        [ 0.9244],\n",
      "        [ 0.7646],\n",
      "        [ 0.8603],\n",
      "        [-0.1363],\n",
      "        [ 0.9455],\n",
      "        [ 0.9123],\n",
      "        [ 0.6069],\n",
      "        [ 0.9024],\n",
      "        [ 0.9429],\n",
      "        [ 0.8929],\n",
      "        [ 0.7329],\n",
      "        [ 0.9087],\n",
      "        [ 0.9352],\n",
      "        [ 0.5798],\n",
      "        [ 0.6651],\n",
      "        [ 0.8907],\n",
      "        [ 1.0420],\n",
      "        [ 0.9526],\n",
      "        [ 0.9192]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.9875],\n",
      "        [ 0.9465],\n",
      "        [ 0.9607],\n",
      "        [-1.0000],\n",
      "        [ 0.9658],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.9360],\n",
      "        [ 0.9312],\n",
      "        [ 0.9391],\n",
      "        [ 0.9346],\n",
      "        [ 0.9701],\n",
      "        [ 0.9669],\n",
      "        [ 0.9598],\n",
      "        [ 0.9407],\n",
      "        [ 0.9694],\n",
      "        [ 0.9772],\n",
      "        [ 0.9353],\n",
      "        [ 0.9570],\n",
      "        [ 0.9645],\n",
      "        [-1.0000],\n",
      "        [ 0.9721],\n",
      "        [-1.0000],\n",
      "        [ 0.9468],\n",
      "        [ 0.9352],\n",
      "        [ 0.9493],\n",
      "        [ 0.9236],\n",
      "        [ 0.9924],\n",
      "        [ 0.9133],\n",
      "        [ 0.9685],\n",
      "        [ 0.9960],\n",
      "        [ 0.9838],\n",
      "        [ 0.9405],\n",
      "        [ 0.9557],\n",
      "        [ 0.9798],\n",
      "        [ 0.9697],\n",
      "        [ 0.9517],\n",
      "        [ 0.9393],\n",
      "        [ 0.9296],\n",
      "        [ 0.9255],\n",
      "        [ 0.9103],\n",
      "        [ 1.0227],\n",
      "        [ 0.9457],\n",
      "        [ 0.9408],\n",
      "        [ 0.9816],\n",
      "        [ 0.9867],\n",
      "        [ 0.9482],\n",
      "        [ 0.9412],\n",
      "        [ 0.9294],\n",
      "        [ 0.9798],\n",
      "        [ 0.9695],\n",
      "        [ 0.9966],\n",
      "        [ 0.9320],\n",
      "        [ 0.9564],\n",
      "        [ 1.0109],\n",
      "        [ 0.9511],\n",
      "        [ 0.9786],\n",
      "        [ 0.9746],\n",
      "        [ 0.9204],\n",
      "        [ 0.9913],\n",
      "        [ 0.9767],\n",
      "        [ 0.9743],\n",
      "        [ 0.9899],\n",
      "        [ 0.9687]], device='cuda:0'))\n",
      "{'loss': tensor(0.1110, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 191, 'agent.time_step': 2476, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 192, 'agent.time_step': 2485, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 193, 'agent.time_step': 2496, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 194, 'agent.time_step': 2505, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 195, 'agent.time_step': 2512, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 196, 'agent.time_step': 2521, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 197, 'agent.time_step': 2541, 'rounds': 20, 'accumulate_reward': 18.0}\n",
      "{'episode': 198, 'agent.time_step': 2552, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 199, 'agent.time_step': 2564, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 200, 'agent.time_step': 2576, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "(q_current, q_targets): (tensor([[0.9768],\n",
      "        [0.9521],\n",
      "        [0.9748],\n",
      "        [0.9661],\n",
      "        [0.5138],\n",
      "        [0.9913],\n",
      "        [1.0133],\n",
      "        [0.9024],\n",
      "        [0.9884],\n",
      "        [0.9384],\n",
      "        [0.9787],\n",
      "        [0.9493],\n",
      "        [1.0115],\n",
      "        [0.3687],\n",
      "        [0.9552],\n",
      "        [0.9207],\n",
      "        [0.9478],\n",
      "        [0.9746],\n",
      "        [0.9687],\n",
      "        [0.9542],\n",
      "        [0.7381],\n",
      "        [0.9862],\n",
      "        [1.0903],\n",
      "        [0.9606],\n",
      "        [0.9660],\n",
      "        [0.9532],\n",
      "        [0.7625],\n",
      "        [0.9935],\n",
      "        [0.9797],\n",
      "        [0.9295],\n",
      "        [1.1072],\n",
      "        [0.9525],\n",
      "        [0.9558],\n",
      "        [0.9334],\n",
      "        [0.9750],\n",
      "        [0.8688],\n",
      "        [0.9517],\n",
      "        [0.3173],\n",
      "        [0.9532],\n",
      "        [0.9777],\n",
      "        [0.6071],\n",
      "        [0.9151],\n",
      "        [0.3780],\n",
      "        [0.9926],\n",
      "        [0.9479],\n",
      "        [0.9539],\n",
      "        [0.9718],\n",
      "        [0.9569],\n",
      "        [0.9889],\n",
      "        [0.9600],\n",
      "        [0.9402],\n",
      "        [0.9917],\n",
      "        [0.9389],\n",
      "        [0.3666],\n",
      "        [0.9955],\n",
      "        [0.9232],\n",
      "        [1.0226],\n",
      "        [0.9833],\n",
      "        [0.9281],\n",
      "        [0.9775],\n",
      "        [1.0375],\n",
      "        [0.9340],\n",
      "        [0.9636],\n",
      "        [0.3387]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.9828],\n",
      "        [-1.0000],\n",
      "        [ 0.8852],\n",
      "        [ 0.9306],\n",
      "        [ 0.9224],\n",
      "        [ 0.9921],\n",
      "        [ 0.9769],\n",
      "        [ 0.9698],\n",
      "        [ 0.9176],\n",
      "        [ 0.9727],\n",
      "        [ 0.9625],\n",
      "        [-1.0000],\n",
      "        [ 0.9956],\n",
      "        [-1.0000],\n",
      "        [ 0.9747],\n",
      "        [ 0.9903],\n",
      "        [ 0.9797],\n",
      "        [ 0.9631],\n",
      "        [ 0.9837],\n",
      "        [ 0.9882],\n",
      "        [-1.0000],\n",
      "        [ 0.9898],\n",
      "        [ 0.9793],\n",
      "        [ 0.9664],\n",
      "        [ 0.9694],\n",
      "        [ 0.9972],\n",
      "        [ 0.9584],\n",
      "        [ 0.9384],\n",
      "        [ 0.9650],\n",
      "        [ 0.9853],\n",
      "        [ 0.9667],\n",
      "        [ 0.9260],\n",
      "        [ 0.9868],\n",
      "        [ 0.9711],\n",
      "        [ 0.9893],\n",
      "        [ 0.9309],\n",
      "        [ 0.9160],\n",
      "        [-1.0000],\n",
      "        [ 0.9954],\n",
      "        [ 0.9767],\n",
      "        [ 0.9610],\n",
      "        [ 0.9180],\n",
      "        [ 0.9260],\n",
      "        [ 0.9634],\n",
      "        [ 0.9759],\n",
      "        [ 1.0095],\n",
      "        [ 0.9952],\n",
      "        [ 0.9459],\n",
      "        [ 0.9820],\n",
      "        [-1.0000],\n",
      "        [ 0.8999],\n",
      "        [ 0.9841],\n",
      "        [ 1.0038],\n",
      "        [ 0.9503],\n",
      "        [ 0.9698],\n",
      "        [-1.0000],\n",
      "        [ 0.9996],\n",
      "        [ 0.9716],\n",
      "        [ 1.0063],\n",
      "        [ 0.9055],\n",
      "        [ 0.9158],\n",
      "        [ 0.9587],\n",
      "        [ 0.9541],\n",
      "        [ 0.9289]], device='cuda:0'))\n",
      "{'loss': tensor(0.1473, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "200 8.89\n",
      "{'episode': 201, 'agent.time_step': 2590, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 202, 'agent.time_step': 2599, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 203, 'agent.time_step': 2607, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 204, 'agent.time_step': 2615, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 205, 'agent.time_step': 2631, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 206, 'agent.time_step': 2638, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 207, 'agent.time_step': 2650, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 208, 'agent.time_step': 2659, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 209, 'agent.time_step': 2667, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 210, 'agent.time_step': 2680, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "(q_current, q_targets): (tensor([[1.0754],\n",
      "        [1.0509],\n",
      "        [1.1133],\n",
      "        [1.1401],\n",
      "        [1.0893],\n",
      "        [1.0996],\n",
      "        [1.0807],\n",
      "        [1.0535],\n",
      "        [1.0699],\n",
      "        [1.1820],\n",
      "        [1.2206],\n",
      "        [1.0699],\n",
      "        [1.0918],\n",
      "        [1.0477],\n",
      "        [1.0476],\n",
      "        [1.0825],\n",
      "        [1.0720],\n",
      "        [0.6475],\n",
      "        [1.0659],\n",
      "        [1.0583],\n",
      "        [1.0739],\n",
      "        [1.1071],\n",
      "        [1.0550],\n",
      "        [1.1622],\n",
      "        [1.1379],\n",
      "        [1.0834],\n",
      "        [1.1686],\n",
      "        [1.1659],\n",
      "        [1.0427],\n",
      "        [1.1024],\n",
      "        [1.1253],\n",
      "        [1.0457],\n",
      "        [1.0465],\n",
      "        [1.1537],\n",
      "        [1.0528],\n",
      "        [1.0934],\n",
      "        [1.0148],\n",
      "        [1.0704],\n",
      "        [1.0791],\n",
      "        [1.1486],\n",
      "        [1.1042],\n",
      "        [1.1115],\n",
      "        [0.7493],\n",
      "        [1.0686],\n",
      "        [1.0538],\n",
      "        [1.0584],\n",
      "        [1.0752],\n",
      "        [1.1375],\n",
      "        [1.1024],\n",
      "        [1.0723],\n",
      "        [1.0446],\n",
      "        [1.1287],\n",
      "        [1.0935],\n",
      "        [1.1340],\n",
      "        [1.0725],\n",
      "        [1.0793],\n",
      "        [1.1228],\n",
      "        [1.1392],\n",
      "        [1.1153],\n",
      "        [1.0695],\n",
      "        [1.1126],\n",
      "        [0.7368],\n",
      "        [0.9643],\n",
      "        [1.1583]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7356],\n",
      "        [ 0.7818],\n",
      "        [ 0.7574],\n",
      "        [-1.0000],\n",
      "        [ 0.7420],\n",
      "        [ 0.7807],\n",
      "        [ 0.7884],\n",
      "        [ 0.7516],\n",
      "        [ 0.7346],\n",
      "        [ 0.7310],\n",
      "        [ 0.7711],\n",
      "        [ 0.7278],\n",
      "        [ 0.7571],\n",
      "        [ 0.7395],\n",
      "        [ 0.7507],\n",
      "        [ 0.7446],\n",
      "        [ 0.7420],\n",
      "        [ 0.7710],\n",
      "        [ 0.7782],\n",
      "        [ 0.7542],\n",
      "        [-1.0000],\n",
      "        [ 0.7633],\n",
      "        [ 0.7741],\n",
      "        [ 0.7516],\n",
      "        [ 0.7386],\n",
      "        [ 0.7522],\n",
      "        [ 0.7613],\n",
      "        [-1.0000],\n",
      "        [ 0.7663],\n",
      "        [ 0.7450],\n",
      "        [ 0.7501],\n",
      "        [ 0.7681],\n",
      "        [ 0.7603],\n",
      "        [ 0.7655],\n",
      "        [ 0.7658],\n",
      "        [ 0.7741],\n",
      "        [ 0.7463],\n",
      "        [ 0.7629],\n",
      "        [ 0.7499],\n",
      "        [ 0.7754],\n",
      "        [ 0.7781],\n",
      "        [ 0.7381],\n",
      "        [ 0.7772],\n",
      "        [ 0.7748],\n",
      "        [ 0.7727],\n",
      "        [ 0.7715],\n",
      "        [ 0.7374],\n",
      "        [ 0.7373],\n",
      "        [ 0.7529],\n",
      "        [ 0.7791],\n",
      "        [ 0.7836],\n",
      "        [ 0.7375],\n",
      "        [ 0.7767],\n",
      "        [ 0.7491],\n",
      "        [ 0.7553],\n",
      "        [ 0.7625],\n",
      "        [ 0.7862],\n",
      "        [ 0.7730],\n",
      "        [ 0.7802],\n",
      "        [ 0.7764],\n",
      "        [ 0.7422],\n",
      "        [ 0.7590],\n",
      "        [-1.0000],\n",
      "        [-1.0000]], device='cuda:0'))\n",
      "{'loss': tensor(0.1746, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 211, 'agent.time_step': 2687, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 212, 'agent.time_step': 2694, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 213, 'agent.time_step': 2708, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 214, 'agent.time_step': 2722, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 215, 'agent.time_step': 2737, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 216, 'agent.time_step': 2744, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 217, 'agent.time_step': 2754, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 218, 'agent.time_step': 2759, 'rounds': 5, 'accumulate_reward': 3.0}\n",
      "{'episode': 219, 'agent.time_step': 2768, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 220, 'agent.time_step': 2779, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "(q_current, q_targets): (tensor([[0.4730],\n",
      "        [0.5318],\n",
      "        [0.5099],\n",
      "        [0.5330],\n",
      "        [0.4833],\n",
      "        [0.4570],\n",
      "        [0.5526],\n",
      "        [0.4827],\n",
      "        [0.3513],\n",
      "        [0.4756],\n",
      "        [0.5147],\n",
      "        [0.4176],\n",
      "        [0.5162],\n",
      "        [0.3201],\n",
      "        [0.4949],\n",
      "        [0.4727],\n",
      "        [0.3763],\n",
      "        [0.5377],\n",
      "        [0.4720],\n",
      "        [0.4925],\n",
      "        [0.4827],\n",
      "        [0.4864],\n",
      "        [0.4705],\n",
      "        [0.4879],\n",
      "        [0.4997],\n",
      "        [0.4907],\n",
      "        [0.4995],\n",
      "        [0.4843],\n",
      "        [0.4974],\n",
      "        [0.4790],\n",
      "        [0.4443],\n",
      "        [0.4695],\n",
      "        [0.5500],\n",
      "        [0.4820],\n",
      "        [0.5349],\n",
      "        [0.4828],\n",
      "        [0.4869],\n",
      "        [0.4558],\n",
      "        [0.4666],\n",
      "        [0.4908],\n",
      "        [0.4821],\n",
      "        [0.4823],\n",
      "        [0.4512],\n",
      "        [0.4665],\n",
      "        [0.4386],\n",
      "        [0.4808],\n",
      "        [0.4891],\n",
      "        [0.4662],\n",
      "        [0.4863],\n",
      "        [0.5067],\n",
      "        [0.5785],\n",
      "        [0.4851],\n",
      "        [0.3527],\n",
      "        [0.4502],\n",
      "        [0.4829],\n",
      "        [0.4659],\n",
      "        [0.4822],\n",
      "        [0.4734],\n",
      "        [0.5209],\n",
      "        [0.4808],\n",
      "        [0.4752],\n",
      "        [0.4588],\n",
      "        [0.3539],\n",
      "        [0.4828]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7459],\n",
      "        [ 0.7650],\n",
      "        [ 0.7819],\n",
      "        [-1.0000],\n",
      "        [ 0.7611],\n",
      "        [ 0.7334],\n",
      "        [-1.0000],\n",
      "        [ 0.7697],\n",
      "        [ 0.7690],\n",
      "        [ 0.7829],\n",
      "        [ 0.7820],\n",
      "        [ 0.7533],\n",
      "        [ 0.7639],\n",
      "        [ 0.7601],\n",
      "        [ 0.7710],\n",
      "        [ 0.7681],\n",
      "        [ 0.7625],\n",
      "        [ 0.7451],\n",
      "        [ 0.7342],\n",
      "        [ 0.7469],\n",
      "        [ 0.7709],\n",
      "        [ 0.7597],\n",
      "        [-1.0000],\n",
      "        [ 0.7780],\n",
      "        [ 0.7638],\n",
      "        [ 0.7547],\n",
      "        [ 0.7619],\n",
      "        [ 0.7788],\n",
      "        [ 0.7752],\n",
      "        [ 0.7740],\n",
      "        [ 0.7753],\n",
      "        [ 0.7687],\n",
      "        [ 0.7641],\n",
      "        [ 0.7744],\n",
      "        [ 0.7651],\n",
      "        [ 0.7684],\n",
      "        [ 0.7445],\n",
      "        [ 0.7641],\n",
      "        [ 0.7457],\n",
      "        [ 0.7738],\n",
      "        [ 0.7740],\n",
      "        [ 0.7723],\n",
      "        [ 0.7827],\n",
      "        [ 0.7613],\n",
      "        [-1.0000],\n",
      "        [ 0.7854],\n",
      "        [ 0.7828],\n",
      "        [ 0.7853],\n",
      "        [-1.0000],\n",
      "        [ 0.7795],\n",
      "        [ 0.7701],\n",
      "        [ 0.7851],\n",
      "        [ 0.7858],\n",
      "        [-1.0000],\n",
      "        [ 0.7749],\n",
      "        [-1.0000],\n",
      "        [ 0.7487],\n",
      "        [ 0.7472],\n",
      "        [ 0.7727],\n",
      "        [ 0.7789],\n",
      "        [ 0.7743],\n",
      "        [ 0.7412],\n",
      "        [ 0.7608],\n",
      "        [ 0.7938]], device='cuda:0'))\n",
      "{'loss': tensor(0.1466, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 221, 'agent.time_step': 2795, 'rounds': 16, 'accumulate_reward': 14.0}\n",
      "{'episode': 222, 'agent.time_step': 2806, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 223, 'agent.time_step': 2818, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 224, 'agent.time_step': 2827, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 225, 'agent.time_step': 2835, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 226, 'agent.time_step': 2841, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 227, 'agent.time_step': 2848, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 228, 'agent.time_step': 2855, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 229, 'agent.time_step': 2866, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 230, 'agent.time_step': 2876, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "(q_current, q_targets): (tensor([[0.2363],\n",
      "        [0.2260],\n",
      "        [0.2522],\n",
      "        [0.2016],\n",
      "        [0.2600],\n",
      "        [0.2277],\n",
      "        [0.2328],\n",
      "        [0.2677],\n",
      "        [0.2400],\n",
      "        [0.1932],\n",
      "        [0.2132],\n",
      "        [0.2435],\n",
      "        [0.2261],\n",
      "        [0.2418],\n",
      "        [0.1529],\n",
      "        [0.2527],\n",
      "        [0.2260],\n",
      "        [0.2968],\n",
      "        [0.2094],\n",
      "        [0.1992],\n",
      "        [0.2632],\n",
      "        [0.2401],\n",
      "        [0.2273],\n",
      "        [0.2204],\n",
      "        [0.2338],\n",
      "        [0.2219],\n",
      "        [0.2386],\n",
      "        [0.3004],\n",
      "        [0.2132],\n",
      "        [0.2212],\n",
      "        [0.2186],\n",
      "        [0.2405],\n",
      "        [0.2019],\n",
      "        [0.2083],\n",
      "        [0.1374],\n",
      "        [0.2227],\n",
      "        [0.2229],\n",
      "        [0.2005],\n",
      "        [0.2792],\n",
      "        [0.2339],\n",
      "        [0.2896],\n",
      "        [0.2297],\n",
      "        [0.2228],\n",
      "        [0.2336],\n",
      "        [0.2071],\n",
      "        [0.2031],\n",
      "        [0.2244],\n",
      "        [0.1847],\n",
      "        [0.2636],\n",
      "        [0.2255],\n",
      "        [0.2245],\n",
      "        [0.2375],\n",
      "        [0.2197],\n",
      "        [0.2263],\n",
      "        [0.2268],\n",
      "        [0.2294],\n",
      "        [0.2602],\n",
      "        [0.2273],\n",
      "        [0.2114],\n",
      "        [0.2093],\n",
      "        [0.2373],\n",
      "        [0.2976],\n",
      "        [0.2285],\n",
      "        [0.1735]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7521],\n",
      "        [ 0.7504],\n",
      "        [ 0.7411],\n",
      "        [ 0.7699],\n",
      "        [ 0.7439],\n",
      "        [ 0.7763],\n",
      "        [ 0.7719],\n",
      "        [ 0.7558],\n",
      "        [ 0.7706],\n",
      "        [ 0.7589],\n",
      "        [ 0.7551],\n",
      "        [ 0.7506],\n",
      "        [ 0.7832],\n",
      "        [ 0.7657],\n",
      "        [-1.0000],\n",
      "        [ 0.7556],\n",
      "        [ 0.7671],\n",
      "        [ 0.7568],\n",
      "        [ 0.7808],\n",
      "        [-1.0000],\n",
      "        [ 0.7587],\n",
      "        [ 0.7627],\n",
      "        [ 0.7688],\n",
      "        [ 0.7746],\n",
      "        [-1.0000],\n",
      "        [ 0.7759],\n",
      "        [ 0.7347],\n",
      "        [ 0.7393],\n",
      "        [ 0.7721],\n",
      "        [ 0.7841],\n",
      "        [ 0.7653],\n",
      "        [ 0.7722],\n",
      "        [ 0.7826],\n",
      "        [ 0.7549],\n",
      "        [ 0.7580],\n",
      "        [ 0.7440],\n",
      "        [-1.0000],\n",
      "        [ 0.7620],\n",
      "        [ 0.7682],\n",
      "        [ 0.7721],\n",
      "        [ 0.7491],\n",
      "        [ 0.7518],\n",
      "        [ 0.7575],\n",
      "        [ 0.7697],\n",
      "        [ 0.9751],\n",
      "        [ 0.7767],\n",
      "        [ 0.7425],\n",
      "        [-1.0000],\n",
      "        [ 0.7464],\n",
      "        [ 0.7798],\n",
      "        [ 0.7565],\n",
      "        [ 0.7740],\n",
      "        [ 0.7587],\n",
      "        [ 0.7795],\n",
      "        [ 0.7818],\n",
      "        [ 0.7644],\n",
      "        [ 0.7678],\n",
      "        [ 0.7826],\n",
      "        [ 0.7648],\n",
      "        [ 0.7566],\n",
      "        [ 0.7482],\n",
      "        [ 0.7647],\n",
      "        [ 0.7644],\n",
      "        [ 0.7724]], device='cuda:0'))\n",
      "{'loss': tensor(0.1877, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 231, 'agent.time_step': 2884, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 232, 'agent.time_step': 2896, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 233, 'agent.time_step': 2903, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 234, 'agent.time_step': 2917, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 235, 'agent.time_step': 2929, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 236, 'agent.time_step': 2937, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 237, 'agent.time_step': 2946, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 238, 'agent.time_step': 2953, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 239, 'agent.time_step': 2961, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 240, 'agent.time_step': 2969, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[0.2219],\n",
      "        [0.2176],\n",
      "        [0.1992],\n",
      "        [0.2199],\n",
      "        [0.2204],\n",
      "        [0.2007],\n",
      "        [0.2180],\n",
      "        [0.2205],\n",
      "        [0.2201],\n",
      "        [0.2312],\n",
      "        [0.2108],\n",
      "        [0.2385],\n",
      "        [0.2314],\n",
      "        [0.2374],\n",
      "        [0.2539],\n",
      "        [0.2154],\n",
      "        [0.2204],\n",
      "        [0.2206],\n",
      "        [0.2598],\n",
      "        [0.2163],\n",
      "        [0.2239],\n",
      "        [0.2627],\n",
      "        [0.2307],\n",
      "        [0.2249],\n",
      "        [0.2778],\n",
      "        [0.2176],\n",
      "        [0.2436],\n",
      "        [0.2257],\n",
      "        [0.2176],\n",
      "        [0.2250],\n",
      "        [0.2176],\n",
      "        [0.2204],\n",
      "        [0.2524],\n",
      "        [0.2050],\n",
      "        [0.2241],\n",
      "        [0.3049],\n",
      "        [0.2399],\n",
      "        [0.2196],\n",
      "        [0.2505],\n",
      "        [0.2647],\n",
      "        [0.2281],\n",
      "        [0.2353],\n",
      "        [0.1455],\n",
      "        [0.3039],\n",
      "        [0.2637],\n",
      "        [0.2196],\n",
      "        [0.2180],\n",
      "        [0.1727],\n",
      "        [0.2203],\n",
      "        [0.2042],\n",
      "        [0.2159],\n",
      "        [0.2223],\n",
      "        [0.2176],\n",
      "        [0.2193],\n",
      "        [0.2230],\n",
      "        [0.2382],\n",
      "        [0.2590],\n",
      "        [0.2101],\n",
      "        [0.2221],\n",
      "        [0.2487],\n",
      "        [0.2173],\n",
      "        [0.2096],\n",
      "        [0.2177],\n",
      "        [0.2201]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7646],\n",
      "        [ 0.7375],\n",
      "        [-1.0000],\n",
      "        [ 0.7492],\n",
      "        [ 0.7652],\n",
      "        [ 0.7781],\n",
      "        [ 0.7732],\n",
      "        [ 0.7600],\n",
      "        [ 0.7395],\n",
      "        [ 0.7394],\n",
      "        [ 0.7690],\n",
      "        [ 0.7721],\n",
      "        [ 0.7648],\n",
      "        [ 0.7611],\n",
      "        [ 0.7515],\n",
      "        [ 0.7598],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.7307],\n",
      "        [ 0.7662],\n",
      "        [ 0.7730],\n",
      "        [ 0.7733],\n",
      "        [ 0.7616],\n",
      "        [ 0.7698],\n",
      "        [ 0.7401],\n",
      "        [ 0.7595],\n",
      "        [ 0.7334],\n",
      "        [ 0.7375],\n",
      "        [ 0.7731],\n",
      "        [ 0.7370],\n",
      "        [ 0.7724],\n",
      "        [ 0.7633],\n",
      "        [ 0.7711],\n",
      "        [-1.0000],\n",
      "        [ 0.7680],\n",
      "        [ 0.7361],\n",
      "        [ 0.7667],\n",
      "        [ 0.7696],\n",
      "        [ 0.7733],\n",
      "        [ 0.7470],\n",
      "        [ 0.7651],\n",
      "        [-1.0000],\n",
      "        [ 0.7496],\n",
      "        [ 0.7778],\n",
      "        [ 0.7283],\n",
      "        [ 0.7695],\n",
      "        [ 0.7532],\n",
      "        [ 0.7359],\n",
      "        [ 0.7704],\n",
      "        [ 0.7704],\n",
      "        [ 0.7721],\n",
      "        [ 0.7375],\n",
      "        [ 0.7727],\n",
      "        [ 0.7419],\n",
      "        [ 0.7718],\n",
      "        [ 0.7797],\n",
      "        [ 0.7551],\n",
      "        [ 0.7821],\n",
      "        [ 0.7783],\n",
      "        [-1.0000],\n",
      "        [ 0.7676],\n",
      "        [ 0.7757],\n",
      "        [ 0.7297]], device='cuda:0'))\n",
      "{'loss': tensor(0.2032, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 241, 'agent.time_step': 2977, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 242, 'agent.time_step': 2987, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 243, 'agent.time_step': 2998, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 244, 'agent.time_step': 3008, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 245, 'agent.time_step': 3015, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 246, 'agent.time_step': 3026, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 247, 'agent.time_step': 3032, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 248, 'agent.time_step': 3040, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 249, 'agent.time_step': 3051, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 250, 'agent.time_step': 3063, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "(q_current, q_targets): (tensor([[0.3593],\n",
      "        [0.3583],\n",
      "        [0.3535],\n",
      "        [0.3637],\n",
      "        [0.3443],\n",
      "        [0.3608],\n",
      "        [0.3609],\n",
      "        [0.3877],\n",
      "        [0.3342],\n",
      "        [0.3463],\n",
      "        [0.3151],\n",
      "        [0.3473],\n",
      "        [0.3567],\n",
      "        [0.4315],\n",
      "        [0.3991],\n",
      "        [0.3560],\n",
      "        [0.3416],\n",
      "        [0.3760],\n",
      "        [0.4212],\n",
      "        [0.3560],\n",
      "        [0.3574],\n",
      "        [0.3567],\n",
      "        [0.4059],\n",
      "        [0.3338],\n",
      "        [0.3612],\n",
      "        [0.3526],\n",
      "        [0.3563],\n",
      "        [0.3604],\n",
      "        [0.3522],\n",
      "        [0.3630],\n",
      "        [0.3349],\n",
      "        [0.3560],\n",
      "        [0.3416],\n",
      "        [0.3626],\n",
      "        [0.3560],\n",
      "        [0.3843],\n",
      "        [0.4085],\n",
      "        [0.3267],\n",
      "        [0.3567],\n",
      "        [0.3545],\n",
      "        [0.3694],\n",
      "        [0.3563],\n",
      "        [0.3554],\n",
      "        [0.3872],\n",
      "        [0.3455],\n",
      "        [0.3902],\n",
      "        [0.3567],\n",
      "        [0.3567],\n",
      "        [0.3600],\n",
      "        [0.3699],\n",
      "        [0.3419],\n",
      "        [0.3983],\n",
      "        [0.3545],\n",
      "        [0.3870],\n",
      "        [0.3563],\n",
      "        [0.3796],\n",
      "        [0.3587],\n",
      "        [0.3627],\n",
      "        [0.3563],\n",
      "        [0.3563],\n",
      "        [0.3548],\n",
      "        [0.3660],\n",
      "        [0.3465],\n",
      "        [0.3587]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7644],\n",
      "        [ 0.7821],\n",
      "        [ 0.7490],\n",
      "        [-1.0000],\n",
      "        [ 0.7558],\n",
      "        [-1.0000],\n",
      "        [ 0.7727],\n",
      "        [ 0.7413],\n",
      "        [ 0.7533],\n",
      "        [ 0.7466],\n",
      "        [-1.0000],\n",
      "        [ 0.7416],\n",
      "        [ 0.7555],\n",
      "        [ 0.7529],\n",
      "        [ 0.7646],\n",
      "        [ 0.7773],\n",
      "        [ 0.7703],\n",
      "        [ 0.7602],\n",
      "        [ 0.7729],\n",
      "        [ 0.7882],\n",
      "        [ 0.7589],\n",
      "        [ 0.7540],\n",
      "        [ 0.7760],\n",
      "        [ 0.7855],\n",
      "        [ 0.7791],\n",
      "        [-1.0000],\n",
      "        [ 0.7389],\n",
      "        [ 0.7814],\n",
      "        [ 0.7881],\n",
      "        [ 0.7565],\n",
      "        [ 0.7575],\n",
      "        [ 0.7836],\n",
      "        [-1.0000],\n",
      "        [ 0.7426],\n",
      "        [ 0.7861],\n",
      "        [ 0.7553],\n",
      "        [ 0.7707],\n",
      "        [ 0.7417],\n",
      "        [ 0.7747],\n",
      "        [ 0.7372],\n",
      "        [ 0.7584],\n",
      "        [ 0.7352],\n",
      "        [-1.0000],\n",
      "        [ 0.7859],\n",
      "        [ 0.7692],\n",
      "        [ 0.7586],\n",
      "        [ 0.7617],\n",
      "        [ 0.7555],\n",
      "        [-1.0000],\n",
      "        [ 0.7608],\n",
      "        [-1.0000],\n",
      "        [ 0.7598],\n",
      "        [ 0.7318],\n",
      "        [ 0.7625],\n",
      "        [ 0.7310],\n",
      "        [ 0.7764],\n",
      "        [ 0.7616],\n",
      "        [-1.0000],\n",
      "        [ 0.7353],\n",
      "        [ 0.7336],\n",
      "        [ 0.7341],\n",
      "        [ 0.7622],\n",
      "        [ 0.7700],\n",
      "        [ 0.7681]], device='cuda:0'))\n",
      "{'loss': tensor(0.1874, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 251, 'agent.time_step': 3074, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 252, 'agent.time_step': 3085, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 253, 'agent.time_step': 3098, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 254, 'agent.time_step': 3105, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 255, 'agent.time_step': 3116, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 256, 'agent.time_step': 3128, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 257, 'agent.time_step': 3137, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 258, 'agent.time_step': 3151, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 259, 'agent.time_step': 3161, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 260, 'agent.time_step': 3168, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "(q_current, q_targets): (tensor([[0.6397],\n",
      "        [0.7137],\n",
      "        [0.6363],\n",
      "        [0.6365],\n",
      "        [0.6296],\n",
      "        [0.6097],\n",
      "        [0.6341],\n",
      "        [0.6125],\n",
      "        [0.6190],\n",
      "        [0.6213],\n",
      "        [0.6111],\n",
      "        [0.6174],\n",
      "        [0.1300],\n",
      "        [0.6324],\n",
      "        [0.6213],\n",
      "        [0.6680],\n",
      "        [0.6287],\n",
      "        [0.6364],\n",
      "        [0.6106],\n",
      "        [0.6515],\n",
      "        [0.6239],\n",
      "        [0.6204],\n",
      "        [0.6286],\n",
      "        [0.6213],\n",
      "        [0.6143],\n",
      "        [0.7471],\n",
      "        [0.6216],\n",
      "        [0.6267],\n",
      "        [0.6301],\n",
      "        [0.6576],\n",
      "        [0.6763],\n",
      "        [0.6213],\n",
      "        [0.6520],\n",
      "        [0.6974],\n",
      "        [0.6259],\n",
      "        [0.6059],\n",
      "        [0.6230],\n",
      "        [0.6530],\n",
      "        [0.1273],\n",
      "        [0.6612],\n",
      "        [0.6213],\n",
      "        [0.5922],\n",
      "        [0.6214],\n",
      "        [0.6302],\n",
      "        [0.6213],\n",
      "        [0.6196],\n",
      "        [0.6208],\n",
      "        [0.7303],\n",
      "        [0.6088],\n",
      "        [0.6480],\n",
      "        [0.6243],\n",
      "        [0.6271],\n",
      "        [0.6814],\n",
      "        [0.6481],\n",
      "        [0.7055],\n",
      "        [0.6275],\n",
      "        [0.6258],\n",
      "        [0.5851],\n",
      "        [0.7344],\n",
      "        [0.6874],\n",
      "        [0.0265],\n",
      "        [0.6304],\n",
      "        [0.6401],\n",
      "        [0.6214]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.6459],\n",
      "        [ 0.6460],\n",
      "        [ 0.6680],\n",
      "        [ 0.6621],\n",
      "        [ 0.6736],\n",
      "        [ 0.6752],\n",
      "        [ 0.6648],\n",
      "        [ 0.6619],\n",
      "        [ 0.6659],\n",
      "        [ 0.6750],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.6478],\n",
      "        [ 0.6744],\n",
      "        [ 0.6488],\n",
      "        [ 0.6627],\n",
      "        [ 0.6608],\n",
      "        [ 0.6831],\n",
      "        [ 0.6854],\n",
      "        [ 0.6600],\n",
      "        [ 0.6913],\n",
      "        [ 0.6790],\n",
      "        [ 0.6809],\n",
      "        [ 0.6684],\n",
      "        [ 0.6669],\n",
      "        [ 0.6684],\n",
      "        [ 0.6546],\n",
      "        [ 0.6681],\n",
      "        [ 0.6566],\n",
      "        [ 0.6765],\n",
      "        [ 0.6547],\n",
      "        [ 0.6368],\n",
      "        [ 0.6519],\n",
      "        [ 0.6684],\n",
      "        [-1.0000],\n",
      "        [ 0.6743],\n",
      "        [ 0.6458],\n",
      "        [ 0.6635],\n",
      "        [ 0.6403],\n",
      "        [ 0.6478],\n",
      "        [ 0.6598],\n",
      "        [ 0.6561],\n",
      "        [ 0.6840],\n",
      "        [ 0.6861],\n",
      "        [ 0.6799],\n",
      "        [ 0.6790],\n",
      "        [ 0.6755],\n",
      "        [ 0.6870],\n",
      "        [ 0.6776],\n",
      "        [ 0.6684],\n",
      "        [ 0.6365],\n",
      "        [ 0.6632],\n",
      "        [ 0.6421],\n",
      "        [ 0.6901],\n",
      "        [ 0.6500],\n",
      "        [-1.0000],\n",
      "        [ 0.6749],\n",
      "        [ 0.6592],\n",
      "        [ 0.6770],\n",
      "        [ 0.6641],\n",
      "        [ 0.6591],\n",
      "        [-1.0000],\n",
      "        [ 0.6646],\n",
      "        [ 0.6798]], device='cuda:0'))\n",
      "{'loss': tensor(0.0959, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 261, 'agent.time_step': 3183, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 262, 'agent.time_step': 3193, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 263, 'agent.time_step': 3204, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 264, 'agent.time_step': 3214, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 265, 'agent.time_step': 3226, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 266, 'agent.time_step': 3233, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 267, 'agent.time_step': 3245, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 268, 'agent.time_step': 3253, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 269, 'agent.time_step': 3260, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 270, 'agent.time_step': 3268, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[0.8464],\n",
      "        [0.8126],\n",
      "        [0.8544],\n",
      "        [0.8687],\n",
      "        [0.8492],\n",
      "        [0.8838],\n",
      "        [0.8336],\n",
      "        [0.8712],\n",
      "        [0.8820],\n",
      "        [0.8911],\n",
      "        [0.8538],\n",
      "        [0.8355],\n",
      "        [0.8490],\n",
      "        [0.8819],\n",
      "        [0.8482],\n",
      "        [0.8491],\n",
      "        [0.8484],\n",
      "        [0.8279],\n",
      "        [0.9055],\n",
      "        [0.8261],\n",
      "        [0.8900],\n",
      "        [0.9168],\n",
      "        [0.9829],\n",
      "        [0.8538],\n",
      "        [0.8697],\n",
      "        [0.8843],\n",
      "        [0.8493],\n",
      "        [0.8547],\n",
      "        [0.1247],\n",
      "        [0.8482],\n",
      "        [0.8481],\n",
      "        [0.8838],\n",
      "        [0.8811],\n",
      "        [0.8626],\n",
      "        [0.8730],\n",
      "        [0.8508],\n",
      "        [0.9030],\n",
      "        [0.8717],\n",
      "        [0.8494],\n",
      "        [0.8529],\n",
      "        [0.8492],\n",
      "        [1.1566],\n",
      "        [0.8678],\n",
      "        [0.8519],\n",
      "        [0.8549],\n",
      "        [0.8476],\n",
      "        [0.8438],\n",
      "        [0.8442],\n",
      "        [0.8482],\n",
      "        [0.8530],\n",
      "        [0.8475],\n",
      "        [0.8780],\n",
      "        [0.8964],\n",
      "        [0.9148],\n",
      "        [0.8380],\n",
      "        [0.9330],\n",
      "        [0.8357],\n",
      "        [0.8720],\n",
      "        [0.8172],\n",
      "        [0.8785],\n",
      "        [0.8271],\n",
      "        [0.8592],\n",
      "        [0.8135],\n",
      "        [0.1162]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.6585],\n",
      "        [ 0.6581],\n",
      "        [ 0.6489],\n",
      "        [ 0.6471],\n",
      "        [ 0.6641],\n",
      "        [ 0.6620],\n",
      "        [ 0.6671],\n",
      "        [ 0.6854],\n",
      "        [ 0.6710],\n",
      "        [ 0.6594],\n",
      "        [ 0.6287],\n",
      "        [ 0.6635],\n",
      "        [ 0.6382],\n",
      "        [ 0.6362],\n",
      "        [ 0.6326],\n",
      "        [ 0.6835],\n",
      "        [ 0.6619],\n",
      "        [ 0.6539],\n",
      "        [ 0.6349],\n",
      "        [-1.0000],\n",
      "        [ 0.6539],\n",
      "        [ 0.6276],\n",
      "        [ 0.6463],\n",
      "        [ 0.6280],\n",
      "        [ 0.6396],\n",
      "        [ 0.6713],\n",
      "        [ 0.6262],\n",
      "        [ 0.6405],\n",
      "        [ 0.6604],\n",
      "        [ 0.6324],\n",
      "        [ 0.6395],\n",
      "        [ 0.6507],\n",
      "        [ 0.6807],\n",
      "        [ 0.6679],\n",
      "        [ 0.6571],\n",
      "        [ 0.6518],\n",
      "        [ 0.6370],\n",
      "        [ 0.6450],\n",
      "        [ 0.6485],\n",
      "        [ 0.6652],\n",
      "        [ 0.6492],\n",
      "        [ 0.6325],\n",
      "        [-1.0000],\n",
      "        [ 0.6599],\n",
      "        [ 0.6670],\n",
      "        [ 0.6759],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.6274],\n",
      "        [-1.0000],\n",
      "        [ 0.6416],\n",
      "        [ 0.6314],\n",
      "        [ 0.6300],\n",
      "        [ 0.6707],\n",
      "        [ 0.6409],\n",
      "        [ 0.6714],\n",
      "        [-1.0000],\n",
      "        [ 0.6619],\n",
      "        [ 0.6488],\n",
      "        [ 0.6656],\n",
      "        [-1.0000],\n",
      "        [ 0.6455],\n",
      "        [-1.0000],\n",
      "        [ 0.6285]], device='cuda:0'))\n",
      "{'loss': tensor(0.1933, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 271, 'agent.time_step': 3275, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 272, 'agent.time_step': 3282, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 273, 'agent.time_step': 3291, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 274, 'agent.time_step': 3300, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 275, 'agent.time_step': 3308, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 276, 'agent.time_step': 3314, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 277, 'agent.time_step': 3325, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 278, 'agent.time_step': 3336, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 279, 'agent.time_step': 3344, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 280, 'agent.time_step': 3351, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "(q_current, q_targets): (tensor([[0.6603],\n",
      "        [0.6977],\n",
      "        [0.7111],\n",
      "        [0.7119],\n",
      "        [0.7482],\n",
      "        [0.7402],\n",
      "        [0.7392],\n",
      "        [0.7569],\n",
      "        [0.7109],\n",
      "        [0.7503],\n",
      "        [0.7230],\n",
      "        [0.7165],\n",
      "        [0.6840],\n",
      "        [0.6939],\n",
      "        [0.7174],\n",
      "        [0.7177],\n",
      "        [0.7145],\n",
      "        [0.6786],\n",
      "        [0.7136],\n",
      "        [0.6984],\n",
      "        [0.7117],\n",
      "        [0.6872],\n",
      "        [0.7147],\n",
      "        [0.7170],\n",
      "        [0.7187],\n",
      "        [0.7363],\n",
      "        [0.7513],\n",
      "        [0.7173],\n",
      "        [0.7111],\n",
      "        [0.6783],\n",
      "        [0.7063],\n",
      "        [0.7472],\n",
      "        [0.7533],\n",
      "        [0.6990],\n",
      "        [0.6797],\n",
      "        [0.6898],\n",
      "        [0.7163],\n",
      "        [0.6860],\n",
      "        [0.6889],\n",
      "        [0.7816],\n",
      "        [0.7119],\n",
      "        [0.7058],\n",
      "        [0.2380],\n",
      "        [0.7119],\n",
      "        [0.7115],\n",
      "        [0.7247],\n",
      "        [0.7119],\n",
      "        [0.8141],\n",
      "        [0.7111],\n",
      "        [0.7064],\n",
      "        [0.6957],\n",
      "        [0.6950],\n",
      "        [0.7152],\n",
      "        [0.7401],\n",
      "        [0.7990],\n",
      "        [0.7116],\n",
      "        [0.7030],\n",
      "        [0.7698],\n",
      "        [0.7096],\n",
      "        [0.6876],\n",
      "        [0.6979],\n",
      "        [0.7232],\n",
      "        [0.7057],\n",
      "        [0.1538]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.6838],\n",
      "        [ 0.6687],\n",
      "        [ 0.6393],\n",
      "        [ 0.6703],\n",
      "        [ 0.6506],\n",
      "        [ 0.6344],\n",
      "        [ 0.6719],\n",
      "        [ 0.6800],\n",
      "        [ 0.6839],\n",
      "        [ 0.6295],\n",
      "        [ 0.6679],\n",
      "        [ 0.6860],\n",
      "        [-1.0000],\n",
      "        [ 0.6640],\n",
      "        [ 0.6669],\n",
      "        [ 0.6457],\n",
      "        [ 0.6736],\n",
      "        [-1.0000],\n",
      "        [ 0.6585],\n",
      "        [ 0.6533],\n",
      "        [ 0.6929],\n",
      "        [ 0.6690],\n",
      "        [ 0.6736],\n",
      "        [ 0.6785],\n",
      "        [ 0.6698],\n",
      "        [ 0.6599],\n",
      "        [ 0.6341],\n",
      "        [ 0.6719],\n",
      "        [ 0.6363],\n",
      "        [ 0.6580],\n",
      "        [ 0.6892],\n",
      "        [ 0.6574],\n",
      "        [ 0.6657],\n",
      "        [ 0.6464],\n",
      "        [ 0.6680],\n",
      "        [ 0.6472],\n",
      "        [ 0.6407],\n",
      "        [ 0.6438],\n",
      "        [ 0.6565],\n",
      "        [ 0.6714],\n",
      "        [ 0.6890],\n",
      "        [-1.0000],\n",
      "        [ 0.6656],\n",
      "        [ 0.6835],\n",
      "        [ 0.6372],\n",
      "        [ 0.6543],\n",
      "        [ 0.6881],\n",
      "        [ 0.6444],\n",
      "        [ 0.6393],\n",
      "        [ 0.6699],\n",
      "        [ 0.6461],\n",
      "        [ 0.6642],\n",
      "        [ 0.6652],\n",
      "        [ 0.6389],\n",
      "        [ 0.6673],\n",
      "        [ 0.6604],\n",
      "        [ 0.6552],\n",
      "        [ 0.6736],\n",
      "        [ 0.6647],\n",
      "        [ 0.6539],\n",
      "        [-1.0000],\n",
      "        [ 0.6851],\n",
      "        [ 0.6907],\n",
      "        [-1.0000]], device='cuda:0'))\n",
      "{'loss': tensor(0.0881, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 281, 'agent.time_step': 3360, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 282, 'agent.time_step': 3366, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 283, 'agent.time_step': 3377, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 284, 'agent.time_step': 3386, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 285, 'agent.time_step': 3401, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 286, 'agent.time_step': 3413, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 287, 'agent.time_step': 3421, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 288, 'agent.time_step': 3429, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 289, 'agent.time_step': 3438, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 290, 'agent.time_step': 3448, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "(q_current, q_targets): (tensor([[0.5507],\n",
      "        [0.5580],\n",
      "        [0.6956],\n",
      "        [0.4853],\n",
      "        [0.5326],\n",
      "        [0.5308],\n",
      "        [0.4900],\n",
      "        [0.5311],\n",
      "        [0.5417],\n",
      "        [0.1148],\n",
      "        [0.5579],\n",
      "        [0.5320],\n",
      "        [0.5356],\n",
      "        [0.5379],\n",
      "        [0.5361],\n",
      "        [0.5178],\n",
      "        [0.5877],\n",
      "        [0.5049],\n",
      "        [0.5283],\n",
      "        [0.5619],\n",
      "        [0.5008],\n",
      "        [0.5617],\n",
      "        [0.5039],\n",
      "        [0.4524],\n",
      "        [0.5230],\n",
      "        [0.5291],\n",
      "        [0.5441],\n",
      "        [0.4620],\n",
      "        [0.5805],\n",
      "        [0.5519],\n",
      "        [0.4873],\n",
      "        [0.5063],\n",
      "        [0.5247],\n",
      "        [0.5134],\n",
      "        [0.5476],\n",
      "        [0.5177],\n",
      "        [0.5083],\n",
      "        [0.5261],\n",
      "        [0.5294],\n",
      "        [0.5283],\n",
      "        [0.5336],\n",
      "        [0.5005],\n",
      "        [0.5291],\n",
      "        [0.5253],\n",
      "        [0.5047],\n",
      "        [0.4494],\n",
      "        [0.5030],\n",
      "        [0.5387],\n",
      "        [0.5252],\n",
      "        [0.5276],\n",
      "        [0.6021],\n",
      "        [0.4990],\n",
      "        [0.5283],\n",
      "        [0.4685],\n",
      "        [0.5362],\n",
      "        [0.5360],\n",
      "        [0.5528],\n",
      "        [0.5659],\n",
      "        [0.4974],\n",
      "        [0.5283],\n",
      "        [0.5478],\n",
      "        [0.5233],\n",
      "        [0.4993],\n",
      "        [0.5833]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.6660],\n",
      "        [ 0.6915],\n",
      "        [ 0.6678],\n",
      "        [-1.0000],\n",
      "        [ 0.6790],\n",
      "        [ 0.6592],\n",
      "        [ 0.6755],\n",
      "        [ 0.6891],\n",
      "        [ 0.6309],\n",
      "        [ 0.6712],\n",
      "        [ 0.6695],\n",
      "        [ 0.6745],\n",
      "        [ 0.6719],\n",
      "        [ 0.6717],\n",
      "        [ 0.6682],\n",
      "        [ 0.6800],\n",
      "        [ 0.6664],\n",
      "        [ 0.6343],\n",
      "        [ 0.6891],\n",
      "        [ 0.6770],\n",
      "        [-1.0000],\n",
      "        [ 0.6544],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.6540],\n",
      "        [ 0.6628],\n",
      "        [-1.0000],\n",
      "        [ 0.6610],\n",
      "        [ 0.6505],\n",
      "        [ 0.6731],\n",
      "        [ 0.6449],\n",
      "        [ 0.6864],\n",
      "        [ 0.6393],\n",
      "        [ 0.6431],\n",
      "        [ 0.6879],\n",
      "        [ 0.6425],\n",
      "        [ 0.6771],\n",
      "        [ 0.6705],\n",
      "        [ 0.6524],\n",
      "        [ 0.6657],\n",
      "        [ 0.6523],\n",
      "        [ 0.6640],\n",
      "        [ 0.6820],\n",
      "        [ 0.6442],\n",
      "        [ 0.6534],\n",
      "        [ 0.6565],\n",
      "        [-1.0000],\n",
      "        [ 0.6869],\n",
      "        [ 0.6903],\n",
      "        [ 0.6709],\n",
      "        [ 0.6528],\n",
      "        [ 0.6549],\n",
      "        [ 0.6444],\n",
      "        [ 0.6627],\n",
      "        [ 0.6648],\n",
      "        [ 0.6793],\n",
      "        [ 0.6734],\n",
      "        [ 0.6476],\n",
      "        [ 0.6685],\n",
      "        [ 0.6469],\n",
      "        [ 0.6675],\n",
      "        [ 0.6785],\n",
      "        [ 0.6640]], device='cuda:0'))\n",
      "{'loss': tensor(0.1194, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 291, 'agent.time_step': 3458, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 292, 'agent.time_step': 3467, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 293, 'agent.time_step': 3478, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 294, 'agent.time_step': 3487, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 295, 'agent.time_step': 3495, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 296, 'agent.time_step': 3508, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 297, 'agent.time_step': 3519, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 298, 'agent.time_step': 3527, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 299, 'agent.time_step': 3540, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 300, 'agent.time_step': 3547, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "(q_current, q_targets): (tensor([[0.3915],\n",
      "        [0.4116],\n",
      "        [0.4226],\n",
      "        [0.4021],\n",
      "        [0.4014],\n",
      "        [0.3559],\n",
      "        [0.5689],\n",
      "        [0.1806],\n",
      "        [0.3999],\n",
      "        [0.4038],\n",
      "        [0.3995],\n",
      "        [0.4518],\n",
      "        [0.3886],\n",
      "        [0.3993],\n",
      "        [0.4450],\n",
      "        [0.3888],\n",
      "        [0.3711],\n",
      "        [0.3763],\n",
      "        [0.4079],\n",
      "        [0.3997],\n",
      "        [0.3993],\n",
      "        [0.3865],\n",
      "        [0.3952],\n",
      "        [0.4143],\n",
      "        [0.3997],\n",
      "        [0.3270],\n",
      "        [0.3929],\n",
      "        [0.3893],\n",
      "        [0.4308],\n",
      "        [0.4059],\n",
      "        [0.3993],\n",
      "        [0.3888],\n",
      "        [0.4259],\n",
      "        [0.3902],\n",
      "        [0.4003],\n",
      "        [0.3503],\n",
      "        [0.4044],\n",
      "        [0.4051],\n",
      "        [0.4158],\n",
      "        [0.4380],\n",
      "        [0.3995],\n",
      "        [0.4389],\n",
      "        [0.3989],\n",
      "        [0.3788],\n",
      "        [0.3571],\n",
      "        [0.4160],\n",
      "        [0.3989],\n",
      "        [0.4051],\n",
      "        [0.4044],\n",
      "        [0.4447],\n",
      "        [0.4903],\n",
      "        [0.2419],\n",
      "        [0.3998],\n",
      "        [0.4440],\n",
      "        [0.3499],\n",
      "        [0.3862],\n",
      "        [0.3618],\n",
      "        [0.4014],\n",
      "        [0.2491],\n",
      "        [0.4043],\n",
      "        [0.3905],\n",
      "        [0.3467],\n",
      "        [0.4260],\n",
      "        [0.4242]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.6629],\n",
      "        [ 0.6359],\n",
      "        [ 0.6312],\n",
      "        [ 0.6309],\n",
      "        [ 0.6424],\n",
      "        [ 0.6413],\n",
      "        [ 0.6695],\n",
      "        [ 0.6781],\n",
      "        [ 0.6586],\n",
      "        [ 0.6625],\n",
      "        [ 0.6774],\n",
      "        [ 0.6433],\n",
      "        [-1.0000],\n",
      "        [ 0.6217],\n",
      "        [ 0.6299],\n",
      "        [ 0.6402],\n",
      "        [ 0.6453],\n",
      "        [ 0.6412],\n",
      "        [ 0.6600],\n",
      "        [ 0.6292],\n",
      "        [ 0.6406],\n",
      "        [-1.0000],\n",
      "        [ 0.6399],\n",
      "        [ 0.6697],\n",
      "        [ 0.6374],\n",
      "        [ 0.6402],\n",
      "        [-1.0000],\n",
      "        [ 0.6680],\n",
      "        [ 0.6526],\n",
      "        [ 0.6678],\n",
      "        [ 0.6760],\n",
      "        [ 0.6428],\n",
      "        [-1.0000],\n",
      "        [ 0.6451],\n",
      "        [ 0.6774],\n",
      "        [-1.0000],\n",
      "        [ 0.6263],\n",
      "        [ 0.6319],\n",
      "        [ 0.6687],\n",
      "        [ 0.6352],\n",
      "        [ 0.6613],\n",
      "        [ 0.6436],\n",
      "        [ 0.6420],\n",
      "        [-1.0000],\n",
      "        [ 0.6616],\n",
      "        [ 0.6648],\n",
      "        [ 0.6384],\n",
      "        [ 0.6333],\n",
      "        [ 0.6266],\n",
      "        [ 0.6695],\n",
      "        [ 0.6623],\n",
      "        [ 0.6436],\n",
      "        [ 0.6789],\n",
      "        [ 0.6834],\n",
      "        [ 0.6369],\n",
      "        [ 0.6795],\n",
      "        [ 0.6419],\n",
      "        [ 0.6500],\n",
      "        [ 0.6491],\n",
      "        [ 0.6831],\n",
      "        [ 0.6682],\n",
      "        [ 0.6586],\n",
      "        [ 0.6261],\n",
      "        [ 0.6349]], device='cuda:0'))\n",
      "{'loss': tensor(0.1141, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "300 7.71\n",
      "{'episode': 301, 'agent.time_step': 3560, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 302, 'agent.time_step': 3571, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 303, 'agent.time_step': 3581, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 304, 'agent.time_step': 3588, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 305, 'agent.time_step': 3595, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 306, 'agent.time_step': 3602, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 307, 'agent.time_step': 3610, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 308, 'agent.time_step': 3624, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 309, 'agent.time_step': 3635, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 310, 'agent.time_step': 3645, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "(q_current, q_targets): (tensor([[0.3492],\n",
      "        [0.3570],\n",
      "        [0.4059],\n",
      "        [0.3149],\n",
      "        [0.3418],\n",
      "        [0.3446],\n",
      "        [0.3685],\n",
      "        [0.3543],\n",
      "        [0.3432],\n",
      "        [0.3541],\n",
      "        [0.2827],\n",
      "        [0.3182],\n",
      "        [0.3704],\n",
      "        [0.3559],\n",
      "        [0.3539],\n",
      "        [0.3417],\n",
      "        [0.3928],\n",
      "        [0.3399],\n",
      "        [0.3319],\n",
      "        [0.4052],\n",
      "        [0.3604],\n",
      "        [0.3541],\n",
      "        [0.4447],\n",
      "        [0.3540],\n",
      "        [0.3714],\n",
      "        [0.3537],\n",
      "        [0.3537],\n",
      "        [0.3689],\n",
      "        [0.3530],\n",
      "        [0.3540],\n",
      "        [0.3541],\n",
      "        [0.3384],\n",
      "        [0.4069],\n",
      "        [0.3390],\n",
      "        [0.3538],\n",
      "        [0.3370],\n",
      "        [0.3083],\n",
      "        [0.3506],\n",
      "        [0.3537],\n",
      "        [0.3537],\n",
      "        [0.3385],\n",
      "        [0.4046],\n",
      "        [0.3540],\n",
      "        [0.3756],\n",
      "        [0.3793],\n",
      "        [0.3204],\n",
      "        [0.3543],\n",
      "        [0.3196],\n",
      "        [0.3811],\n",
      "        [0.3678],\n",
      "        [0.3543],\n",
      "        [0.3598],\n",
      "        [0.3571],\n",
      "        [0.4071],\n",
      "        [0.3841],\n",
      "        [0.3541],\n",
      "        [0.3301],\n",
      "        [0.3932],\n",
      "        [0.3548],\n",
      "        [0.3491],\n",
      "        [0.3853],\n",
      "        [0.4030],\n",
      "        [0.3559],\n",
      "        [0.2806]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.5541],\n",
      "        [ 0.5823],\n",
      "        [ 0.5871],\n",
      "        [ 0.5655],\n",
      "        [-1.0000],\n",
      "        [ 0.5697],\n",
      "        [ 0.5870],\n",
      "        [ 0.5763],\n",
      "        [ 0.5900],\n",
      "        [ 0.5528],\n",
      "        [ 0.5710],\n",
      "        [-1.0000],\n",
      "        [ 0.5758],\n",
      "        [ 0.6072],\n",
      "        [ 0.6050],\n",
      "        [-1.0000],\n",
      "        [ 0.5795],\n",
      "        [ 0.5563],\n",
      "        [ 0.5595],\n",
      "        [ 0.5581],\n",
      "        [ 0.5629],\n",
      "        [ 0.5582],\n",
      "        [ 0.5721],\n",
      "        [ 0.5740],\n",
      "        [ 0.5764],\n",
      "        [ 0.5660],\n",
      "        [ 0.5526],\n",
      "        [ 0.5820],\n",
      "        [ 0.5660],\n",
      "        [ 0.5567],\n",
      "        [ 0.5616],\n",
      "        [ 0.5861],\n",
      "        [ 0.5561],\n",
      "        [ 0.5568],\n",
      "        [ 0.5646],\n",
      "        [ 0.5561],\n",
      "        [-1.0000],\n",
      "        [ 0.5685],\n",
      "        [ 0.5525],\n",
      "        [ 0.5764],\n",
      "        [-1.0000],\n",
      "        [ 0.5889],\n",
      "        [ 0.5679],\n",
      "        [ 0.5537],\n",
      "        [ 0.5646],\n",
      "        [ 0.5912],\n",
      "        [ 0.5900],\n",
      "        [ 0.5738],\n",
      "        [ 0.5846],\n",
      "        [ 0.5616],\n",
      "        [ 0.5805],\n",
      "        [ 0.5795],\n",
      "        [ 0.5816],\n",
      "        [ 0.5954],\n",
      "        [ 0.5496],\n",
      "        [ 0.5569],\n",
      "        [ 0.5706],\n",
      "        [ 0.5639],\n",
      "        [ 0.5787],\n",
      "        [ 0.5771],\n",
      "        [ 0.5844],\n",
      "        [ 0.5681],\n",
      "        [ 0.5665],\n",
      "        [ 0.5559]], device='cuda:0'))\n",
      "{'loss': tensor(0.0859, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 311, 'agent.time_step': 3652, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 312, 'agent.time_step': 3662, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 313, 'agent.time_step': 3670, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 314, 'agent.time_step': 3678, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 315, 'agent.time_step': 3691, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 316, 'agent.time_step': 3703, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 317, 'agent.time_step': 3710, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 318, 'agent.time_step': 3725, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 319, 'agent.time_step': 3738, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 320, 'agent.time_step': 3752, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "(q_current, q_targets): (tensor([[0.3646],\n",
      "        [0.3993],\n",
      "        [0.3732],\n",
      "        [0.3629],\n",
      "        [0.3605],\n",
      "        [0.5004],\n",
      "        [0.3695],\n",
      "        [0.3298],\n",
      "        [0.3610],\n",
      "        [0.4212],\n",
      "        [0.4014],\n",
      "        [0.3845],\n",
      "        [0.3738],\n",
      "        [0.3426],\n",
      "        [0.3683],\n",
      "        [0.3936],\n",
      "        [0.3701],\n",
      "        [0.3656],\n",
      "        [0.3585],\n",
      "        [0.2951],\n",
      "        [0.3627],\n",
      "        [0.3546],\n",
      "        [0.3825],\n",
      "        [0.3619],\n",
      "        [0.3652],\n",
      "        [0.3646],\n",
      "        [0.3852],\n",
      "        [0.3837],\n",
      "        [0.2697],\n",
      "        [0.3912],\n",
      "        [0.3796],\n",
      "        [0.3714],\n",
      "        [0.2786],\n",
      "        [0.4128],\n",
      "        [0.3605],\n",
      "        [0.2629],\n",
      "        [0.4443],\n",
      "        [0.4018],\n",
      "        [0.3038],\n",
      "        [0.3631],\n",
      "        [0.3622],\n",
      "        [0.3409],\n",
      "        [0.4212],\n",
      "        [0.3627],\n",
      "        [0.3954],\n",
      "        [0.3627],\n",
      "        [0.3664],\n",
      "        [0.3763],\n",
      "        [0.3726],\n",
      "        [0.3919],\n",
      "        [0.3633],\n",
      "        [0.3846],\n",
      "        [0.3712],\n",
      "        [0.3463],\n",
      "        [0.3623],\n",
      "        [0.3605],\n",
      "        [0.4177],\n",
      "        [0.3636],\n",
      "        [0.3742],\n",
      "        [0.2404],\n",
      "        [0.3627],\n",
      "        [0.3776],\n",
      "        [0.3514],\n",
      "        [0.3627]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.5515],\n",
      "        [ 0.5661],\n",
      "        [ 0.5762],\n",
      "        [ 0.5778],\n",
      "        [ 0.5770],\n",
      "        [ 0.5910],\n",
      "        [ 0.5868],\n",
      "        [-1.0000],\n",
      "        [ 0.5843],\n",
      "        [ 0.6017],\n",
      "        [ 0.5628],\n",
      "        [-1.0000],\n",
      "        [ 0.5617],\n",
      "        [ 0.5884],\n",
      "        [ 0.5686],\n",
      "        [ 0.5957],\n",
      "        [ 0.5825],\n",
      "        [ 0.5772],\n",
      "        [ 0.5829],\n",
      "        [-1.0000],\n",
      "        [ 0.5763],\n",
      "        [ 0.5603],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.5515],\n",
      "        [ 0.5831],\n",
      "        [ 0.5764],\n",
      "        [ 0.5888],\n",
      "        [ 0.5585],\n",
      "        [ 0.5678],\n",
      "        [ 0.5788],\n",
      "        [-1.0000],\n",
      "        [ 0.5581],\n",
      "        [ 0.5776],\n",
      "        [ 0.5968],\n",
      "        [ 0.5809],\n",
      "        [ 0.5975],\n",
      "        [-1.0000],\n",
      "        [ 0.5672],\n",
      "        [ 0.5890],\n",
      "        [ 0.9261],\n",
      "        [ 0.5976],\n",
      "        [ 0.5700],\n",
      "        [ 0.5792],\n",
      "        [ 0.5568],\n",
      "        [ 0.5637],\n",
      "        [ 0.5797],\n",
      "        [ 0.5783],\n",
      "        [ 0.5817],\n",
      "        [ 0.5917],\n",
      "        [ 0.5883],\n",
      "        [ 0.5677],\n",
      "        [ 0.6035],\n",
      "        [ 0.5751],\n",
      "        [ 0.6023],\n",
      "        [ 0.5809],\n",
      "        [ 0.5882],\n",
      "        [ 0.5771],\n",
      "        [ 0.5696],\n",
      "        [ 0.5584],\n",
      "        [ 0.5461],\n",
      "        [ 0.5788],\n",
      "        [ 0.5539]], device='cuda:0'))\n",
      "{'loss': tensor(0.1262, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 321, 'agent.time_step': 3761, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 322, 'agent.time_step': 3775, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 323, 'agent.time_step': 3787, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 324, 'agent.time_step': 3794, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 325, 'agent.time_step': 3805, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 326, 'agent.time_step': 3817, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 327, 'agent.time_step': 3826, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 328, 'agent.time_step': 3836, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 329, 'agent.time_step': 3846, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 330, 'agent.time_step': 3858, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "(q_current, q_targets): (tensor([[0.3655],\n",
      "        [0.3697],\n",
      "        [0.3975],\n",
      "        [0.4075],\n",
      "        [0.2793],\n",
      "        [0.2311],\n",
      "        [0.3998],\n",
      "        [0.3979],\n",
      "        [0.4118],\n",
      "        [0.3875],\n",
      "        [0.3981],\n",
      "        [0.3977],\n",
      "        [0.4591],\n",
      "        [0.4033],\n",
      "        [0.3977],\n",
      "        [0.3409],\n",
      "        [0.3703],\n",
      "        [0.4328],\n",
      "        [0.3977],\n",
      "        [0.3975],\n",
      "        [0.4297],\n",
      "        [0.4001],\n",
      "        [0.3600],\n",
      "        [0.4280],\n",
      "        [0.3761],\n",
      "        [0.3981],\n",
      "        [0.2946],\n",
      "        [0.3697],\n",
      "        [0.3970],\n",
      "        [0.3956],\n",
      "        [0.4433],\n",
      "        [0.2783],\n",
      "        [0.3677],\n",
      "        [0.3979],\n",
      "        [0.4318],\n",
      "        [0.4183],\n",
      "        [0.4287],\n",
      "        [0.3877],\n",
      "        [0.3968],\n",
      "        [0.4045],\n",
      "        [0.3662],\n",
      "        [0.4015],\n",
      "        [0.4199],\n",
      "        [0.3847],\n",
      "        [0.4021],\n",
      "        [0.3975],\n",
      "        [0.3912],\n",
      "        [0.4032],\n",
      "        [0.3903],\n",
      "        [0.3525],\n",
      "        [0.4015],\n",
      "        [0.3661],\n",
      "        [0.3890],\n",
      "        [0.4310],\n",
      "        [0.3753],\n",
      "        [0.3546],\n",
      "        [0.4075],\n",
      "        [0.3981],\n",
      "        [0.3747],\n",
      "        [0.3773],\n",
      "        [0.3963],\n",
      "        [0.4374],\n",
      "        [0.4528],\n",
      "        [0.3944]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.5694],\n",
      "        [ 0.5691],\n",
      "        [ 0.5794],\n",
      "        [ 0.5614],\n",
      "        [-1.0000],\n",
      "        [ 0.5879],\n",
      "        [ 0.5578],\n",
      "        [ 0.6158],\n",
      "        [ 0.5892],\n",
      "        [ 0.5888],\n",
      "        [ 0.5781],\n",
      "        [ 0.5570],\n",
      "        [ 0.5987],\n",
      "        [ 0.5884],\n",
      "        [ 0.5711],\n",
      "        [ 0.5758],\n",
      "        [ 0.5729],\n",
      "        [ 0.5666],\n",
      "        [ 0.5694],\n",
      "        [ 0.5796],\n",
      "        [ 0.5879],\n",
      "        [ 0.5768],\n",
      "        [ 0.5827],\n",
      "        [ 0.5814],\n",
      "        [ 0.5757],\n",
      "        [ 0.5782],\n",
      "        [ 0.5976],\n",
      "        [ 0.5725],\n",
      "        [ 0.5770],\n",
      "        [ 0.5741],\n",
      "        [ 0.5930],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.6156],\n",
      "        [ 0.5839],\n",
      "        [ 0.5903],\n",
      "        [ 0.5582],\n",
      "        [ 0.5747],\n",
      "        [ 0.5836],\n",
      "        [-1.0000],\n",
      "        [ 0.5935],\n",
      "        [ 0.9495],\n",
      "        [ 0.5706],\n",
      "        [-1.0000],\n",
      "        [ 0.5994],\n",
      "        [ 0.6096],\n",
      "        [-1.0000],\n",
      "        [ 0.5894],\n",
      "        [ 0.5848],\n",
      "        [ 0.5810],\n",
      "        [ 0.6028],\n",
      "        [ 0.5839],\n",
      "        [ 0.5687],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.5852],\n",
      "        [ 0.5767],\n",
      "        [ 0.5823],\n",
      "        [ 0.5643],\n",
      "        [ 0.5959],\n",
      "        [ 0.5877],\n",
      "        [ 0.5913],\n",
      "        [ 0.5830],\n",
      "        [ 0.5784]], device='cuda:0'))\n",
      "{'loss': tensor(0.1264, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 331, 'agent.time_step': 3866, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 332, 'agent.time_step': 3881, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 333, 'agent.time_step': 3892, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 334, 'agent.time_step': 3902, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 335, 'agent.time_step': 3909, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 336, 'agent.time_step': 3921, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 337, 'agent.time_step': 3931, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 338, 'agent.time_step': 3941, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 339, 'agent.time_step': 3947, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 340, 'agent.time_step': 3964, 'rounds': 17, 'accumulate_reward': 15.0}\n",
      "(q_current, q_targets): (tensor([[0.4647],\n",
      "        [0.4555],\n",
      "        [0.4311],\n",
      "        [0.3939],\n",
      "        [0.4300],\n",
      "        [0.5035],\n",
      "        [0.5020],\n",
      "        [0.4424],\n",
      "        [0.4572],\n",
      "        [0.4546],\n",
      "        [0.4541],\n",
      "        [0.4658],\n",
      "        [0.4253],\n",
      "        [0.4690],\n",
      "        [0.4539],\n",
      "        [0.4596],\n",
      "        [0.4254],\n",
      "        [0.4471],\n",
      "        [0.4542],\n",
      "        [0.4539],\n",
      "        [0.4679],\n",
      "        [0.4358],\n",
      "        [0.4491],\n",
      "        [0.4550],\n",
      "        [0.5112],\n",
      "        [0.4539],\n",
      "        [0.4485],\n",
      "        [0.4992],\n",
      "        [0.4983],\n",
      "        [0.4646],\n",
      "        [0.4539],\n",
      "        [0.4944],\n",
      "        [0.4313],\n",
      "        [0.3333],\n",
      "        [0.4539],\n",
      "        [0.5299],\n",
      "        [0.4341],\n",
      "        [0.4988],\n",
      "        [0.4478],\n",
      "        [0.4600],\n",
      "        [0.4433],\n",
      "        [0.5087],\n",
      "        [0.3858],\n",
      "        [0.4547],\n",
      "        [0.4527],\n",
      "        [0.4959],\n",
      "        [0.4306],\n",
      "        [0.4532],\n",
      "        [0.5373],\n",
      "        [0.3777],\n",
      "        [0.4540],\n",
      "        [0.4559],\n",
      "        [0.4601],\n",
      "        [0.4413],\n",
      "        [0.4462],\n",
      "        [0.4549],\n",
      "        [0.4245],\n",
      "        [0.5508],\n",
      "        [0.3834],\n",
      "        [0.5391],\n",
      "        [0.4480],\n",
      "        [0.4539],\n",
      "        [0.5045],\n",
      "        [0.4714]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.5660],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.5962],\n",
      "        [ 0.6005],\n",
      "        [ 0.5664],\n",
      "        [ 0.5803],\n",
      "        [ 0.5960],\n",
      "        [ 0.5871],\n",
      "        [ 0.5796],\n",
      "        [ 0.5876],\n",
      "        [ 0.5845],\n",
      "        [ 0.5697],\n",
      "        [ 0.5522],\n",
      "        [ 0.5866],\n",
      "        [-1.0000],\n",
      "        [ 0.5894],\n",
      "        [ 0.5564],\n",
      "        [ 0.5700],\n",
      "        [ 0.5925],\n",
      "        [ 0.5948],\n",
      "        [ 0.5633],\n",
      "        [ 0.9273],\n",
      "        [ 0.5706],\n",
      "        [ 0.5645],\n",
      "        [ 0.5542],\n",
      "        [ 0.5877],\n",
      "        [ 0.5814],\n",
      "        [ 0.5580],\n",
      "        [ 0.5770],\n",
      "        [ 0.5545],\n",
      "        [ 0.5844],\n",
      "        [ 0.5958],\n",
      "        [ 0.5625],\n",
      "        [ 0.5871],\n",
      "        [ 0.5793],\n",
      "        [ 0.5570],\n",
      "        [ 0.5858],\n",
      "        [ 0.5838],\n",
      "        [ 0.5793],\n",
      "        [ 0.5964],\n",
      "        [ 0.6050],\n",
      "        [ 0.5612],\n",
      "        [ 0.5915],\n",
      "        [-1.0000],\n",
      "        [ 0.5698],\n",
      "        [ 0.5901],\n",
      "        [ 0.5941],\n",
      "        [-1.0000],\n",
      "        [ 0.5911],\n",
      "        [ 0.5471],\n",
      "        [ 0.5793],\n",
      "        [ 0.5888],\n",
      "        [ 0.5845],\n",
      "        [ 0.5695],\n",
      "        [ 0.5847],\n",
      "        [ 0.5655],\n",
      "        [ 0.5884],\n",
      "        [ 0.5847],\n",
      "        [ 0.6013],\n",
      "        [ 0.5648],\n",
      "        [ 0.5924],\n",
      "        [ 0.5669]], device='cuda:0'))\n",
      "{'loss': tensor(0.0959, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 341, 'agent.time_step': 3973, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 342, 'agent.time_step': 3984, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 343, 'agent.time_step': 3992, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 344, 'agent.time_step': 4001, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 345, 'agent.time_step': 4013, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 346, 'agent.time_step': 4026, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 347, 'agent.time_step': 4036, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 348, 'agent.time_step': 4048, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 349, 'agent.time_step': 4057, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 350, 'agent.time_step': 4067, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "(q_current, q_targets): (tensor([[0.5233],\n",
      "        [0.5278],\n",
      "        [0.4992],\n",
      "        [0.5107],\n",
      "        [0.4881],\n",
      "        [0.5101],\n",
      "        [0.5200],\n",
      "        [0.4837],\n",
      "        [0.5808],\n",
      "        [0.5206],\n",
      "        [0.5198],\n",
      "        [0.5005],\n",
      "        [0.5157],\n",
      "        [0.3193],\n",
      "        [0.5137],\n",
      "        [0.5164],\n",
      "        [0.5200],\n",
      "        [0.5347],\n",
      "        [0.5200],\n",
      "        [0.5555],\n",
      "        [0.5201],\n",
      "        [0.3493],\n",
      "        [0.5889],\n",
      "        [0.5248],\n",
      "        [0.4957],\n",
      "        [0.5362],\n",
      "        [0.4857],\n",
      "        [0.5260],\n",
      "        [0.5200],\n",
      "        [0.5139],\n",
      "        [0.4771],\n",
      "        [0.5266],\n",
      "        [0.3383],\n",
      "        [0.5126],\n",
      "        [0.5201],\n",
      "        [0.5006],\n",
      "        [0.5401],\n",
      "        [0.5710],\n",
      "        [0.4537],\n",
      "        [0.5066],\n",
      "        [0.5200],\n",
      "        [0.4987],\n",
      "        [0.5585],\n",
      "        [0.5198],\n",
      "        [0.5057],\n",
      "        [0.6043],\n",
      "        [0.5347],\n",
      "        [0.3043],\n",
      "        [0.5808],\n",
      "        [0.4858],\n",
      "        [0.4969],\n",
      "        [0.5874],\n",
      "        [0.5269],\n",
      "        [0.5062],\n",
      "        [0.5200],\n",
      "        [0.5158],\n",
      "        [0.5702],\n",
      "        [0.5055],\n",
      "        [0.3537],\n",
      "        [0.5612],\n",
      "        [0.5581],\n",
      "        [0.3843],\n",
      "        [0.3421],\n",
      "        [0.5217]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.9445],\n",
      "        [ 0.5571],\n",
      "        [-1.0000],\n",
      "        [ 0.5641],\n",
      "        [ 0.5888],\n",
      "        [ 0.5822],\n",
      "        [ 0.6073],\n",
      "        [-1.0000],\n",
      "        [ 0.5913],\n",
      "        [ 0.5906],\n",
      "        [ 0.5873],\n",
      "        [ 0.9419],\n",
      "        [ 0.9230],\n",
      "        [ 0.9297],\n",
      "        [-1.0000],\n",
      "        [ 0.9270],\n",
      "        [ 0.5766],\n",
      "        [ 0.5591],\n",
      "        [ 0.6057],\n",
      "        [ 0.5757],\n",
      "        [ 0.5657],\n",
      "        [ 0.5910],\n",
      "        [ 0.5899],\n",
      "        [ 0.5717],\n",
      "        [ 0.5828],\n",
      "        [ 0.5626],\n",
      "        [ 0.6028],\n",
      "        [ 0.9345],\n",
      "        [ 0.5540],\n",
      "        [ 0.5830],\n",
      "        [ 0.9435],\n",
      "        [ 0.5653],\n",
      "        [ 0.5804],\n",
      "        [ 0.6022],\n",
      "        [ 0.5668],\n",
      "        [ 0.6112],\n",
      "        [ 0.5629],\n",
      "        [ 0.9466],\n",
      "        [ 0.9374],\n",
      "        [ 0.5679],\n",
      "        [ 0.5572],\n",
      "        [ 0.5912],\n",
      "        [ 0.5837],\n",
      "        [ 0.5830],\n",
      "        [ 0.9341],\n",
      "        [ 0.6032],\n",
      "        [ 0.5620],\n",
      "        [ 0.5895],\n",
      "        [ 0.5900],\n",
      "        [ 0.5884],\n",
      "        [ 0.9302],\n",
      "        [ 0.5740],\n",
      "        [ 0.5722],\n",
      "        [ 0.5669],\n",
      "        [ 0.6062],\n",
      "        [ 0.9324],\n",
      "        [ 0.5745],\n",
      "        [ 0.5949],\n",
      "        [ 0.5722],\n",
      "        [ 0.5839],\n",
      "        [ 0.5821],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.6025]], device='cuda:0'))\n",
      "{'loss': tensor(0.0956, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 351, 'agent.time_step': 4074, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 352, 'agent.time_step': 4084, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 353, 'agent.time_step': 4096, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 354, 'agent.time_step': 4108, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 355, 'agent.time_step': 4117, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 356, 'agent.time_step': 4127, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 357, 'agent.time_step': 4142, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 358, 'agent.time_step': 4151, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 359, 'agent.time_step': 4159, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 360, 'agent.time_step': 4167, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[0.6284],\n",
      "        [0.7287],\n",
      "        [0.6479],\n",
      "        [0.6219],\n",
      "        [0.5868],\n",
      "        [0.6282],\n",
      "        [0.6054],\n",
      "        [0.4057],\n",
      "        [0.6219],\n",
      "        [0.7960],\n",
      "        [0.6207],\n",
      "        [0.4446],\n",
      "        [0.6606],\n",
      "        [0.6219],\n",
      "        [0.4071],\n",
      "        [0.6568],\n",
      "        [0.4724],\n",
      "        [0.6188],\n",
      "        [0.6117],\n",
      "        [0.6225],\n",
      "        [0.6122],\n",
      "        [0.6225],\n",
      "        [0.6103],\n",
      "        [0.6219],\n",
      "        [0.6154],\n",
      "        [0.5226],\n",
      "        [0.6230],\n",
      "        [0.6910],\n",
      "        [0.6219],\n",
      "        [0.6219],\n",
      "        [0.5892],\n",
      "        [0.4459],\n",
      "        [0.6912],\n",
      "        [0.6202],\n",
      "        [0.6596],\n",
      "        [0.3822],\n",
      "        [0.5908],\n",
      "        [0.6183],\n",
      "        [0.6219],\n",
      "        [0.6275],\n",
      "        [0.6207],\n",
      "        [0.4088],\n",
      "        [0.5863],\n",
      "        [0.7145],\n",
      "        [0.6044],\n",
      "        [0.6493],\n",
      "        [0.6065],\n",
      "        [0.6248],\n",
      "        [0.6207],\n",
      "        [0.6219],\n",
      "        [0.6201],\n",
      "        [0.6219],\n",
      "        [0.6224],\n",
      "        [0.5439],\n",
      "        [0.4542],\n",
      "        [0.6578],\n",
      "        [0.6219],\n",
      "        [0.6060],\n",
      "        [0.6062],\n",
      "        [0.6291],\n",
      "        [0.6219],\n",
      "        [0.6164],\n",
      "        [0.3829],\n",
      "        [0.5839]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[-1.0000],\n",
      "        [ 0.4784],\n",
      "        [ 0.5055],\n",
      "        [ 0.5079],\n",
      "        [-1.0000],\n",
      "        [ 0.5151],\n",
      "        [ 0.5005],\n",
      "        [ 0.5015],\n",
      "        [ 0.4615],\n",
      "        [ 0.5007],\n",
      "        [ 0.4854],\n",
      "        [-1.0000],\n",
      "        [ 0.4739],\n",
      "        [ 0.4851],\n",
      "        [ 0.5093],\n",
      "        [ 0.4615],\n",
      "        [-1.0000],\n",
      "        [ 0.8787],\n",
      "        [ 0.5197],\n",
      "        [ 0.5022],\n",
      "        [ 0.4853],\n",
      "        [ 0.5075],\n",
      "        [ 0.4867],\n",
      "        [ 0.5220],\n",
      "        [ 0.4772],\n",
      "        [ 0.5034],\n",
      "        [ 0.8610],\n",
      "        [ 0.5000],\n",
      "        [ 0.4959],\n",
      "        [ 0.5175],\n",
      "        [ 0.4930],\n",
      "        [-1.0000],\n",
      "        [ 0.5036],\n",
      "        [ 0.4859],\n",
      "        [ 0.4904],\n",
      "        [-1.0000],\n",
      "        [ 0.4982],\n",
      "        [ 0.4693],\n",
      "        [ 0.5265],\n",
      "        [ 0.8851],\n",
      "        [ 0.4791],\n",
      "        [-1.0000],\n",
      "        [ 0.8831],\n",
      "        [ 0.5057],\n",
      "        [ 0.5022],\n",
      "        [ 0.4742],\n",
      "        [ 0.5249],\n",
      "        [ 0.5158],\n",
      "        [ 0.4810],\n",
      "        [ 0.5142],\n",
      "        [ 0.4718],\n",
      "        [ 0.5200],\n",
      "        [ 0.5244],\n",
      "        [ 0.5002],\n",
      "        [ 0.4989],\n",
      "        [ 0.4596],\n",
      "        [ 0.4841],\n",
      "        [ 0.4934],\n",
      "        [ 0.8745],\n",
      "        [ 0.5164],\n",
      "        [ 0.5102],\n",
      "        [ 0.8705],\n",
      "        [ 0.4965],\n",
      "        [ 0.5170]], device='cuda:0'))\n",
      "{'loss': tensor(0.1181, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 361, 'agent.time_step': 4176, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 362, 'agent.time_step': 4184, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 363, 'agent.time_step': 4193, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 364, 'agent.time_step': 4204, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 365, 'agent.time_step': 4215, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 366, 'agent.time_step': 4228, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 367, 'agent.time_step': 4237, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 368, 'agent.time_step': 4250, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 369, 'agent.time_step': 4259, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 370, 'agent.time_step': 4267, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[0.5946],\n",
      "        [0.5924],\n",
      "        [0.5991],\n",
      "        [0.4460],\n",
      "        [0.6045],\n",
      "        [0.5299],\n",
      "        [0.4338],\n",
      "        [0.5044],\n",
      "        [0.5973],\n",
      "        [0.6732],\n",
      "        [0.5982],\n",
      "        [0.5987],\n",
      "        [0.4016],\n",
      "        [0.5990],\n",
      "        [0.5996],\n",
      "        [0.5530],\n",
      "        [0.5990],\n",
      "        [0.5669],\n",
      "        [0.5990],\n",
      "        [0.4897],\n",
      "        [0.5362],\n",
      "        [0.6184],\n",
      "        [0.5996],\n",
      "        [0.5898],\n",
      "        [0.6046],\n",
      "        [0.6786],\n",
      "        [0.6364],\n",
      "        [0.5990],\n",
      "        [0.5930],\n",
      "        [0.5996],\n",
      "        [0.5230],\n",
      "        [0.5990],\n",
      "        [0.5990],\n",
      "        [0.5932],\n",
      "        [0.5975],\n",
      "        [0.5990],\n",
      "        [0.6232],\n",
      "        [0.6602],\n",
      "        [0.6108],\n",
      "        [0.5528],\n",
      "        [0.5990],\n",
      "        [0.5465],\n",
      "        [0.5884],\n",
      "        [0.5990],\n",
      "        [0.5633],\n",
      "        [0.4774],\n",
      "        [0.6063],\n",
      "        [0.5996],\n",
      "        [0.6015],\n",
      "        [0.5840],\n",
      "        [0.3324],\n",
      "        [0.7343],\n",
      "        [0.5996],\n",
      "        [0.5991],\n",
      "        [0.6520],\n",
      "        [0.6827],\n",
      "        [0.7015],\n",
      "        [0.6842],\n",
      "        [0.5996],\n",
      "        [0.5833],\n",
      "        [0.5309],\n",
      "        [0.5774],\n",
      "        [0.6431],\n",
      "        [0.6682]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.4953],\n",
      "        [ 0.8761],\n",
      "        [ 0.4813],\n",
      "        [ 0.5065],\n",
      "        [-1.0000],\n",
      "        [ 0.8770],\n",
      "        [ 0.4968],\n",
      "        [ 0.4766],\n",
      "        [ 0.5003],\n",
      "        [ 0.5130],\n",
      "        [-1.0000],\n",
      "        [ 0.4781],\n",
      "        [ 0.4784],\n",
      "        [-1.0000],\n",
      "        [ 0.4819],\n",
      "        [ 0.5039],\n",
      "        [ 0.4837],\n",
      "        [-1.0000],\n",
      "        [ 0.5027],\n",
      "        [ 0.4779],\n",
      "        [ 0.4784],\n",
      "        [ 0.4812],\n",
      "        [ 0.5097],\n",
      "        [ 0.5062],\n",
      "        [ 0.4994],\n",
      "        [ 0.4641],\n",
      "        [-1.0000],\n",
      "        [ 0.4784],\n",
      "        [ 0.4796],\n",
      "        [ 0.4700],\n",
      "        [ 0.4824],\n",
      "        [ 0.5228],\n",
      "        [ 0.5163],\n",
      "        [ 0.4590],\n",
      "        [ 0.4760],\n",
      "        [ 0.4981],\n",
      "        [ 0.5059],\n",
      "        [ 0.5081],\n",
      "        [ 0.4996],\n",
      "        [ 0.4928],\n",
      "        [ 0.5024],\n",
      "        [ 0.4792],\n",
      "        [ 0.8705],\n",
      "        [ 0.4891],\n",
      "        [ 0.4744],\n",
      "        [ 0.5032],\n",
      "        [ 0.4976],\n",
      "        [ 0.4792],\n",
      "        [ 0.4961],\n",
      "        [ 0.4864],\n",
      "        [ 0.5028],\n",
      "        [ 0.4914],\n",
      "        [ 0.4739],\n",
      "        [ 0.4987],\n",
      "        [ 0.5061],\n",
      "        [ 0.4944],\n",
      "        [ 0.4998],\n",
      "        [ 0.4708],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.4903],\n",
      "        [ 0.5004]], device='cuda:0'))\n",
      "{'loss': tensor(0.1545, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 371, 'agent.time_step': 4279, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 372, 'agent.time_step': 4289, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 373, 'agent.time_step': 4298, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 374, 'agent.time_step': 4310, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 375, 'agent.time_step': 4318, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 376, 'agent.time_step': 4325, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 377, 'agent.time_step': 4335, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 378, 'agent.time_step': 4341, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 379, 'agent.time_step': 4352, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 380, 'agent.time_step': 4361, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "(q_current, q_targets): (tensor([[0.5080],\n",
      "        [0.4702],\n",
      "        [0.4576],\n",
      "        [0.4580],\n",
      "        [0.2302],\n",
      "        [0.4510],\n",
      "        [0.3852],\n",
      "        [0.3925],\n",
      "        [0.4659],\n",
      "        [0.4576],\n",
      "        [0.4370],\n",
      "        [0.4633],\n",
      "        [0.4451],\n",
      "        [0.2611],\n",
      "        [0.2592],\n",
      "        [0.3901],\n",
      "        [0.5549],\n",
      "        [0.4583],\n",
      "        [0.4001],\n",
      "        [0.4577],\n",
      "        [0.2865],\n",
      "        [0.4708],\n",
      "        [0.4581],\n",
      "        [0.5339],\n",
      "        [0.6839],\n",
      "        [0.4581],\n",
      "        [0.4906],\n",
      "        [0.4590],\n",
      "        [0.4483],\n",
      "        [0.3640],\n",
      "        [0.4583],\n",
      "        [0.4557],\n",
      "        [0.5460],\n",
      "        [0.3313],\n",
      "        [0.4583],\n",
      "        [0.4489],\n",
      "        [0.5074],\n",
      "        [0.3917],\n",
      "        [0.4559],\n",
      "        [0.4373],\n",
      "        [0.2217],\n",
      "        [0.3963],\n",
      "        [0.4947],\n",
      "        [0.5185],\n",
      "        [0.4568],\n",
      "        [0.4578],\n",
      "        [0.4404],\n",
      "        [0.3067],\n",
      "        [0.2153],\n",
      "        [0.4137],\n",
      "        [0.4583],\n",
      "        [0.4963],\n",
      "        [0.4654],\n",
      "        [0.5339],\n",
      "        [0.4967],\n",
      "        [0.4583],\n",
      "        [0.4404],\n",
      "        [0.4291],\n",
      "        [0.3325],\n",
      "        [0.5557],\n",
      "        [0.4576],\n",
      "        [0.4585],\n",
      "        [0.5027],\n",
      "        [0.3014]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.5090],\n",
      "        [ 0.8720],\n",
      "        [ 0.5132],\n",
      "        [ 0.4857],\n",
      "        [ 0.4944],\n",
      "        [ 0.4973],\n",
      "        [ 0.8837],\n",
      "        [ 0.8762],\n",
      "        [ 0.4767],\n",
      "        [ 0.4933],\n",
      "        [ 0.8767],\n",
      "        [ 0.8651],\n",
      "        [ 0.5020],\n",
      "        [-1.0000],\n",
      "        [ 0.5184],\n",
      "        [ 0.8788],\n",
      "        [ 0.4830],\n",
      "        [ 0.4974],\n",
      "        [ 0.8716],\n",
      "        [ 0.4799],\n",
      "        [-1.0000],\n",
      "        [ 0.4761],\n",
      "        [ 0.5136],\n",
      "        [ 0.5116],\n",
      "        [ 0.5083],\n",
      "        [ 0.5199],\n",
      "        [ 0.4599],\n",
      "        [ 0.4858],\n",
      "        [ 0.8723],\n",
      "        [ 0.8796],\n",
      "        [ 0.5002],\n",
      "        [ 0.4947],\n",
      "        [ 0.8836],\n",
      "        [-1.0000],\n",
      "        [ 0.5006],\n",
      "        [ 0.5034],\n",
      "        [ 0.4859],\n",
      "        [-1.0000],\n",
      "        [ 0.5005],\n",
      "        [-1.0000],\n",
      "        [ 0.8684],\n",
      "        [ 0.8730],\n",
      "        [ 0.4862],\n",
      "        [ 0.8784],\n",
      "        [ 0.4806],\n",
      "        [ 0.8768],\n",
      "        [ 0.4920],\n",
      "        [ 0.8739],\n",
      "        [ 0.8687],\n",
      "        [ 0.8818],\n",
      "        [ 0.4984],\n",
      "        [ 0.4808],\n",
      "        [ 0.4886],\n",
      "        [ 0.5026],\n",
      "        [ 0.4916],\n",
      "        [ 0.5009],\n",
      "        [-1.0000],\n",
      "        [ 0.8729],\n",
      "        [ 0.8641],\n",
      "        [ 0.4976],\n",
      "        [ 0.5193],\n",
      "        [ 0.4882],\n",
      "        [ 0.5019],\n",
      "        [ 0.5108]], device='cuda:0'))\n",
      "{'loss': tensor(0.1170, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 381, 'agent.time_step': 4386, 'rounds': 25, 'accumulate_reward': 23.0}\n",
      "{'episode': 382, 'agent.time_step': 4405, 'rounds': 19, 'accumulate_reward': 17.0}\n",
      "{'episode': 383, 'agent.time_step': 4414, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 384, 'agent.time_step': 4428, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 385, 'agent.time_step': 4450, 'rounds': 22, 'accumulate_reward': 20.0}\n",
      "{'episode': 386, 'agent.time_step': 4480, 'rounds': 30, 'accumulate_reward': 28.0}\n",
      "{'episode': 387, 'agent.time_step': 4487, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 388, 'agent.time_step': 4492, 'rounds': 5, 'accumulate_reward': 3.0}\n",
      "{'episode': 389, 'agent.time_step': 4518, 'rounds': 26, 'accumulate_reward': 24.0}\n",
      "{'episode': 390, 'agent.time_step': 4531, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "(q_current, q_targets): (tensor([[0.3826],\n",
      "        [0.3990],\n",
      "        [0.3817],\n",
      "        [0.7091],\n",
      "        [0.3760],\n",
      "        [0.1968],\n",
      "        [0.4126],\n",
      "        [0.3739],\n",
      "        [0.3774],\n",
      "        [0.3826],\n",
      "        [0.3818],\n",
      "        [0.5322],\n",
      "        [0.3776],\n",
      "        [0.4627],\n",
      "        [0.3817],\n",
      "        [0.3504],\n",
      "        [0.3784],\n",
      "        [0.3711],\n",
      "        [0.3821],\n",
      "        [0.2363],\n",
      "        [0.3888],\n",
      "        [0.3682],\n",
      "        [0.4228],\n",
      "        [0.3818],\n",
      "        [0.3426],\n",
      "        [0.3724],\n",
      "        [0.3281],\n",
      "        [0.3402],\n",
      "        [0.1509],\n",
      "        [0.3817],\n",
      "        [0.3818],\n",
      "        [0.3802],\n",
      "        [0.3813],\n",
      "        [0.6410],\n",
      "        [0.3822],\n",
      "        [0.3684],\n",
      "        [0.1532],\n",
      "        [0.3461],\n",
      "        [0.3408],\n",
      "        [0.3818],\n",
      "        [0.3622],\n",
      "        [0.3351],\n",
      "        [0.2691],\n",
      "        [0.3817],\n",
      "        [0.3821],\n",
      "        [0.4252],\n",
      "        [0.3744],\n",
      "        [0.3818],\n",
      "        [0.1455],\n",
      "        [0.1472],\n",
      "        [0.3667],\n",
      "        [0.4555],\n",
      "        [0.3816],\n",
      "        [0.6180],\n",
      "        [0.1409],\n",
      "        [0.3693],\n",
      "        [0.2736],\n",
      "        [0.3561],\n",
      "        [0.3753],\n",
      "        [0.4816],\n",
      "        [0.3854],\n",
      "        [0.3547],\n",
      "        [0.3832],\n",
      "        [0.3763]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8781],\n",
      "        [ 0.8662],\n",
      "        [ 0.8817],\n",
      "        [ 0.8536],\n",
      "        [ 0.5005],\n",
      "        [ 0.8675],\n",
      "        [ 0.8531],\n",
      "        [ 0.8851],\n",
      "        [-1.0000],\n",
      "        [ 0.8627],\n",
      "        [ 0.8653],\n",
      "        [ 0.4740],\n",
      "        [ 0.8689],\n",
      "        [ 0.4880],\n",
      "        [ 0.8347],\n",
      "        [ 0.8530],\n",
      "        [ 0.8730],\n",
      "        [ 0.8879],\n",
      "        [ 0.8656],\n",
      "        [ 0.8591],\n",
      "        [ 0.8773],\n",
      "        [ 0.8793],\n",
      "        [ 0.8602],\n",
      "        [ 0.8929],\n",
      "        [ 0.8827],\n",
      "        [ 0.8566],\n",
      "        [ 0.8782],\n",
      "        [ 0.8808],\n",
      "        [ 0.8327],\n",
      "        [ 0.4748],\n",
      "        [ 0.5197],\n",
      "        [ 0.8412],\n",
      "        [ 0.8434],\n",
      "        [-1.0000],\n",
      "        [ 0.8553],\n",
      "        [ 0.8547],\n",
      "        [ 0.8527],\n",
      "        [ 0.8550],\n",
      "        [ 0.8810],\n",
      "        [ 0.5110],\n",
      "        [ 0.8906],\n",
      "        [ 0.8784],\n",
      "        [ 0.8442],\n",
      "        [ 0.8793],\n",
      "        [ 0.8655],\n",
      "        [ 0.5114],\n",
      "        [ 0.8559],\n",
      "        [ 0.8633],\n",
      "        [ 0.8497],\n",
      "        [ 0.8663],\n",
      "        [ 0.5109],\n",
      "        [ 0.8698],\n",
      "        [ 0.5142],\n",
      "        [ 0.8910],\n",
      "        [ 0.8483],\n",
      "        [ 0.4803],\n",
      "        [ 0.8547],\n",
      "        [ 0.5076],\n",
      "        [ 0.8688],\n",
      "        [ 0.8794],\n",
      "        [ 0.4854],\n",
      "        [ 0.8682],\n",
      "        [ 0.8879],\n",
      "        [ 0.8570]], device='cuda:0'))\n",
      "{'loss': tensor(0.1382, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 391, 'agent.time_step': 4540, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 392, 'agent.time_step': 4548, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 393, 'agent.time_step': 4565, 'rounds': 17, 'accumulate_reward': 15.0}\n",
      "{'episode': 394, 'agent.time_step': 4572, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 395, 'agent.time_step': 4587, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 396, 'agent.time_step': 4601, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 397, 'agent.time_step': 4614, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 398, 'agent.time_step': 4622, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 399, 'agent.time_step': 4640, 'rounds': 18, 'accumulate_reward': 16.0}\n",
      "{'episode': 400, 'agent.time_step': 4652, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "(q_current, q_targets): (tensor([[0.4468],\n",
      "        [0.4423],\n",
      "        [0.4472],\n",
      "        [0.4006],\n",
      "        [0.3639],\n",
      "        [0.4422],\n",
      "        [0.5269],\n",
      "        [0.4328],\n",
      "        [0.3762],\n",
      "        [0.5191],\n",
      "        [0.4387],\n",
      "        [0.4465],\n",
      "        [0.4464],\n",
      "        [0.4465],\n",
      "        [0.4468],\n",
      "        [0.4299],\n",
      "        [0.4696],\n",
      "        [0.4452],\n",
      "        [0.4623],\n",
      "        [0.4473],\n",
      "        [0.1758],\n",
      "        [0.3522],\n",
      "        [0.4464],\n",
      "        [0.4438],\n",
      "        [0.4465],\n",
      "        [0.4366],\n",
      "        [0.4177],\n",
      "        [0.6506],\n",
      "        [0.4352],\n",
      "        [0.6227],\n",
      "        [0.4468],\n",
      "        [0.4473],\n",
      "        [0.4796],\n",
      "        [0.4726],\n",
      "        [0.3703],\n",
      "        [0.4032],\n",
      "        [0.4466],\n",
      "        [0.4411],\n",
      "        [0.6727],\n",
      "        [0.4502],\n",
      "        [0.4574],\n",
      "        [0.4473],\n",
      "        [0.4447],\n",
      "        [0.5234],\n",
      "        [0.6506],\n",
      "        [0.4847],\n",
      "        [0.4468],\n",
      "        [0.4669],\n",
      "        [0.6280],\n",
      "        [0.4499],\n",
      "        [0.4231],\n",
      "        [0.4194],\n",
      "        [0.4473],\n",
      "        [0.4574],\n",
      "        [0.4467],\n",
      "        [0.4319],\n",
      "        [0.4467],\n",
      "        [0.4381],\n",
      "        [0.4460],\n",
      "        [0.3642],\n",
      "        [0.6007],\n",
      "        [0.4470],\n",
      "        [0.4484],\n",
      "        [0.4470]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8648],\n",
      "        [ 0.8743],\n",
      "        [ 0.8546],\n",
      "        [ 0.8801],\n",
      "        [ 0.8637],\n",
      "        [ 0.4758],\n",
      "        [ 0.8800],\n",
      "        [ 0.8994],\n",
      "        [ 0.8748],\n",
      "        [ 0.8766],\n",
      "        [ 0.4751],\n",
      "        [ 0.8807],\n",
      "        [ 0.8739],\n",
      "        [ 0.8831],\n",
      "        [ 0.8775],\n",
      "        [ 0.8831],\n",
      "        [ 0.8860],\n",
      "        [-1.0000],\n",
      "        [ 0.4928],\n",
      "        [ 0.8845],\n",
      "        [ 0.8527],\n",
      "        [ 0.8731],\n",
      "        [ 0.8785],\n",
      "        [ 0.8884],\n",
      "        [ 0.8803],\n",
      "        [ 0.4820],\n",
      "        [ 0.8776],\n",
      "        [ 0.8722],\n",
      "        [ 0.4983],\n",
      "        [ 0.8811],\n",
      "        [-1.0000],\n",
      "        [ 0.8839],\n",
      "        [ 0.4925],\n",
      "        [ 0.4872],\n",
      "        [ 0.8715],\n",
      "        [ 0.8913],\n",
      "        [ 0.8839],\n",
      "        [ 0.8713],\n",
      "        [ 0.8811],\n",
      "        [ 0.8804],\n",
      "        [ 0.8676],\n",
      "        [ 0.8808],\n",
      "        [ 0.8778],\n",
      "        [ 0.8859],\n",
      "        [ 0.8717],\n",
      "        [ 0.8871],\n",
      "        [ 0.8771],\n",
      "        [ 0.5060],\n",
      "        [ 0.8800],\n",
      "        [ 0.8712],\n",
      "        [ 0.4931],\n",
      "        [ 0.8870],\n",
      "        [ 0.8845],\n",
      "        [ 0.8834],\n",
      "        [ 0.8916],\n",
      "        [ 0.4856],\n",
      "        [ 0.8735],\n",
      "        [-1.0000],\n",
      "        [ 0.8837],\n",
      "        [-1.0000],\n",
      "        [ 0.8837],\n",
      "        [ 0.8773],\n",
      "        [ 0.8837],\n",
      "        [ 0.8910]], device='cuda:0'))\n",
      "{'loss': tensor(0.1288, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "400 9.05\n",
      "{'episode': 401, 'agent.time_step': 4664, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 402, 'agent.time_step': 4671, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 403, 'agent.time_step': 4681, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 404, 'agent.time_step': 4689, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 405, 'agent.time_step': 4700, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 406, 'agent.time_step': 4711, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 407, 'agent.time_step': 4721, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 408, 'agent.time_step': 4730, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 409, 'agent.time_step': 4738, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 410, 'agent.time_step': 4750, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "(q_current, q_targets): (tensor([[0.6371],\n",
      "        [0.6909],\n",
      "        [0.6789],\n",
      "        [0.6654],\n",
      "        [0.6420],\n",
      "        [0.6531],\n",
      "        [0.6669],\n",
      "        [0.6071],\n",
      "        [0.6708],\n",
      "        [0.6618],\n",
      "        [0.6654],\n",
      "        [0.6654],\n",
      "        [0.7455],\n",
      "        [0.6654],\n",
      "        [0.5812],\n",
      "        [0.7390],\n",
      "        [0.6650],\n",
      "        [0.6518],\n",
      "        [0.4030],\n",
      "        [0.6665],\n",
      "        [0.6338],\n",
      "        [0.6655],\n",
      "        [0.6624],\n",
      "        [0.8579],\n",
      "        [0.6574],\n",
      "        [0.6665],\n",
      "        [0.2312],\n",
      "        [0.6845],\n",
      "        [0.6662],\n",
      "        [0.6684],\n",
      "        [0.6762],\n",
      "        [0.6665],\n",
      "        [0.6490],\n",
      "        [0.6278],\n",
      "        [0.6654],\n",
      "        [0.5505],\n",
      "        [0.6432],\n",
      "        [0.7901],\n",
      "        [0.5624],\n",
      "        [0.6756],\n",
      "        [0.2266],\n",
      "        [0.6662],\n",
      "        [0.3930],\n",
      "        [0.6655],\n",
      "        [0.6654],\n",
      "        [0.6610],\n",
      "        [0.6640],\n",
      "        [0.6647],\n",
      "        [0.6640],\n",
      "        [0.7168],\n",
      "        [0.6654],\n",
      "        [0.7232],\n",
      "        [0.6654],\n",
      "        [0.6757],\n",
      "        [0.6353],\n",
      "        [0.6660],\n",
      "        [0.8156],\n",
      "        [0.6623],\n",
      "        [0.7901],\n",
      "        [0.6654],\n",
      "        [0.6654],\n",
      "        [0.6845],\n",
      "        [0.6655],\n",
      "        [0.6640]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8342],\n",
      "        [ 0.8243],\n",
      "        [ 0.8232],\n",
      "        [ 0.8367],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.8048],\n",
      "        [ 0.8197],\n",
      "        [ 0.8260],\n",
      "        [ 0.8228],\n",
      "        [ 0.8206],\n",
      "        [ 0.8280],\n",
      "        [ 0.8423],\n",
      "        [ 0.8099],\n",
      "        [ 0.8187],\n",
      "        [ 0.8216],\n",
      "        [ 0.8299],\n",
      "        [ 0.8052],\n",
      "        [ 0.8278],\n",
      "        [-1.0000],\n",
      "        [ 0.8321],\n",
      "        [ 0.8204],\n",
      "        [ 0.8220],\n",
      "        [ 0.8152],\n",
      "        [ 0.8222],\n",
      "        [-1.0000],\n",
      "        [ 0.8308],\n",
      "        [ 0.8410],\n",
      "        [ 0.8101],\n",
      "        [ 0.8406],\n",
      "        [ 0.8325],\n",
      "        [ 0.8239],\n",
      "        [ 0.8256],\n",
      "        [ 0.8243],\n",
      "        [ 0.8018],\n",
      "        [-1.0000],\n",
      "        [ 0.8247],\n",
      "        [ 0.8012],\n",
      "        [ 0.8219],\n",
      "        [ 0.8023],\n",
      "        [ 0.8250],\n",
      "        [ 0.8257],\n",
      "        [ 0.8301],\n",
      "        [ 0.8331],\n",
      "        [ 0.8306],\n",
      "        [-1.0000],\n",
      "        [ 0.8451],\n",
      "        [ 0.8039],\n",
      "        [ 0.8071],\n",
      "        [ 0.8354],\n",
      "        [ 0.8210],\n",
      "        [ 0.8226],\n",
      "        [ 0.8160],\n",
      "        [ 0.8292],\n",
      "        [ 0.8337],\n",
      "        [ 0.8213],\n",
      "        [ 0.8164],\n",
      "        [ 0.8300],\n",
      "        [ 0.8321],\n",
      "        [ 0.8177],\n",
      "        [ 0.8213],\n",
      "        [ 0.8284],\n",
      "        [-1.0000]], device='cuda:0'))\n",
      "{'loss': tensor(0.1532, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 411, 'agent.time_step': 4758, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 412, 'agent.time_step': 4769, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 413, 'agent.time_step': 4778, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 414, 'agent.time_step': 4785, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 415, 'agent.time_step': 4794, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 416, 'agent.time_step': 4802, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 417, 'agent.time_step': 4815, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 418, 'agent.time_step': 4821, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 419, 'agent.time_step': 4831, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 420, 'agent.time_step': 4838, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "(q_current, q_targets): (tensor([[0.9466],\n",
      "        [0.9442],\n",
      "        [0.9479],\n",
      "        [0.9526],\n",
      "        [0.9537],\n",
      "        [1.0024],\n",
      "        [0.9526],\n",
      "        [0.9525],\n",
      "        [1.1775],\n",
      "        [0.9537],\n",
      "        [1.0227],\n",
      "        [1.1797],\n",
      "        [0.9415],\n",
      "        [0.2877],\n",
      "        [1.1366],\n",
      "        [0.9537],\n",
      "        [0.9305],\n",
      "        [1.1763],\n",
      "        [1.0085],\n",
      "        [1.1366],\n",
      "        [0.9189],\n",
      "        [0.9525],\n",
      "        [0.9580],\n",
      "        [0.9412],\n",
      "        [0.9537],\n",
      "        [0.9526],\n",
      "        [0.9533],\n",
      "        [0.9511],\n",
      "        [0.9921],\n",
      "        [0.9537],\n",
      "        [0.9526],\n",
      "        [0.9501],\n",
      "        [0.9821],\n",
      "        [0.9744],\n",
      "        [0.9485],\n",
      "        [0.9525],\n",
      "        [0.9507],\n",
      "        [0.9759],\n",
      "        [0.9328],\n",
      "        [1.1745],\n",
      "        [0.2562],\n",
      "        [0.9525],\n",
      "        [0.9526],\n",
      "        [0.9965],\n",
      "        [0.9525],\n",
      "        [0.9525],\n",
      "        [0.9519],\n",
      "        [0.9814],\n",
      "        [0.9526],\n",
      "        [0.9537],\n",
      "        [0.9525],\n",
      "        [0.9821],\n",
      "        [1.1704],\n",
      "        [0.9490],\n",
      "        [1.1512],\n",
      "        [0.9419],\n",
      "        [0.9525],\n",
      "        [0.9540],\n",
      "        [0.9950],\n",
      "        [0.9525],\n",
      "        [0.9443],\n",
      "        [0.2543],\n",
      "        [1.1809],\n",
      "        [0.9555]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8420],\n",
      "        [ 0.8271],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.8278],\n",
      "        [ 0.8318],\n",
      "        [ 0.8252],\n",
      "        [ 0.8380],\n",
      "        [-1.0000],\n",
      "        [ 0.8246],\n",
      "        [ 0.8228],\n",
      "        [ 0.8122],\n",
      "        [ 0.8341],\n",
      "        [-1.0000],\n",
      "        [ 0.8253],\n",
      "        [ 0.8291],\n",
      "        [ 0.8282],\n",
      "        [-1.0000],\n",
      "        [ 0.8314],\n",
      "        [ 0.8322],\n",
      "        [ 0.8202],\n",
      "        [ 0.8253],\n",
      "        [ 0.8239],\n",
      "        [ 0.8272],\n",
      "        [ 0.8242],\n",
      "        [ 0.8349],\n",
      "        [ 0.8226],\n",
      "        [ 0.8235],\n",
      "        [ 0.8245],\n",
      "        [ 0.8219],\n",
      "        [ 0.8410],\n",
      "        [ 0.8299],\n",
      "        [ 0.8225],\n",
      "        [ 0.8376],\n",
      "        [ 0.8352],\n",
      "        [ 0.8335],\n",
      "        [-1.0000],\n",
      "        [ 0.8177],\n",
      "        [ 0.8292],\n",
      "        [ 0.8213],\n",
      "        [ 0.8053],\n",
      "        [ 0.8273],\n",
      "        [-1.0000],\n",
      "        [ 0.8240],\n",
      "        [ 0.8295],\n",
      "        [ 0.8358],\n",
      "        [ 0.8327],\n",
      "        [ 0.8162],\n",
      "        [ 0.8321],\n",
      "        [ 0.8298],\n",
      "        [ 0.8354],\n",
      "        [ 0.8264],\n",
      "        [ 0.8283],\n",
      "        [ 0.8287],\n",
      "        [ 0.8156],\n",
      "        [ 0.8358],\n",
      "        [ 0.8301],\n",
      "        [ 0.8359],\n",
      "        [ 0.8309],\n",
      "        [ 0.8269],\n",
      "        [ 0.8380],\n",
      "        [-1.0000],\n",
      "        [ 0.8255],\n",
      "        [ 0.8380]], device='cuda:0'))\n",
      "{'loss': tensor(0.1823, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 421, 'agent.time_step': 4845, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 422, 'agent.time_step': 4854, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 423, 'agent.time_step': 4867, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 424, 'agent.time_step': 4872, 'rounds': 5, 'accumulate_reward': 3.0}\n",
      "{'episode': 425, 'agent.time_step': 4881, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 426, 'agent.time_step': 4887, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 427, 'agent.time_step': 4902, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 428, 'agent.time_step': 4916, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 429, 'agent.time_step': 4930, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 430, 'agent.time_step': 4940, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "(q_current, q_targets): (tensor([[0.2662],\n",
      "        [0.8144],\n",
      "        [0.8160],\n",
      "        [0.8189],\n",
      "        [0.7633],\n",
      "        [0.9231],\n",
      "        [0.8402],\n",
      "        [0.7884],\n",
      "        [0.8175],\n",
      "        [0.8160],\n",
      "        [0.8319],\n",
      "        [0.7675],\n",
      "        [0.8164],\n",
      "        [0.8189],\n",
      "        [0.8186],\n",
      "        [0.8189],\n",
      "        [0.8182],\n",
      "        [0.8093],\n",
      "        [0.8186],\n",
      "        [0.5316],\n",
      "        [0.2662],\n",
      "        [0.8186],\n",
      "        [0.8190],\n",
      "        [0.8574],\n",
      "        [1.0087],\n",
      "        [0.8103],\n",
      "        [0.8144],\n",
      "        [0.8618],\n",
      "        [0.8170],\n",
      "        [0.8438],\n",
      "        [0.8189],\n",
      "        [0.8180],\n",
      "        [0.6911],\n",
      "        [1.0078],\n",
      "        [0.8189],\n",
      "        [0.6747],\n",
      "        [0.7950],\n",
      "        [0.2848],\n",
      "        [0.8048],\n",
      "        [0.7853],\n",
      "        [0.9180],\n",
      "        [0.7834],\n",
      "        [0.8186],\n",
      "        [0.7827],\n",
      "        [0.9978],\n",
      "        [0.9155],\n",
      "        [0.8205],\n",
      "        [0.2662],\n",
      "        [0.2468],\n",
      "        [0.8432],\n",
      "        [0.8175],\n",
      "        [0.7727],\n",
      "        [0.7508],\n",
      "        [0.8746],\n",
      "        [0.8189],\n",
      "        [0.8175],\n",
      "        [0.7657],\n",
      "        [0.8186],\n",
      "        [0.8308],\n",
      "        [0.8189],\n",
      "        [0.8327],\n",
      "        [0.8073],\n",
      "        [0.2530],\n",
      "        [0.9581]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8048],\n",
      "        [ 0.8007],\n",
      "        [-1.0000],\n",
      "        [ 0.8252],\n",
      "        [ 0.8293],\n",
      "        [ 0.8161],\n",
      "        [ 0.8219],\n",
      "        [ 0.8234],\n",
      "        [ 0.8138],\n",
      "        [ 0.8144],\n",
      "        [ 0.8213],\n",
      "        [ 0.8244],\n",
      "        [ 0.8364],\n",
      "        [ 0.8267],\n",
      "        [ 0.8170],\n",
      "        [ 0.8289],\n",
      "        [ 0.8217],\n",
      "        [-1.0000],\n",
      "        [ 0.8259],\n",
      "        [ 0.8181],\n",
      "        [ 0.8014],\n",
      "        [ 0.8214],\n",
      "        [ 0.8253],\n",
      "        [ 0.8199],\n",
      "        [-1.0000],\n",
      "        [ 0.8179],\n",
      "        [ 0.7956],\n",
      "        [ 0.8251],\n",
      "        [ 0.8210],\n",
      "        [ 0.8130],\n",
      "        [ 0.8211],\n",
      "        [ 0.8111],\n",
      "        [ 0.7975],\n",
      "        [-1.0000],\n",
      "        [ 0.8289],\n",
      "        [ 0.8338],\n",
      "        [ 0.8256],\n",
      "        [ 0.8078],\n",
      "        [ 0.8339],\n",
      "        [ 0.8113],\n",
      "        [ 0.8154],\n",
      "        [ 0.8170],\n",
      "        [ 0.8117],\n",
      "        [ 0.8177],\n",
      "        [ 0.8238],\n",
      "        [ 0.8100],\n",
      "        [ 0.8235],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.8156],\n",
      "        [ 0.8223],\n",
      "        [ 0.8175],\n",
      "        [ 0.8204],\n",
      "        [ 0.8187],\n",
      "        [ 0.8257],\n",
      "        [ 0.8137],\n",
      "        [ 0.8127],\n",
      "        [ 0.8362],\n",
      "        [ 0.8177],\n",
      "        [ 0.8295],\n",
      "        [ 0.8286],\n",
      "        [ 0.8245],\n",
      "        [-1.0000],\n",
      "        [ 0.8118]], device='cuda:0'))\n",
      "{'loss': tensor(0.1320, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 431, 'agent.time_step': 4949, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 432, 'agent.time_step': 4960, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 433, 'agent.time_step': 4967, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 434, 'agent.time_step': 4975, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 435, 'agent.time_step': 4982, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 436, 'agent.time_step': 4992, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 437, 'agent.time_step': 5002, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 438, 'agent.time_step': 5010, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 439, 'agent.time_step': 5018, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 440, 'agent.time_step': 5027, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "(q_current, q_targets): (tensor([[0.6564],\n",
      "        [0.5839],\n",
      "        [0.6569],\n",
      "        [0.6475],\n",
      "        [0.6572],\n",
      "        [0.7286],\n",
      "        [0.6569],\n",
      "        [0.6405],\n",
      "        [0.6561],\n",
      "        [0.2098],\n",
      "        [0.5706],\n",
      "        [0.6585],\n",
      "        [0.6530],\n",
      "        [0.6524],\n",
      "        [0.6731],\n",
      "        [0.6546],\n",
      "        [0.7014],\n",
      "        [0.7286],\n",
      "        [0.6725],\n",
      "        [0.6192],\n",
      "        [0.6567],\n",
      "        [0.6569],\n",
      "        [0.6566],\n",
      "        [0.7701],\n",
      "        [0.6589],\n",
      "        [0.6589],\n",
      "        [0.6447],\n",
      "        [0.6564],\n",
      "        [0.6584],\n",
      "        [0.2221],\n",
      "        [0.6456],\n",
      "        [0.6457],\n",
      "        [0.2341],\n",
      "        [0.6699],\n",
      "        [0.7701],\n",
      "        [0.6571],\n",
      "        [0.7890],\n",
      "        [0.7162],\n",
      "        [0.6571],\n",
      "        [0.6220],\n",
      "        [0.6530],\n",
      "        [0.6672],\n",
      "        [0.7814],\n",
      "        [0.7951],\n",
      "        [0.6718],\n",
      "        [0.6717],\n",
      "        [0.6569],\n",
      "        [0.6485],\n",
      "        [0.6530],\n",
      "        [0.2100],\n",
      "        [0.6569],\n",
      "        [0.6569],\n",
      "        [0.6717],\n",
      "        [0.6585],\n",
      "        [0.6672],\n",
      "        [0.6571],\n",
      "        [0.6629],\n",
      "        [0.6027],\n",
      "        [0.6571],\n",
      "        [0.2321],\n",
      "        [0.6571],\n",
      "        [0.6530],\n",
      "        [0.6370],\n",
      "        [0.6717]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8227],\n",
      "        [ 0.8275],\n",
      "        [-1.0000],\n",
      "        [ 0.8230],\n",
      "        [ 0.8288],\n",
      "        [ 0.8174],\n",
      "        [-1.0000],\n",
      "        [ 0.8249],\n",
      "        [ 0.8185],\n",
      "        [ 0.8061],\n",
      "        [-1.0000],\n",
      "        [ 0.8181],\n",
      "        [-1.0000],\n",
      "        [ 0.8274],\n",
      "        [ 0.8256],\n",
      "        [ 0.8291],\n",
      "        [ 0.8191],\n",
      "        [ 0.8184],\n",
      "        [ 0.8199],\n",
      "        [ 0.8166],\n",
      "        [ 0.8269],\n",
      "        [ 0.8317],\n",
      "        [ 0.8326],\n",
      "        [ 0.8300],\n",
      "        [ 0.8240],\n",
      "        [ 0.8208],\n",
      "        [ 0.8339],\n",
      "        [ 0.8163],\n",
      "        [ 0.8240],\n",
      "        [-1.0000],\n",
      "        [ 0.8177],\n",
      "        [ 0.8299],\n",
      "        [ 0.8041],\n",
      "        [ 0.8286],\n",
      "        [ 0.8302],\n",
      "        [ 0.8273],\n",
      "        [ 0.8315],\n",
      "        [ 0.8121],\n",
      "        [ 0.8220],\n",
      "        [ 0.8229],\n",
      "        [-1.0000],\n",
      "        [ 0.8203],\n",
      "        [-1.0000],\n",
      "        [ 0.8335],\n",
      "        [ 0.8126],\n",
      "        [ 0.8252],\n",
      "        [ 0.8420],\n",
      "        [ 0.8423],\n",
      "        [-1.0000],\n",
      "        [ 0.8093],\n",
      "        [-1.0000],\n",
      "        [ 0.8176],\n",
      "        [ 0.8227],\n",
      "        [ 0.8292],\n",
      "        [ 0.8167],\n",
      "        [ 0.8400],\n",
      "        [ 0.8215],\n",
      "        [ 0.8204],\n",
      "        [ 0.8213],\n",
      "        [-1.0000],\n",
      "        [ 0.8279],\n",
      "        [ 0.7956],\n",
      "        [ 0.8231],\n",
      "        [ 0.8259]], device='cuda:0'))\n",
      "{'loss': tensor(0.1862, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 441, 'agent.time_step': 5034, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 442, 'agent.time_step': 5047, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 443, 'agent.time_step': 5058, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 444, 'agent.time_step': 5066, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 445, 'agent.time_step': 5073, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 446, 'agent.time_step': 5086, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 447, 'agent.time_step': 5092, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 448, 'agent.time_step': 5102, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 449, 'agent.time_step': 5110, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 450, 'agent.time_step': 5119, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "(q_current, q_targets): (tensor([[0.5515],\n",
      "        [0.1912],\n",
      "        [0.5608],\n",
      "        [0.5533],\n",
      "        [0.5739],\n",
      "        [0.5625],\n",
      "        [0.5630],\n",
      "        [0.5881],\n",
      "        [0.5625],\n",
      "        [0.1915],\n",
      "        [0.5637],\n",
      "        [0.1917],\n",
      "        [0.5622],\n",
      "        [0.5627],\n",
      "        [0.5585],\n",
      "        [0.6449],\n",
      "        [0.2202],\n",
      "        [0.6063],\n",
      "        [0.5625],\n",
      "        [0.5668],\n",
      "        [0.5625],\n",
      "        [0.6056],\n",
      "        [0.5625],\n",
      "        [0.5686],\n",
      "        [0.5625],\n",
      "        [0.5082],\n",
      "        [0.5459],\n",
      "        [0.5567],\n",
      "        [0.6021],\n",
      "        [0.5134],\n",
      "        [0.6005],\n",
      "        [0.6354],\n",
      "        [0.5618],\n",
      "        [0.5280],\n",
      "        [0.5981],\n",
      "        [0.2007],\n",
      "        [0.1938],\n",
      "        [0.5622],\n",
      "        [0.5596],\n",
      "        [0.5617],\n",
      "        [0.5622],\n",
      "        [0.5630],\n",
      "        [0.5637],\n",
      "        [0.5317],\n",
      "        [0.5213],\n",
      "        [0.5622],\n",
      "        [0.5625],\n",
      "        [0.5278],\n",
      "        [0.5630],\n",
      "        [0.5577],\n",
      "        [0.5632],\n",
      "        [0.5759],\n",
      "        [0.5631],\n",
      "        [0.5721],\n",
      "        [0.5614],\n",
      "        [0.5628],\n",
      "        [0.5792],\n",
      "        [0.5550],\n",
      "        [0.5612],\n",
      "        [0.5476],\n",
      "        [0.5904],\n",
      "        [0.5807],\n",
      "        [0.5214],\n",
      "        [0.5530]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8297],\n",
      "        [-1.0000],\n",
      "        [ 0.8320],\n",
      "        [ 0.8290],\n",
      "        [ 0.8301],\n",
      "        [ 0.8277],\n",
      "        [ 0.8225],\n",
      "        [ 0.8307],\n",
      "        [ 0.8278],\n",
      "        [ 0.8094],\n",
      "        [ 0.8194],\n",
      "        [ 0.8061],\n",
      "        [ 0.8420],\n",
      "        [ 0.8107],\n",
      "        [ 0.8128],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.8174],\n",
      "        [ 0.8317],\n",
      "        [ 0.8153],\n",
      "        [ 0.8370],\n",
      "        [ 0.8268],\n",
      "        [ 0.8327],\n",
      "        [ 0.8206],\n",
      "        [ 0.8315],\n",
      "        [ 0.8231],\n",
      "        [ 0.8130],\n",
      "        [-1.0000],\n",
      "        [ 0.8252],\n",
      "        [ 0.8413],\n",
      "        [ 0.8179],\n",
      "        [ 0.8238],\n",
      "        [ 0.8246],\n",
      "        [ 0.8166],\n",
      "        [ 0.8317],\n",
      "        [-1.0000],\n",
      "        [ 0.8014],\n",
      "        [ 0.8317],\n",
      "        [ 0.8192],\n",
      "        [ 0.8204],\n",
      "        [ 0.8368],\n",
      "        [-1.0000],\n",
      "        [ 0.8188],\n",
      "        [ 0.8091],\n",
      "        [ 0.8401],\n",
      "        [ 0.8415],\n",
      "        [ 0.8308],\n",
      "        [-1.0000],\n",
      "        [ 0.8161],\n",
      "        [ 0.8286],\n",
      "        [ 0.8203],\n",
      "        [ 0.8301],\n",
      "        [ 0.8258],\n",
      "        [ 0.8184],\n",
      "        [-1.0000],\n",
      "        [ 0.8341],\n",
      "        [ 0.8289],\n",
      "        [ 0.8211],\n",
      "        [ 0.8321],\n",
      "        [ 0.8197],\n",
      "        [ 0.8158],\n",
      "        [ 0.8262],\n",
      "        [ 0.8167],\n",
      "        [-1.0000]], device='cuda:0'))\n",
      "{'loss': tensor(0.1699, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 451, 'agent.time_step': 5127, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 452, 'agent.time_step': 5141, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 453, 'agent.time_step': 5156, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 454, 'agent.time_step': 5167, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 455, 'agent.time_step': 5177, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 456, 'agent.time_step': 5184, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 457, 'agent.time_step': 5195, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 458, 'agent.time_step': 5203, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 459, 'agent.time_step': 5209, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 460, 'agent.time_step': 5224, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "(q_current, q_targets): (tensor([[0.5505],\n",
      "        [0.5883],\n",
      "        [0.5505],\n",
      "        [0.5503],\n",
      "        [0.5506],\n",
      "        [0.1897],\n",
      "        [0.5503],\n",
      "        [0.5719],\n",
      "        [0.5498],\n",
      "        [0.5591],\n",
      "        [0.5380],\n",
      "        [0.5533],\n",
      "        [0.5503],\n",
      "        [0.5522],\n",
      "        [0.4305],\n",
      "        [0.5480],\n",
      "        [0.5505],\n",
      "        [0.5478],\n",
      "        [0.5480],\n",
      "        [0.5421],\n",
      "        [0.5883],\n",
      "        [0.5470],\n",
      "        [0.5778],\n",
      "        [0.5528],\n",
      "        [0.5503],\n",
      "        [0.5817],\n",
      "        [0.5510],\n",
      "        [0.5582],\n",
      "        [0.5495],\n",
      "        [0.5367],\n",
      "        [0.5465],\n",
      "        [0.6218],\n",
      "        [0.6205],\n",
      "        [0.5510],\n",
      "        [0.5413],\n",
      "        [0.5422],\n",
      "        [0.5591],\n",
      "        [0.5508],\n",
      "        [0.4923],\n",
      "        [0.5503],\n",
      "        [0.5522],\n",
      "        [0.5632],\n",
      "        [0.5278],\n",
      "        [0.5503],\n",
      "        [0.5422],\n",
      "        [0.5510],\n",
      "        [0.5549],\n",
      "        [0.5510],\n",
      "        [0.5494],\n",
      "        [0.5479],\n",
      "        [0.5883],\n",
      "        [0.5444],\n",
      "        [0.5203],\n",
      "        [0.5413],\n",
      "        [0.5503],\n",
      "        [0.5503],\n",
      "        [0.5423],\n",
      "        [0.5522],\n",
      "        [0.6218],\n",
      "        [0.5492],\n",
      "        [0.5915],\n",
      "        [0.6085],\n",
      "        [0.5386],\n",
      "        [0.5510]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[-1.0000],\n",
      "        [ 0.7861],\n",
      "        [ 0.8110],\n",
      "        [ 0.7934],\n",
      "        [ 0.7945],\n",
      "        [-1.0000],\n",
      "        [ 0.7888],\n",
      "        [-1.0000],\n",
      "        [ 0.7937],\n",
      "        [ 0.7940],\n",
      "        [ 0.7998],\n",
      "        [ 0.7825],\n",
      "        [ 0.7979],\n",
      "        [ 0.7945],\n",
      "        [ 0.7930],\n",
      "        [ 0.7830],\n",
      "        [-1.0000],\n",
      "        [ 0.7974],\n",
      "        [-1.0000],\n",
      "        [ 0.7737],\n",
      "        [ 0.7924],\n",
      "        [-1.0000],\n",
      "        [ 0.7919],\n",
      "        [ 0.7900],\n",
      "        [ 0.7888],\n",
      "        [ 0.7857],\n",
      "        [ 0.7907],\n",
      "        [ 0.7773],\n",
      "        [ 0.7909],\n",
      "        [ 0.7951],\n",
      "        [ 0.7780],\n",
      "        [ 0.7892],\n",
      "        [ 0.7954],\n",
      "        [ 0.7945],\n",
      "        [ 0.8026],\n",
      "        [ 0.7954],\n",
      "        [ 0.7995],\n",
      "        [ 0.7841],\n",
      "        [ 0.7995],\n",
      "        [ 0.7888],\n",
      "        [ 0.7939],\n",
      "        [ 0.7978],\n",
      "        [ 0.7848],\n",
      "        [ 0.7815],\n",
      "        [ 0.7926],\n",
      "        [ 0.8010],\n",
      "        [ 0.7911],\n",
      "        [ 0.8026],\n",
      "        [ 0.7988],\n",
      "        [ 0.7822],\n",
      "        [ 0.7914],\n",
      "        [ 0.7833],\n",
      "        [ 0.8087],\n",
      "        [-1.0000],\n",
      "        [ 0.7900],\n",
      "        [ 0.7900],\n",
      "        [ 0.7932],\n",
      "        [ 0.7900],\n",
      "        [ 0.7935],\n",
      "        [ 0.7966],\n",
      "        [ 0.7861],\n",
      "        [ 0.7781],\n",
      "        [ 0.7888],\n",
      "        [ 0.7889]], device='cuda:0'))\n",
      "{'loss': tensor(0.1349, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 461, 'agent.time_step': 5234, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 462, 'agent.time_step': 5248, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 463, 'agent.time_step': 5257, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 464, 'agent.time_step': 5267, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 465, 'agent.time_step': 5276, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 466, 'agent.time_step': 5288, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 467, 'agent.time_step': 5295, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 468, 'agent.time_step': 5304, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 469, 'agent.time_step': 5313, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 470, 'agent.time_step': 5328, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "(q_current, q_targets): (tensor([[0.6224],\n",
      "        [0.5982],\n",
      "        [0.5990],\n",
      "        [0.5956],\n",
      "        [0.6149],\n",
      "        [0.5922],\n",
      "        [0.5957],\n",
      "        [0.5990],\n",
      "        [0.6224],\n",
      "        [0.5935],\n",
      "        [0.5998],\n",
      "        [0.5933],\n",
      "        [0.5757],\n",
      "        [0.6003],\n",
      "        [0.2124],\n",
      "        [0.5990],\n",
      "        [0.5971],\n",
      "        [0.5752],\n",
      "        [0.6043],\n",
      "        [0.6619],\n",
      "        [0.5877],\n",
      "        [0.5879],\n",
      "        [0.5834],\n",
      "        [0.5757],\n",
      "        [0.6010],\n",
      "        [0.3269],\n",
      "        [0.5756],\n",
      "        [0.5982],\n",
      "        [0.2011],\n",
      "        [0.6203],\n",
      "        [0.3941],\n",
      "        [0.6302],\n",
      "        [0.6364],\n",
      "        [0.5990],\n",
      "        [0.5947],\n",
      "        [0.5990],\n",
      "        [0.5994],\n",
      "        [0.5468],\n",
      "        [0.6007],\n",
      "        [0.5982],\n",
      "        [0.4286],\n",
      "        [0.5982],\n",
      "        [0.6230],\n",
      "        [0.5877],\n",
      "        [0.5757],\n",
      "        [0.5990],\n",
      "        [0.5897],\n",
      "        [0.5990],\n",
      "        [0.6035],\n",
      "        [0.5990],\n",
      "        [0.6453],\n",
      "        [0.5879],\n",
      "        [0.5990],\n",
      "        [0.5982],\n",
      "        [0.1994],\n",
      "        [0.5877],\n",
      "        [0.4819],\n",
      "        [0.5911],\n",
      "        [0.6475],\n",
      "        [0.5979],\n",
      "        [0.6241],\n",
      "        [0.5757],\n",
      "        [0.5926],\n",
      "        [0.5976]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8013],\n",
      "        [-1.0000],\n",
      "        [ 0.8024],\n",
      "        [ 0.7907],\n",
      "        [ 0.7931],\n",
      "        [ 0.7901],\n",
      "        [ 0.7990],\n",
      "        [ 0.7924],\n",
      "        [ 0.8037],\n",
      "        [ 0.8065],\n",
      "        [ 0.7959],\n",
      "        [ 0.8061],\n",
      "        [ 0.7955],\n",
      "        [ 0.7974],\n",
      "        [ 0.7867],\n",
      "        [ 0.7957],\n",
      "        [ 0.7916],\n",
      "        [-1.0000],\n",
      "        [ 0.7928],\n",
      "        [ 0.7964],\n",
      "        [ 0.7946],\n",
      "        [ 0.8110],\n",
      "        [ 0.8008],\n",
      "        [ 0.7987],\n",
      "        [ 0.8041],\n",
      "        [ 0.7999],\n",
      "        [ 0.8104],\n",
      "        [-1.0000],\n",
      "        [ 0.7790],\n",
      "        [ 0.7983],\n",
      "        [ 0.7864],\n",
      "        [ 0.8102],\n",
      "        [ 0.8027],\n",
      "        [ 0.7982],\n",
      "        [ 0.7991],\n",
      "        [ 0.7978],\n",
      "        [ 0.7937],\n",
      "        [ 0.8005],\n",
      "        [ 0.7944],\n",
      "        [ 0.7990],\n",
      "        [ 0.7848],\n",
      "        [ 0.7950],\n",
      "        [ 0.8065],\n",
      "        [ 0.7978],\n",
      "        [ 0.7880],\n",
      "        [ 0.8037],\n",
      "        [ 0.7902],\n",
      "        [ 0.8022],\n",
      "        [ 0.7932],\n",
      "        [ 0.7985],\n",
      "        [ 0.8004],\n",
      "        [ 0.7951],\n",
      "        [ 0.7946],\n",
      "        [ 0.8013],\n",
      "        [-1.0000],\n",
      "        [ 0.7890],\n",
      "        [ 0.7956],\n",
      "        [ 0.7956],\n",
      "        [ 0.8014],\n",
      "        [ 0.7895],\n",
      "        [ 0.8016],\n",
      "        [ 0.8031],\n",
      "        [ 0.7986],\n",
      "        [ 0.7938]], device='cuda:0'))\n",
      "{'loss': tensor(0.0886, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 471, 'agent.time_step': 5336, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 472, 'agent.time_step': 5348, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 473, 'agent.time_step': 5357, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 474, 'agent.time_step': 5369, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 475, 'agent.time_step': 5383, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 476, 'agent.time_step': 5392, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 477, 'agent.time_step': 5401, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 478, 'agent.time_step': 5410, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 479, 'agent.time_step': 5420, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 480, 'agent.time_step': 5430, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "(q_current, q_targets): (tensor([[0.6917],\n",
      "        [0.5475],\n",
      "        [0.7053],\n",
      "        [0.7121],\n",
      "        [0.7156],\n",
      "        [0.7073],\n",
      "        [0.7106],\n",
      "        [0.7118],\n",
      "        [0.7021],\n",
      "        [0.7121],\n",
      "        [0.7081],\n",
      "        [0.6994],\n",
      "        [0.7081],\n",
      "        [0.7067],\n",
      "        [0.6695],\n",
      "        [0.7121],\n",
      "        [0.6748],\n",
      "        [0.7105],\n",
      "        [0.7988],\n",
      "        [0.6898],\n",
      "        [0.7121],\n",
      "        [0.7121],\n",
      "        [0.6863],\n",
      "        [0.7191],\n",
      "        [0.7098],\n",
      "        [0.6908],\n",
      "        [0.7026],\n",
      "        [0.7502],\n",
      "        [0.7118],\n",
      "        [0.7575],\n",
      "        [0.7121],\n",
      "        [0.5544],\n",
      "        [0.7121],\n",
      "        [0.6671],\n",
      "        [0.6999],\n",
      "        [0.7150],\n",
      "        [0.7105],\n",
      "        [0.2230],\n",
      "        [0.6635],\n",
      "        [0.6914],\n",
      "        [0.5562],\n",
      "        [0.6915],\n",
      "        [0.7067],\n",
      "        [0.7121],\n",
      "        [0.7078],\n",
      "        [0.7105],\n",
      "        [0.7510],\n",
      "        [0.1990],\n",
      "        [0.7617],\n",
      "        [0.2459],\n",
      "        [0.6898],\n",
      "        [0.7119],\n",
      "        [0.6476],\n",
      "        [0.7098],\n",
      "        [0.7121],\n",
      "        [0.7118],\n",
      "        [0.7121],\n",
      "        [0.7201],\n",
      "        [0.7131],\n",
      "        [0.7125],\n",
      "        [0.6863],\n",
      "        [0.7374],\n",
      "        [0.7065],\n",
      "        [0.7105]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.8052],\n",
      "        [ 0.8041],\n",
      "        [ 0.7893],\n",
      "        [ 0.7988],\n",
      "        [ 0.7905],\n",
      "        [ 0.7915],\n",
      "        [ 0.8146],\n",
      "        [ 0.8027],\n",
      "        [ 0.8008],\n",
      "        [ 0.7922],\n",
      "        [ 0.8072],\n",
      "        [ 0.8062],\n",
      "        [ 0.8067],\n",
      "        [ 0.7818],\n",
      "        [ 0.8027],\n",
      "        [ 0.8083],\n",
      "        [ 0.7973],\n",
      "        [ 0.8099],\n",
      "        [ 0.7995],\n",
      "        [ 0.7879],\n",
      "        [ 0.7915],\n",
      "        [ 0.7934],\n",
      "        [ 0.7925],\n",
      "        [ 0.7896],\n",
      "        [ 0.7965],\n",
      "        [ 0.7974],\n",
      "        [ 0.8077],\n",
      "        [ 0.8076],\n",
      "        [ 0.8035],\n",
      "        [ 0.7952],\n",
      "        [-1.0000],\n",
      "        [ 0.7873],\n",
      "        [ 0.7898],\n",
      "        [ 0.7899],\n",
      "        [ 0.8020],\n",
      "        [ 0.7908],\n",
      "        [ 0.8197],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.8059],\n",
      "        [ 0.7886],\n",
      "        [ 0.8093],\n",
      "        [-1.0000],\n",
      "        [ 0.7897],\n",
      "        [ 0.7948],\n",
      "        [ 0.8191],\n",
      "        [ 0.7944],\n",
      "        [ 0.7816],\n",
      "        [ 0.8105],\n",
      "        [-1.0000],\n",
      "        [ 0.7998],\n",
      "        [ 0.8080],\n",
      "        [ 0.8063],\n",
      "        [-1.0000],\n",
      "        [ 0.7946],\n",
      "        [ 0.7998],\n",
      "        [ 0.7999],\n",
      "        [ 0.8010],\n",
      "        [ 0.8050],\n",
      "        [ 0.7952],\n",
      "        [ 0.7877],\n",
      "        [ 0.7998],\n",
      "        [ 0.8117],\n",
      "        [ 0.8117]], device='cuda:0'))\n",
      "{'loss': tensor(0.1056, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 481, 'agent.time_step': 5438, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 482, 'agent.time_step': 5449, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 483, 'agent.time_step': 5458, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 484, 'agent.time_step': 5469, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 485, 'agent.time_step': 5480, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 486, 'agent.time_step': 5489, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 487, 'agent.time_step': 5502, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 488, 'agent.time_step': 5509, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 489, 'agent.time_step': 5520, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 490, 'agent.time_step': 5533, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "(q_current, q_targets): (tensor([[7.2626e-01],\n",
      "        [8.3353e-01],\n",
      "        [8.4616e-01],\n",
      "        [3.6875e-01],\n",
      "        [2.4814e-01],\n",
      "        [8.1740e-01],\n",
      "        [8.3938e-01],\n",
      "        [8.4363e-01],\n",
      "        [8.4363e-01],\n",
      "        [8.1711e-01],\n",
      "        [8.2041e-01],\n",
      "        [8.4363e-01],\n",
      "        [2.0748e-01],\n",
      "        [8.4616e-01],\n",
      "        [8.1711e-01],\n",
      "        [8.2654e-01],\n",
      "        [8.9251e-01],\n",
      "        [8.4616e-01],\n",
      "        [7.2153e-01],\n",
      "        [8.4625e-01],\n",
      "        [8.0992e-01],\n",
      "        [8.4631e-01],\n",
      "        [2.0784e-01],\n",
      "        [8.4616e-01],\n",
      "        [7.5306e-01],\n",
      "        [8.1711e-01],\n",
      "        [8.7297e-01],\n",
      "        [8.8874e-01],\n",
      "        [8.4077e-01],\n",
      "        [9.5272e-01],\n",
      "        [8.4616e-01],\n",
      "        [8.7503e-01],\n",
      "        [8.4616e-01],\n",
      "        [8.1065e-01],\n",
      "        [9.5005e-04],\n",
      "        [8.4631e-01],\n",
      "        [9.0923e-01],\n",
      "        [8.3162e-01],\n",
      "        [8.4624e-01],\n",
      "        [8.4631e-01],\n",
      "        [8.1747e-01],\n",
      "        [8.2555e-01],\n",
      "        [7.9388e-01],\n",
      "        [8.0992e-01],\n",
      "        [8.6022e-01],\n",
      "        [8.4300e-01],\n",
      "        [8.4631e-01],\n",
      "        [8.3585e-01],\n",
      "        [8.3365e-01],\n",
      "        [8.1711e-01],\n",
      "        [8.4420e-01],\n",
      "        [8.4616e-01],\n",
      "        [8.5737e-01],\n",
      "        [8.4295e-01],\n",
      "        [8.9251e-01],\n",
      "        [8.4363e-01],\n",
      "        [9.1041e-01],\n",
      "        [8.5376e-01],\n",
      "        [8.5737e-01],\n",
      "        [8.4363e-01],\n",
      "        [2.9871e-01],\n",
      "        [8.5703e-01],\n",
      "        [8.4656e-01],\n",
      "        [8.4631e-01]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7944],\n",
      "        [ 0.8107],\n",
      "        [ 0.8060],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.8115],\n",
      "        [-1.0000],\n",
      "        [ 0.7909],\n",
      "        [ 0.8192],\n",
      "        [ 0.8003],\n",
      "        [ 0.7869],\n",
      "        [ 0.7991],\n",
      "        [-1.0000],\n",
      "        [ 0.7981],\n",
      "        [ 0.7973],\n",
      "        [ 0.7918],\n",
      "        [ 0.8003],\n",
      "        [ 0.7986],\n",
      "        [ 0.7903],\n",
      "        [ 0.7941],\n",
      "        [ 0.7909],\n",
      "        [ 0.7959],\n",
      "        [ 0.7794],\n",
      "        [ 0.7915],\n",
      "        [ 0.7856],\n",
      "        [-1.0000],\n",
      "        [ 0.7964],\n",
      "        [ 0.8047],\n",
      "        [ 0.8052],\n",
      "        [ 0.8052],\n",
      "        [ 0.7900],\n",
      "        [ 0.7908],\n",
      "        [ 0.7910],\n",
      "        [ 0.7991],\n",
      "        [ 0.7798],\n",
      "        [ 0.7886],\n",
      "        [ 0.7939],\n",
      "        [ 0.7897],\n",
      "        [ 0.7893],\n",
      "        [ 0.7867],\n",
      "        [ 0.8013],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.7987],\n",
      "        [ 0.7935],\n",
      "        [ 0.8003],\n",
      "        [ 0.7919],\n",
      "        [ 0.7923],\n",
      "        [ 0.8095],\n",
      "        [ 0.8021],\n",
      "        [ 0.7937],\n",
      "        [ 0.7962],\n",
      "        [ 0.7913],\n",
      "        [ 0.7941],\n",
      "        [ 0.7873],\n",
      "        [ 0.7963],\n",
      "        [ 0.7937],\n",
      "        [ 0.8020],\n",
      "        [ 0.7901],\n",
      "        [ 0.8124],\n",
      "        [ 0.7892],\n",
      "        [ 0.7937],\n",
      "        [ 0.7901],\n",
      "        [ 0.7895]], device='cuda:0'))\n",
      "{'loss': tensor(0.1294, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 491, 'agent.time_step': 5539, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 492, 'agent.time_step': 5546, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 493, 'agent.time_step': 5554, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 494, 'agent.time_step': 5562, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 495, 'agent.time_step': 5571, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 496, 'agent.time_step': 5580, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 497, 'agent.time_step': 5592, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 498, 'agent.time_step': 5603, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 499, 'agent.time_step': 5610, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 500, 'agent.time_step': 5620, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "(q_current, q_targets): (tensor([[0.8767],\n",
      "        [0.7577],\n",
      "        [0.8646],\n",
      "        [0.8733],\n",
      "        [0.8773],\n",
      "        [0.8764],\n",
      "        [0.2067],\n",
      "        [0.8613],\n",
      "        [0.8850],\n",
      "        [0.8627],\n",
      "        [0.7963],\n",
      "        [0.8852],\n",
      "        [0.8767],\n",
      "        [0.8767],\n",
      "        [0.8764],\n",
      "        [0.9094],\n",
      "        [0.9046],\n",
      "        [0.8732],\n",
      "        [0.8455],\n",
      "        [0.8806],\n",
      "        [0.8767],\n",
      "        [0.8730],\n",
      "        [0.8720],\n",
      "        [0.2448],\n",
      "        [0.8764],\n",
      "        [0.8733],\n",
      "        [0.8733],\n",
      "        [0.8767],\n",
      "        [0.8651],\n",
      "        [0.2490],\n",
      "        [0.8947],\n",
      "        [0.8765],\n",
      "        [0.8412],\n",
      "        [0.8619],\n",
      "        [0.8850],\n",
      "        [0.8710],\n",
      "        [0.8701],\n",
      "        [0.8698],\n",
      "        [0.8852],\n",
      "        [0.8768],\n",
      "        [0.8412],\n",
      "        [0.8180],\n",
      "        [0.2072],\n",
      "        [0.8532],\n",
      "        [0.8746],\n",
      "        [0.7265],\n",
      "        [0.8764],\n",
      "        [0.8892],\n",
      "        [0.7598],\n",
      "        [0.9067],\n",
      "        [0.8839],\n",
      "        [0.8498],\n",
      "        [0.8765],\n",
      "        [0.8733],\n",
      "        [0.7265],\n",
      "        [0.8586],\n",
      "        [0.8733],\n",
      "        [0.8764],\n",
      "        [0.8679],\n",
      "        [0.8733],\n",
      "        [0.8680],\n",
      "        [0.8764],\n",
      "        [0.8334],\n",
      "        [0.8706]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7979],\n",
      "        [ 0.8044],\n",
      "        [ 0.7869],\n",
      "        [ 0.7928],\n",
      "        [ 0.7933],\n",
      "        [ 0.7969],\n",
      "        [-1.0000],\n",
      "        [ 0.8042],\n",
      "        [ 0.7939],\n",
      "        [ 0.7890],\n",
      "        [ 0.8118],\n",
      "        [ 0.7901],\n",
      "        [ 0.8000],\n",
      "        [ 0.7930],\n",
      "        [ 0.7935],\n",
      "        [ 0.7908],\n",
      "        [ 0.7949],\n",
      "        [ 0.7826],\n",
      "        [ 0.7946],\n",
      "        [ 0.7930],\n",
      "        [ 0.8015],\n",
      "        [ 0.7928],\n",
      "        [ 0.7978],\n",
      "        [-1.0000],\n",
      "        [ 0.7893],\n",
      "        [ 0.8089],\n",
      "        [ 0.8005],\n",
      "        [ 0.7909],\n",
      "        [ 0.7970],\n",
      "        [ 0.7795],\n",
      "        [ 0.7826],\n",
      "        [ 0.7909],\n",
      "        [ 0.7842],\n",
      "        [ 0.8024],\n",
      "        [ 0.7940],\n",
      "        [ 0.7963],\n",
      "        [ 0.7907],\n",
      "        [ 0.7931],\n",
      "        [ 0.7913],\n",
      "        [ 0.8097],\n",
      "        [ 0.7948],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.7932],\n",
      "        [ 0.7955],\n",
      "        [ 0.7857],\n",
      "        [ 0.7976],\n",
      "        [ 0.7997],\n",
      "        [ 0.7911],\n",
      "        [ 0.7878],\n",
      "        [ 0.7927],\n",
      "        [ 0.7882],\n",
      "        [ 0.8211],\n",
      "        [ 0.7995],\n",
      "        [ 0.8158],\n",
      "        [ 0.8059],\n",
      "        [ 0.7907],\n",
      "        [ 0.7805],\n",
      "        [-1.0000],\n",
      "        [ 0.7961],\n",
      "        [ 0.7987],\n",
      "        [ 0.8126],\n",
      "        [ 0.7980]], device='cuda:0'))\n",
      "{'loss': tensor(0.1019, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "500 7.68\n",
      "{'episode': 501, 'agent.time_step': 5627, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 502, 'agent.time_step': 5634, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 503, 'agent.time_step': 5643, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 504, 'agent.time_step': 5655, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 505, 'agent.time_step': 5664, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 506, 'agent.time_step': 5677, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 507, 'agent.time_step': 5688, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 508, 'agent.time_step': 5697, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 509, 'agent.time_step': 5704, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 510, 'agent.time_step': 5715, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "(q_current, q_targets): (tensor([[0.7974],\n",
      "        [0.7968],\n",
      "        [0.2963],\n",
      "        [0.7931],\n",
      "        [0.7893],\n",
      "        [0.7656],\n",
      "        [0.7965],\n",
      "        [0.7852],\n",
      "        [0.7965],\n",
      "        [0.7962],\n",
      "        [0.8656],\n",
      "        [0.7725],\n",
      "        [0.7965],\n",
      "        [0.7965],\n",
      "        [0.7634],\n",
      "        [0.7974],\n",
      "        [0.8200],\n",
      "        [0.7893],\n",
      "        [0.7974],\n",
      "        [0.7911],\n",
      "        [0.7929],\n",
      "        [0.7965],\n",
      "        [0.7909],\n",
      "        [0.7931],\n",
      "        [0.7695],\n",
      "        [0.7931],\n",
      "        [0.7878],\n",
      "        [0.8279],\n",
      "        [0.7968],\n",
      "        [0.7965],\n",
      "        [0.7894],\n",
      "        [0.7965],\n",
      "        [0.7879],\n",
      "        [0.7694],\n",
      "        [0.7965],\n",
      "        [0.7909],\n",
      "        [0.7974],\n",
      "        [0.7655],\n",
      "        [0.7931],\n",
      "        [0.8161],\n",
      "        [0.7562],\n",
      "        [0.7931],\n",
      "        [0.7656],\n",
      "        [0.7931],\n",
      "        [0.7942],\n",
      "        [0.7915],\n",
      "        [0.7184],\n",
      "        [0.8403],\n",
      "        [0.7965],\n",
      "        [0.7965],\n",
      "        [0.7946],\n",
      "        [0.7965],\n",
      "        [0.8223],\n",
      "        [0.7946],\n",
      "        [0.8014],\n",
      "        [0.7965],\n",
      "        [0.8146],\n",
      "        [0.7969],\n",
      "        [0.7931],\n",
      "        [0.7656],\n",
      "        [0.7913],\n",
      "        [0.7931],\n",
      "        [0.7974],\n",
      "        [0.7538]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7797],\n",
      "        [ 0.7733],\n",
      "        [ 0.7712],\n",
      "        [ 0.7960],\n",
      "        [ 0.7685],\n",
      "        [ 0.7765],\n",
      "        [ 0.7834],\n",
      "        [ 0.8018],\n",
      "        [ 0.7750],\n",
      "        [ 0.7745],\n",
      "        [ 0.7842],\n",
      "        [ 0.7827],\n",
      "        [ 0.7827],\n",
      "        [ 0.7744],\n",
      "        [ 0.7779],\n",
      "        [ 0.7804],\n",
      "        [ 0.7744],\n",
      "        [-1.0000],\n",
      "        [ 0.7811],\n",
      "        [ 0.7934],\n",
      "        [ 0.7890],\n",
      "        [ 0.7723],\n",
      "        [ 0.7737],\n",
      "        [ 0.7975],\n",
      "        [-1.0000],\n",
      "        [ 0.7936],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.7695],\n",
      "        [ 0.7864],\n",
      "        [ 0.7899],\n",
      "        [ 0.7724],\n",
      "        [ 0.7780],\n",
      "        [ 0.7807],\n",
      "        [ 0.7727],\n",
      "        [ 0.7757],\n",
      "        [ 0.7820],\n",
      "        [ 0.7778],\n",
      "        [ 0.7703],\n",
      "        [ 0.7774],\n",
      "        [ 0.7768],\n",
      "        [ 0.7842],\n",
      "        [ 0.7787],\n",
      "        [ 0.7760],\n",
      "        [ 0.7776],\n",
      "        [ 0.7938],\n",
      "        [-1.0000],\n",
      "        [ 0.7904],\n",
      "        [ 0.7733],\n",
      "        [ 0.7831],\n",
      "        [ 0.7764],\n",
      "        [ 0.7754],\n",
      "        [ 0.7777],\n",
      "        [ 0.8049],\n",
      "        [-1.0000],\n",
      "        [ 0.7828],\n",
      "        [ 0.7847],\n",
      "        [ 0.7797],\n",
      "        [ 0.7803],\n",
      "        [ 0.7806],\n",
      "        [ 0.7906],\n",
      "        [ 0.7953],\n",
      "        [ 0.7825],\n",
      "        [ 0.7668]], device='cuda:0'))\n",
      "{'loss': tensor(0.1222, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 511, 'agent.time_step': 5721, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 512, 'agent.time_step': 5729, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 513, 'agent.time_step': 5738, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 514, 'agent.time_step': 5748, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 515, 'agent.time_step': 5761, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 516, 'agent.time_step': 5770, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 517, 'agent.time_step': 5778, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 518, 'agent.time_step': 5787, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 519, 'agent.time_step': 5794, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 520, 'agent.time_step': 5809, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "(q_current, q_targets): (tensor([[0.6723],\n",
      "        [0.6584],\n",
      "        [0.6550],\n",
      "        [0.6636],\n",
      "        [0.6568],\n",
      "        [0.7087],\n",
      "        [0.6564],\n",
      "        [0.6550],\n",
      "        [0.6576],\n",
      "        [0.6532],\n",
      "        [0.6130],\n",
      "        [0.6794],\n",
      "        [0.5619],\n",
      "        [0.6936],\n",
      "        [0.6826],\n",
      "        [0.6347],\n",
      "        [0.6520],\n",
      "        [0.6584],\n",
      "        [0.6891],\n",
      "        [0.6576],\n",
      "        [0.5477],\n",
      "        [0.6576],\n",
      "        [0.6400],\n",
      "        [0.6960],\n",
      "        [0.6559],\n",
      "        [0.7237],\n",
      "        [0.6464],\n",
      "        [0.6590],\n",
      "        [0.6452],\n",
      "        [0.6550],\n",
      "        [0.6391],\n",
      "        [0.6576],\n",
      "        [0.6576],\n",
      "        [0.6584],\n",
      "        [0.6520],\n",
      "        [0.6697],\n",
      "        [0.6366],\n",
      "        [0.6584],\n",
      "        [0.6649],\n",
      "        [0.6574],\n",
      "        [0.7269],\n",
      "        [0.6779],\n",
      "        [0.6516],\n",
      "        [0.5896],\n",
      "        [0.5603],\n",
      "        [0.6576],\n",
      "        [0.6576],\n",
      "        [0.6696],\n",
      "        [0.5547],\n",
      "        [0.6584],\n",
      "        [0.6581],\n",
      "        [0.6771],\n",
      "        [0.6576],\n",
      "        [0.1777],\n",
      "        [0.6636],\n",
      "        [0.6576],\n",
      "        [0.6570],\n",
      "        [0.6584],\n",
      "        [0.1912],\n",
      "        [0.6274],\n",
      "        [0.6761],\n",
      "        [0.5984],\n",
      "        [0.6576],\n",
      "        [0.5910]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7790],\n",
      "        [ 0.7777],\n",
      "        [-1.0000],\n",
      "        [ 0.7782],\n",
      "        [ 0.7717],\n",
      "        [ 0.7754],\n",
      "        [ 0.7562],\n",
      "        [-1.0000],\n",
      "        [ 0.7852],\n",
      "        [ 0.7655],\n",
      "        [ 0.7692],\n",
      "        [ 0.7774],\n",
      "        [ 0.7805],\n",
      "        [ 0.7795],\n",
      "        [ 0.7739],\n",
      "        [-1.0000],\n",
      "        [ 0.7804],\n",
      "        [ 0.7737],\n",
      "        [ 0.7716],\n",
      "        [ 0.7781],\n",
      "        [ 0.7674],\n",
      "        [ 0.7754],\n",
      "        [ 0.7947],\n",
      "        [ 0.7895],\n",
      "        [ 0.7705],\n",
      "        [ 0.7842],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.7852],\n",
      "        [ 0.7767],\n",
      "        [ 0.7795],\n",
      "        [ 0.7848],\n",
      "        [ 0.7864],\n",
      "        [ 0.7736],\n",
      "        [ 0.7703],\n",
      "        [ 0.7744],\n",
      "        [ 0.7730],\n",
      "        [ 0.7805],\n",
      "        [ 0.7722],\n",
      "        [ 0.7770],\n",
      "        [ 0.7720],\n",
      "        [ 0.7670],\n",
      "        [ 0.7794],\n",
      "        [ 0.7845],\n",
      "        [ 0.7884],\n",
      "        [ 0.7809],\n",
      "        [ 0.7738],\n",
      "        [ 0.7785],\n",
      "        [ 0.7735],\n",
      "        [ 0.7854],\n",
      "        [ 0.7790],\n",
      "        [ 0.7937],\n",
      "        [ 0.7806],\n",
      "        [-1.0000],\n",
      "        [ 0.7884],\n",
      "        [ 0.7767],\n",
      "        [ 0.7724],\n",
      "        [ 0.7762],\n",
      "        [ 0.7710],\n",
      "        [ 0.7744],\n",
      "        [ 0.7672],\n",
      "        [ 0.7751],\n",
      "        [ 0.7846],\n",
      "        [ 0.7698]], device='cuda:0'))\n",
      "{'loss': tensor(0.1106, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 521, 'agent.time_step': 5816, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 522, 'agent.time_step': 5827, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 523, 'agent.time_step': 5835, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 524, 'agent.time_step': 5843, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 525, 'agent.time_step': 5853, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 526, 'agent.time_step': 5864, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 527, 'agent.time_step': 5871, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 528, 'agent.time_step': 5881, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 529, 'agent.time_step': 5892, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 530, 'agent.time_step': 5900, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[0.5685],\n",
      "        [0.5279],\n",
      "        [0.5613],\n",
      "        [0.5695],\n",
      "        [0.5707],\n",
      "        [0.5700],\n",
      "        [0.5535],\n",
      "        [0.5312],\n",
      "        [0.5707],\n",
      "        [0.5695],\n",
      "        [0.5673],\n",
      "        [0.1784],\n",
      "        [0.5710],\n",
      "        [0.5707],\n",
      "        [0.2572],\n",
      "        [0.5627],\n",
      "        [0.5593],\n",
      "        [0.5562],\n",
      "        [0.5707],\n",
      "        [0.5721],\n",
      "        [0.5700],\n",
      "        [0.5546],\n",
      "        [0.6096],\n",
      "        [0.5677],\n",
      "        [0.2031],\n",
      "        [0.5677],\n",
      "        [0.5069],\n",
      "        [0.5800],\n",
      "        [0.5664],\n",
      "        [0.5312],\n",
      "        [0.1997],\n",
      "        [0.6110],\n",
      "        [0.6128],\n",
      "        [0.5707],\n",
      "        [0.5832],\n",
      "        [0.5647],\n",
      "        [0.5069],\n",
      "        [0.5692],\n",
      "        [0.5652],\n",
      "        [0.5694],\n",
      "        [0.6543],\n",
      "        [0.5758],\n",
      "        [0.5700],\n",
      "        [0.5605],\n",
      "        [0.5700],\n",
      "        [0.6157],\n",
      "        [0.5677],\n",
      "        [0.5614],\n",
      "        [0.5699],\n",
      "        [0.5719],\n",
      "        [0.5590],\n",
      "        [0.5554],\n",
      "        [0.5665],\n",
      "        [0.5700],\n",
      "        [0.5524],\n",
      "        [0.4913],\n",
      "        [0.5674],\n",
      "        [0.5694],\n",
      "        [0.5700],\n",
      "        [0.4974],\n",
      "        [0.5699],\n",
      "        [0.5707],\n",
      "        [0.6122],\n",
      "        [0.5702]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7562],\n",
      "        [ 0.7692],\n",
      "        [ 0.7778],\n",
      "        [ 0.7829],\n",
      "        [ 0.7819],\n",
      "        [ 0.7775],\n",
      "        [-1.0000],\n",
      "        [ 0.7763],\n",
      "        [ 0.7819],\n",
      "        [ 0.7906],\n",
      "        [ 0.7851],\n",
      "        [ 0.7710],\n",
      "        [ 0.7888],\n",
      "        [ 0.7775],\n",
      "        [ 0.8053],\n",
      "        [ 0.7854],\n",
      "        [ 0.7739],\n",
      "        [ 0.7715],\n",
      "        [ 0.7829],\n",
      "        [ 0.7886],\n",
      "        [ 0.7759],\n",
      "        [ 0.8066],\n",
      "        [ 0.7856],\n",
      "        [ 0.7925],\n",
      "        [ 0.7684],\n",
      "        [-1.0000],\n",
      "        [ 0.7755],\n",
      "        [ 0.7707],\n",
      "        [ 0.7655],\n",
      "        [ 0.7781],\n",
      "        [ 0.7728],\n",
      "        [ 0.7862],\n",
      "        [ 0.7777],\n",
      "        [ 0.7819],\n",
      "        [ 0.7789],\n",
      "        [-1.0000],\n",
      "        [ 0.7859],\n",
      "        [-1.0000],\n",
      "        [ 0.7787],\n",
      "        [ 0.7792],\n",
      "        [ 0.7850],\n",
      "        [ 0.7827],\n",
      "        [ 0.7754],\n",
      "        [ 0.8014],\n",
      "        [ 0.7811],\n",
      "        [ 0.7867],\n",
      "        [ 0.7812],\n",
      "        [ 0.7747],\n",
      "        [ 0.7763],\n",
      "        [ 0.7973],\n",
      "        [-1.0000],\n",
      "        [ 0.7853],\n",
      "        [ 0.7741],\n",
      "        [ 0.7741],\n",
      "        [ 0.7737],\n",
      "        [-1.0000],\n",
      "        [ 0.7758],\n",
      "        [ 0.7777],\n",
      "        [ 0.7802],\n",
      "        [ 0.7674],\n",
      "        [ 0.7757],\n",
      "        [ 0.7776],\n",
      "        [-1.0000],\n",
      "        [ 0.7731]], device='cuda:0'))\n",
      "{'loss': tensor(0.1451, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 531, 'agent.time_step': 5913, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 532, 'agent.time_step': 5922, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 533, 'agent.time_step': 5929, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 534, 'agent.time_step': 5938, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 535, 'agent.time_step': 5947, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 536, 'agent.time_step': 5959, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 537, 'agent.time_step': 5970, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 538, 'agent.time_step': 5979, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 539, 'agent.time_step': 5989, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 540, 'agent.time_step': 6000, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "(q_current, q_targets): (tensor([[0.5330],\n",
      "        [0.1951],\n",
      "        [0.5269],\n",
      "        [0.5269],\n",
      "        [0.4816],\n",
      "        [0.5296],\n",
      "        [0.5278],\n",
      "        [0.5399],\n",
      "        [0.1670],\n",
      "        [0.5317],\n",
      "        [0.5292],\n",
      "        [0.5285],\n",
      "        [0.5269],\n",
      "        [0.5720],\n",
      "        [0.5169],\n",
      "        [0.5530],\n",
      "        [0.5269],\n",
      "        [0.5281],\n",
      "        [0.5157],\n",
      "        [0.5269],\n",
      "        [0.5267],\n",
      "        [0.5269],\n",
      "        [0.5169],\n",
      "        [0.5283],\n",
      "        [0.1949],\n",
      "        [0.5296],\n",
      "        [0.5514],\n",
      "        [0.5269],\n",
      "        [0.4316],\n",
      "        [0.5292],\n",
      "        [0.5554],\n",
      "        [0.5428],\n",
      "        [0.5296],\n",
      "        [0.5479],\n",
      "        [0.5169],\n",
      "        [0.5117],\n",
      "        [0.1747],\n",
      "        [0.5287],\n",
      "        [0.5287],\n",
      "        [0.4956],\n",
      "        [0.3841],\n",
      "        [0.5292],\n",
      "        [0.4882],\n",
      "        [0.5252],\n",
      "        [0.5469],\n",
      "        [0.5169],\n",
      "        [0.5269],\n",
      "        [0.5221],\n",
      "        [0.5427],\n",
      "        [0.5269],\n",
      "        [0.5292],\n",
      "        [0.5386],\n",
      "        [0.5017],\n",
      "        [0.6026],\n",
      "        [0.5149],\n",
      "        [0.5239],\n",
      "        [0.5169],\n",
      "        [0.5492],\n",
      "        [0.5239],\n",
      "        [0.5285],\n",
      "        [0.5292],\n",
      "        [0.5296],\n",
      "        [0.5299],\n",
      "        [0.5239]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7734],\n",
      "        [ 0.7731],\n",
      "        [ 0.7858],\n",
      "        [ 0.7958],\n",
      "        [-1.0000],\n",
      "        [ 0.7778],\n",
      "        [ 0.7758],\n",
      "        [ 0.7721],\n",
      "        [ 0.7632],\n",
      "        [ 0.7806],\n",
      "        [ 0.7742],\n",
      "        [ 0.7802],\n",
      "        [ 0.7772],\n",
      "        [ 0.7751],\n",
      "        [ 0.7802],\n",
      "        [ 0.7865],\n",
      "        [ 0.7869],\n",
      "        [ 0.7731],\n",
      "        [ 0.7807],\n",
      "        [-1.0000],\n",
      "        [ 0.7959],\n",
      "        [ 0.7988],\n",
      "        [ 0.7720],\n",
      "        [ 0.7740],\n",
      "        [-1.0000],\n",
      "        [ 0.7797],\n",
      "        [ 0.7733],\n",
      "        [ 0.7786],\n",
      "        [ 0.7737],\n",
      "        [ 0.7846],\n",
      "        [ 0.7720],\n",
      "        [ 0.7717],\n",
      "        [ 0.7780],\n",
      "        [ 0.7650],\n",
      "        [ 0.7798],\n",
      "        [ 0.7845],\n",
      "        [ 0.7675],\n",
      "        [ 0.7755],\n",
      "        [ 0.7764],\n",
      "        [ 0.7802],\n",
      "        [-1.0000],\n",
      "        [ 0.7728],\n",
      "        [-1.0000],\n",
      "        [ 0.7784],\n",
      "        [ 0.7940],\n",
      "        [ 0.7768],\n",
      "        [ 0.7941],\n",
      "        [ 0.7842],\n",
      "        [ 0.7786],\n",
      "        [ 0.7860],\n",
      "        [ 0.7846],\n",
      "        [ 0.7800],\n",
      "        [-1.0000],\n",
      "        [ 0.7710],\n",
      "        [ 0.7982],\n",
      "        [ 0.7630],\n",
      "        [ 0.7727],\n",
      "        [ 0.7729],\n",
      "        [ 0.7679],\n",
      "        [ 0.7737],\n",
      "        [ 0.7673],\n",
      "        [ 0.7779],\n",
      "        [ 0.7724],\n",
      "        [ 0.7676]], device='cuda:0'))\n",
      "{'loss': tensor(0.1222, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 541, 'agent.time_step': 6009, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 542, 'agent.time_step': 6021, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 543, 'agent.time_step': 6030, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 544, 'agent.time_step': 6040, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 545, 'agent.time_step': 6050, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 546, 'agent.time_step': 6057, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 547, 'agent.time_step': 6072, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 548, 'agent.time_step': 6084, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 549, 'agent.time_step': 6091, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 550, 'agent.time_step': 6101, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "(q_current, q_targets): (tensor([[0.5420],\n",
      "        [0.5472],\n",
      "        [0.5376],\n",
      "        [0.5636],\n",
      "        [0.5886],\n",
      "        [0.5433],\n",
      "        [0.1697],\n",
      "        [0.5433],\n",
      "        [0.6138],\n",
      "        [0.5713],\n",
      "        [0.1782],\n",
      "        [0.5465],\n",
      "        [0.5516],\n",
      "        [0.5995],\n",
      "        [0.5689],\n",
      "        [0.5466],\n",
      "        [0.5248],\n",
      "        [0.5473],\n",
      "        [0.5465],\n",
      "        [0.5465],\n",
      "        [0.5481],\n",
      "        [0.5432],\n",
      "        [0.5423],\n",
      "        [0.5029],\n",
      "        [0.5530],\n",
      "        [0.5465],\n",
      "        [0.5472],\n",
      "        [0.5442],\n",
      "        [0.5378],\n",
      "        [0.5465],\n",
      "        [0.5387],\n",
      "        [0.5442],\n",
      "        [0.5460],\n",
      "        [0.5404],\n",
      "        [0.5641],\n",
      "        [0.5465],\n",
      "        [0.5517],\n",
      "        [0.4579],\n",
      "        [0.5267],\n",
      "        [0.5409],\n",
      "        [0.5386],\n",
      "        [0.5317],\n",
      "        [0.5253],\n",
      "        [0.5478],\n",
      "        [0.5069],\n",
      "        [0.5379],\n",
      "        [0.5464],\n",
      "        [0.5423],\n",
      "        [0.5379],\n",
      "        [0.5424],\n",
      "        [0.5284],\n",
      "        [0.5478],\n",
      "        [0.5472],\n",
      "        [0.5478],\n",
      "        [0.5455],\n",
      "        [0.3492],\n",
      "        [0.5442],\n",
      "        [0.5258],\n",
      "        [0.5682],\n",
      "        [0.5533],\n",
      "        [0.5442],\n",
      "        [0.5339],\n",
      "        [0.5387],\n",
      "        [0.5402]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7719],\n",
      "        [ 0.7796],\n",
      "        [ 0.7581],\n",
      "        [ 0.7915],\n",
      "        [ 0.7808],\n",
      "        [ 0.7759],\n",
      "        [ 0.7691],\n",
      "        [ 0.7790],\n",
      "        [ 0.7659],\n",
      "        [ 0.7781],\n",
      "        [-1.0000],\n",
      "        [ 0.7730],\n",
      "        [ 0.7941],\n",
      "        [ 0.7652],\n",
      "        [ 0.7767],\n",
      "        [ 0.7755],\n",
      "        [ 0.7929],\n",
      "        [ 0.7771],\n",
      "        [ 0.7764],\n",
      "        [ 0.7725],\n",
      "        [ 0.7768],\n",
      "        [ 0.7835],\n",
      "        [-1.0000],\n",
      "        [ 0.7849],\n",
      "        [ 0.7593],\n",
      "        [ 0.7727],\n",
      "        [ 0.7837],\n",
      "        [ 0.7724],\n",
      "        [-1.0000],\n",
      "        [ 0.7691],\n",
      "        [ 0.7781],\n",
      "        [-1.0000],\n",
      "        [ 0.7868],\n",
      "        [ 0.7707],\n",
      "        [ 0.7693],\n",
      "        [ 0.7627],\n",
      "        [ 0.7819],\n",
      "        [ 0.7656],\n",
      "        [ 0.7755],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.7780],\n",
      "        [ 0.7867],\n",
      "        [ 0.7775],\n",
      "        [ 0.7957],\n",
      "        [ 0.7743],\n",
      "        [ 0.7731],\n",
      "        [ 0.7810],\n",
      "        [ 0.7953],\n",
      "        [ 0.7770],\n",
      "        [ 0.7860],\n",
      "        [ 0.7768],\n",
      "        [ 0.7779],\n",
      "        [ 0.7736],\n",
      "        [ 0.7844],\n",
      "        [ 0.7772],\n",
      "        [ 0.7843],\n",
      "        [ 0.7837],\n",
      "        [ 0.7717],\n",
      "        [ 0.7793],\n",
      "        [ 0.7779],\n",
      "        [ 0.7848],\n",
      "        [ 0.7989],\n",
      "        [ 0.7791]], device='cuda:0'))\n",
      "{'loss': tensor(0.1202, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 551, 'agent.time_step': 6108, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 552, 'agent.time_step': 6119, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 553, 'agent.time_step': 6130, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 554, 'agent.time_step': 6143, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 555, 'agent.time_step': 6153, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 556, 'agent.time_step': 6159, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 557, 'agent.time_step': 6167, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 558, 'agent.time_step': 6176, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 559, 'agent.time_step': 6187, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 560, 'agent.time_step': 6195, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[0.6325],\n",
      "        [0.1788],\n",
      "        [0.4343],\n",
      "        [0.6294],\n",
      "        [0.6127],\n",
      "        [0.6169],\n",
      "        [0.5727],\n",
      "        [0.1951],\n",
      "        [0.6169],\n",
      "        [0.6169],\n",
      "        [0.5602],\n",
      "        [0.6237],\n",
      "        [0.5869],\n",
      "        [0.6034],\n",
      "        [0.6160],\n",
      "        [0.6113],\n",
      "        [0.6352],\n",
      "        [0.6059],\n",
      "        [0.6244],\n",
      "        [0.6168],\n",
      "        [0.6127],\n",
      "        [0.6101],\n",
      "        [0.5752],\n",
      "        [0.6290],\n",
      "        [0.1899],\n",
      "        [0.6160],\n",
      "        [0.6281],\n",
      "        [0.6196],\n",
      "        [0.6659],\n",
      "        [0.1951],\n",
      "        [0.2276],\n",
      "        [0.6127],\n",
      "        [0.6101],\n",
      "        [0.6127],\n",
      "        [0.6074],\n",
      "        [0.6333],\n",
      "        [0.6088],\n",
      "        [0.6169],\n",
      "        [0.6127],\n",
      "        [0.6169],\n",
      "        [0.6161],\n",
      "        [0.6169],\n",
      "        [0.6138],\n",
      "        [0.5777],\n",
      "        [0.6421],\n",
      "        [0.6088],\n",
      "        [0.6169],\n",
      "        [0.5577],\n",
      "        [0.6169],\n",
      "        [0.6169],\n",
      "        [0.6169],\n",
      "        [0.6266],\n",
      "        [0.1951],\n",
      "        [0.5986],\n",
      "        [0.2344],\n",
      "        [0.6190],\n",
      "        [0.6118],\n",
      "        [0.6266],\n",
      "        [0.6101],\n",
      "        [0.6654],\n",
      "        [0.6160],\n",
      "        [0.6237],\n",
      "        [0.6088],\n",
      "        [0.6055]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7615],\n",
      "        [ 0.7597],\n",
      "        [-1.0000],\n",
      "        [ 0.7645],\n",
      "        [ 0.7732],\n",
      "        [ 0.7681],\n",
      "        [ 0.7876],\n",
      "        [ 0.7579],\n",
      "        [ 0.7632],\n",
      "        [ 0.7740],\n",
      "        [ 0.7817],\n",
      "        [ 0.7708],\n",
      "        [-1.0000],\n",
      "        [ 0.7700],\n",
      "        [ 0.7756],\n",
      "        [ 0.7730],\n",
      "        [ 0.7799],\n",
      "        [ 0.7574],\n",
      "        [ 0.7677],\n",
      "        [ 0.7641],\n",
      "        [ 0.7798],\n",
      "        [ 0.7640],\n",
      "        [ 0.7687],\n",
      "        [ 0.7642],\n",
      "        [-1.0000],\n",
      "        [ 0.7546],\n",
      "        [ 0.7489],\n",
      "        [ 0.7467],\n",
      "        [ 0.7644],\n",
      "        [ 0.7536],\n",
      "        [ 0.7735],\n",
      "        [ 0.7933],\n",
      "        [ 0.7618],\n",
      "        [ 0.7710],\n",
      "        [ 0.7611],\n",
      "        [ 0.7611],\n",
      "        [ 0.7501],\n",
      "        [ 0.7619],\n",
      "        [ 0.7660],\n",
      "        [ 0.7638],\n",
      "        [ 0.7872],\n",
      "        [ 0.7660],\n",
      "        [ 0.7677],\n",
      "        [-1.0000],\n",
      "        [ 0.7565],\n",
      "        [ 0.7554],\n",
      "        [ 0.7681],\n",
      "        [-1.0000],\n",
      "        [ 0.7815],\n",
      "        [ 0.7646],\n",
      "        [ 0.7699],\n",
      "        [ 0.7644],\n",
      "        [-1.0000],\n",
      "        [ 0.7620],\n",
      "        [-1.0000],\n",
      "        [ 0.7601],\n",
      "        [ 0.7626],\n",
      "        [ 0.7541],\n",
      "        [ 0.7751],\n",
      "        [ 0.7644],\n",
      "        [ 0.7554],\n",
      "        [ 0.7760],\n",
      "        [ 0.7510],\n",
      "        [-1.0000]], device='cuda:0'))\n",
      "{'loss': tensor(0.1345, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 561, 'agent.time_step': 6203, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 562, 'agent.time_step': 6212, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 563, 'agent.time_step': 6221, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 564, 'agent.time_step': 6233, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 565, 'agent.time_step': 6242, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 566, 'agent.time_step': 6250, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 567, 'agent.time_step': 6258, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 568, 'agent.time_step': 6267, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 569, 'agent.time_step': 6275, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 570, 'agent.time_step': 6287, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "(q_current, q_targets): (tensor([[0.6524],\n",
      "        [0.7330],\n",
      "        [0.7112],\n",
      "        [0.7018],\n",
      "        [0.7112],\n",
      "        [0.7122],\n",
      "        [0.7065],\n",
      "        [0.7026],\n",
      "        [0.7083],\n",
      "        [0.6593],\n",
      "        [0.7071],\n",
      "        [0.6827],\n",
      "        [0.7122],\n",
      "        [0.7057],\n",
      "        [0.7713],\n",
      "        [0.7116],\n",
      "        [0.7112],\n",
      "        [0.7105],\n",
      "        [0.7430],\n",
      "        [0.2896],\n",
      "        [0.7094],\n",
      "        [0.7437],\n",
      "        [0.7224],\n",
      "        [0.7027],\n",
      "        [0.7053],\n",
      "        [0.7130],\n",
      "        [0.7096],\n",
      "        [0.8067],\n",
      "        [0.6531],\n",
      "        [0.7500],\n",
      "        [0.7122],\n",
      "        [0.7062],\n",
      "        [0.7065],\n",
      "        [0.7122],\n",
      "        [0.7112],\n",
      "        [0.7311],\n",
      "        [0.7065],\n",
      "        [0.7198],\n",
      "        [0.7065],\n",
      "        [0.7053],\n",
      "        [0.6827],\n",
      "        [0.7113],\n",
      "        [0.7122],\n",
      "        [0.7112],\n",
      "        [0.7112],\n",
      "        [0.7125],\n",
      "        [0.7437],\n",
      "        [0.7122],\n",
      "        [0.2715],\n",
      "        [0.7238],\n",
      "        [0.7289],\n",
      "        [0.7122],\n",
      "        [0.6772],\n",
      "        [0.7490],\n",
      "        [0.7113],\n",
      "        [0.6642],\n",
      "        [0.7207],\n",
      "        [0.7122],\n",
      "        [0.7122],\n",
      "        [0.7112],\n",
      "        [0.7121],\n",
      "        [0.7130],\n",
      "        [0.7125],\n",
      "        [0.7231]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7679],\n",
      "        [ 0.7838],\n",
      "        [ 0.7455],\n",
      "        [ 0.7671],\n",
      "        [ 0.7446],\n",
      "        [ 0.7661],\n",
      "        [-1.0000],\n",
      "        [ 0.7561],\n",
      "        [ 0.7640],\n",
      "        [ 0.7580],\n",
      "        [ 0.7628],\n",
      "        [ 0.7700],\n",
      "        [ 0.7701],\n",
      "        [ 0.7618],\n",
      "        [ 0.7540],\n",
      "        [ 0.7675],\n",
      "        [ 0.7545],\n",
      "        [ 0.7622],\n",
      "        [ 0.7570],\n",
      "        [ 0.7429],\n",
      "        [ 0.7872],\n",
      "        [ 0.7587],\n",
      "        [ 0.7677],\n",
      "        [ 0.7549],\n",
      "        [ 0.7590],\n",
      "        [ 0.7637],\n",
      "        [ 0.7612],\n",
      "        [ 0.7681],\n",
      "        [-1.0000],\n",
      "        [ 0.7611],\n",
      "        [ 0.7767],\n",
      "        [ 0.7684],\n",
      "        [-1.0000],\n",
      "        [ 0.7716],\n",
      "        [ 0.7613],\n",
      "        [ 0.7665],\n",
      "        [ 0.7732],\n",
      "        [ 0.7624],\n",
      "        [ 0.7713],\n",
      "        [ 0.7510],\n",
      "        [ 0.7712],\n",
      "        [ 0.7596],\n",
      "        [ 0.7679],\n",
      "        [ 0.7480],\n",
      "        [ 0.7540],\n",
      "        [ 0.7457],\n",
      "        [ 0.7662],\n",
      "        [ 0.7638],\n",
      "        [-1.0000],\n",
      "        [ 0.7605],\n",
      "        [ 0.7837],\n",
      "        [ 0.7667],\n",
      "        [-1.0000],\n",
      "        [ 0.7712],\n",
      "        [ 0.7617],\n",
      "        [ 0.7691],\n",
      "        [-1.0000],\n",
      "        [ 0.7614],\n",
      "        [ 0.7628],\n",
      "        [ 0.7678],\n",
      "        [ 0.7609],\n",
      "        [ 0.7624],\n",
      "        [ 0.7601],\n",
      "        [ 0.7644]], device='cuda:0'))\n",
      "{'loss': tensor(0.1082, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 571, 'agent.time_step': 6295, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 572, 'agent.time_step': 6303, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 573, 'agent.time_step': 6314, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 574, 'agent.time_step': 6323, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 575, 'agent.time_step': 6335, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 576, 'agent.time_step': 6346, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 577, 'agent.time_step': 6358, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 578, 'agent.time_step': 6367, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 579, 'agent.time_step': 6375, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 580, 'agent.time_step': 6387, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "(q_current, q_targets): (tensor([[0.7186],\n",
      "        [0.7740],\n",
      "        [0.7869],\n",
      "        [0.8020],\n",
      "        [0.7752],\n",
      "        [0.7674],\n",
      "        [0.7816],\n",
      "        [0.7546],\n",
      "        [0.7816],\n",
      "        [0.7800],\n",
      "        [0.1917],\n",
      "        [0.2209],\n",
      "        [0.7808],\n",
      "        [0.7623],\n",
      "        [0.7808],\n",
      "        [0.7730],\n",
      "        [0.7457],\n",
      "        [0.7671],\n",
      "        [0.7671],\n",
      "        [0.7674],\n",
      "        [0.7504],\n",
      "        [0.7785],\n",
      "        [0.7682],\n",
      "        [0.7808],\n",
      "        [0.7816],\n",
      "        [0.8113],\n",
      "        [0.7740],\n",
      "        [0.7800],\n",
      "        [0.7216],\n",
      "        [0.7562],\n",
      "        [0.8230],\n",
      "        [0.7794],\n",
      "        [0.7808],\n",
      "        [0.7719],\n",
      "        [0.7744],\n",
      "        [0.7717],\n",
      "        [0.7808],\n",
      "        [0.7187],\n",
      "        [0.7740],\n",
      "        [0.7808],\n",
      "        [0.7795],\n",
      "        [0.7674],\n",
      "        [0.1940],\n",
      "        [0.7808],\n",
      "        [0.7740],\n",
      "        [0.7808],\n",
      "        [0.2979],\n",
      "        [0.7816],\n",
      "        [0.8366],\n",
      "        [0.7800],\n",
      "        [0.7671],\n",
      "        [0.7794],\n",
      "        [0.8055],\n",
      "        [0.7800],\n",
      "        [0.7674],\n",
      "        [0.8008],\n",
      "        [0.7863],\n",
      "        [0.7808],\n",
      "        [0.8325],\n",
      "        [0.7532],\n",
      "        [0.7671],\n",
      "        [0.7816],\n",
      "        [0.7740],\n",
      "        [0.7794]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.7580],\n",
      "        [ 0.7635],\n",
      "        [ 0.7631],\n",
      "        [-1.0000],\n",
      "        [ 0.7566],\n",
      "        [ 0.7473],\n",
      "        [ 0.7644],\n",
      "        [ 0.7580],\n",
      "        [ 0.7458],\n",
      "        [ 0.7477],\n",
      "        [ 0.7641],\n",
      "        [ 0.7657],\n",
      "        [ 0.7523],\n",
      "        [ 0.7667],\n",
      "        [ 0.7585],\n",
      "        [ 0.7588],\n",
      "        [ 0.7654],\n",
      "        [-1.0000],\n",
      "        [ 0.7743],\n",
      "        [ 0.7711],\n",
      "        [ 0.7568],\n",
      "        [ 0.7593],\n",
      "        [ 0.7612],\n",
      "        [ 0.7680],\n",
      "        [ 0.7920],\n",
      "        [ 0.7568],\n",
      "        [ 0.7629],\n",
      "        [-1.0000],\n",
      "        [ 0.7572],\n",
      "        [ 0.7664],\n",
      "        [ 0.7586],\n",
      "        [ 0.7696],\n",
      "        [ 0.7819],\n",
      "        [ 0.7590],\n",
      "        [ 0.7568],\n",
      "        [ 0.7616],\n",
      "        [ 0.7647],\n",
      "        [ 0.7699],\n",
      "        [ 0.7619],\n",
      "        [ 0.7567],\n",
      "        [ 0.7578],\n",
      "        [ 0.7522],\n",
      "        [ 0.7649],\n",
      "        [ 0.7699],\n",
      "        [-1.0000],\n",
      "        [ 0.7601],\n",
      "        [ 0.7584],\n",
      "        [ 0.7580],\n",
      "        [ 0.7587],\n",
      "        [ 0.7639],\n",
      "        [ 0.7568],\n",
      "        [ 0.7614],\n",
      "        [ 0.7525],\n",
      "        [ 0.7626],\n",
      "        [ 0.7626],\n",
      "        [ 0.7624],\n",
      "        [ 0.7699],\n",
      "        [ 0.7724],\n",
      "        [ 0.7583],\n",
      "        [ 0.7592],\n",
      "        [ 0.7758],\n",
      "        [ 0.7688]], device='cuda:0'))\n",
      "{'loss': tensor(0.1180, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 581, 'agent.time_step': 6393, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 582, 'agent.time_step': 6402, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 583, 'agent.time_step': 6411, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 584, 'agent.time_step': 6421, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 585, 'agent.time_step': 6429, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 586, 'agent.time_step': 6439, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 587, 'agent.time_step': 6448, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 588, 'agent.time_step': 6458, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 589, 'agent.time_step': 6470, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 590, 'agent.time_step': 6477, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "(q_current, q_targets): (tensor([[0.7935],\n",
      "        [0.7683],\n",
      "        [0.4091],\n",
      "        [0.7643],\n",
      "        [0.7802],\n",
      "        [0.7338],\n",
      "        [0.7643],\n",
      "        [0.7831],\n",
      "        [0.6220],\n",
      "        [0.1968],\n",
      "        [0.7335],\n",
      "        [0.7547],\n",
      "        [0.7947],\n",
      "        [0.2441],\n",
      "        [0.2125],\n",
      "        [0.7829],\n",
      "        [0.7793],\n",
      "        [0.7789],\n",
      "        [0.7619],\n",
      "        [0.6087],\n",
      "        [0.7623],\n",
      "        [0.7935],\n",
      "        [0.7538],\n",
      "        [0.8055],\n",
      "        [0.7696],\n",
      "        [0.7803],\n",
      "        [0.7613],\n",
      "        [0.7723],\n",
      "        [0.7763],\n",
      "        [0.7898],\n",
      "        [0.7803],\n",
      "        [0.7723],\n",
      "        [0.7415],\n",
      "        [0.1968],\n",
      "        [0.7935],\n",
      "        [0.7757],\n",
      "        [0.8094],\n",
      "        [0.7698],\n",
      "        [0.7658],\n",
      "        [0.7126],\n",
      "        [0.7680],\n",
      "        [0.8133],\n",
      "        [0.7654],\n",
      "        [0.7754],\n",
      "        [0.7877],\n",
      "        [0.7782],\n",
      "        [0.7793],\n",
      "        [0.7623],\n",
      "        [0.7638],\n",
      "        [0.1966],\n",
      "        [0.7520],\n",
      "        [0.7623],\n",
      "        [0.7600],\n",
      "        [0.7055],\n",
      "        [0.7858],\n",
      "        [0.8438],\n",
      "        [0.7723],\n",
      "        [0.7793],\n",
      "        [0.7803],\n",
      "        [0.7789],\n",
      "        [0.8089],\n",
      "        [0.7728],\n",
      "        [0.7730],\n",
      "        [0.7876]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7587],\n",
      "        [ 0.7630],\n",
      "        [-1.0000],\n",
      "        [ 0.7547],\n",
      "        [ 0.7606],\n",
      "        [ 0.7698],\n",
      "        [-1.0000],\n",
      "        [ 0.7637],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.7585],\n",
      "        [ 0.7544],\n",
      "        [ 0.7569],\n",
      "        [ 0.7582],\n",
      "        [ 0.7567],\n",
      "        [ 0.7810],\n",
      "        [ 0.7573],\n",
      "        [ 0.7669],\n",
      "        [ 0.7681],\n",
      "        [ 0.7618],\n",
      "        [ 0.7604],\n",
      "        [ 0.7576],\n",
      "        [ 0.7649],\n",
      "        [ 0.7642],\n",
      "        [ 0.7660],\n",
      "        [ 0.7615],\n",
      "        [ 0.7869],\n",
      "        [ 0.7756],\n",
      "        [ 0.7755],\n",
      "        [ 0.7715],\n",
      "        [ 0.7723],\n",
      "        [-1.0000],\n",
      "        [ 0.7543],\n",
      "        [-1.0000],\n",
      "        [ 0.7626],\n",
      "        [ 0.7628],\n",
      "        [ 0.7525],\n",
      "        [ 0.7574],\n",
      "        [-1.0000],\n",
      "        [ 0.7583],\n",
      "        [ 0.7845],\n",
      "        [ 0.7684],\n",
      "        [ 0.7622],\n",
      "        [ 0.7612],\n",
      "        [ 0.7598],\n",
      "        [ 0.7715],\n",
      "        [ 0.7617],\n",
      "        [ 0.7595],\n",
      "        [ 0.7552],\n",
      "        [-1.0000],\n",
      "        [ 0.7582],\n",
      "        [ 0.7631],\n",
      "        [ 0.7773],\n",
      "        [ 0.7479],\n",
      "        [ 0.7816],\n",
      "        [ 0.7652],\n",
      "        [ 0.7789],\n",
      "        [ 0.7646],\n",
      "        [ 0.7570],\n",
      "        [ 0.7634],\n",
      "        [ 0.7685],\n",
      "        [ 0.7545],\n",
      "        [ 0.7685],\n",
      "        [ 0.7785]], device='cuda:0'))\n",
      "{'loss': tensor(0.1286, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 591, 'agent.time_step': 6486, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 592, 'agent.time_step': 6496, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 593, 'agent.time_step': 6506, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 594, 'agent.time_step': 6518, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 595, 'agent.time_step': 6525, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 596, 'agent.time_step': 6538, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 597, 'agent.time_step': 6551, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 598, 'agent.time_step': 6561, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 599, 'agent.time_step': 6572, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 600, 'agent.time_step': 6580, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[0.7250],\n",
      "        [0.7256],\n",
      "        [0.7049],\n",
      "        [0.7156],\n",
      "        [0.7250],\n",
      "        [0.7241],\n",
      "        [0.7191],\n",
      "        [0.7409],\n",
      "        [0.7250],\n",
      "        [0.7175],\n",
      "        [0.7256],\n",
      "        [0.7270],\n",
      "        [0.7253],\n",
      "        [0.6931],\n",
      "        [0.7175],\n",
      "        [0.7096],\n",
      "        [0.7236],\n",
      "        [0.7250],\n",
      "        [0.7253],\n",
      "        [0.7175],\n",
      "        [0.7250],\n",
      "        [0.7528],\n",
      "        [0.6169],\n",
      "        [0.7389],\n",
      "        [0.7433],\n",
      "        [0.7175],\n",
      "        [0.7049],\n",
      "        [0.7256],\n",
      "        [0.7237],\n",
      "        [0.7023],\n",
      "        [0.7250],\n",
      "        [0.7256],\n",
      "        [0.7027],\n",
      "        [0.8063],\n",
      "        [0.6442],\n",
      "        [0.7250],\n",
      "        [0.7621],\n",
      "        [0.7049],\n",
      "        [0.7236],\n",
      "        [0.7614],\n",
      "        [0.7970],\n",
      "        [0.5591],\n",
      "        [0.6554],\n",
      "        [0.7256],\n",
      "        [0.7175],\n",
      "        [0.7608],\n",
      "        [0.7578],\n",
      "        [0.7326],\n",
      "        [0.7256],\n",
      "        [0.7113],\n",
      "        [0.7098],\n",
      "        [0.7236],\n",
      "        [0.6984],\n",
      "        [0.7250],\n",
      "        [0.1886],\n",
      "        [0.7049],\n",
      "        [0.7253],\n",
      "        [0.7250],\n",
      "        [0.7114],\n",
      "        [0.6738],\n",
      "        [0.8105],\n",
      "        [0.7250],\n",
      "        [0.7725],\n",
      "        [0.7253]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7652],\n",
      "        [ 0.7593],\n",
      "        [-1.0000],\n",
      "        [ 0.7686],\n",
      "        [ 0.7685],\n",
      "        [ 0.7683],\n",
      "        [ 0.7597],\n",
      "        [ 0.7521],\n",
      "        [ 0.7713],\n",
      "        [-1.0000],\n",
      "        [ 0.7574],\n",
      "        [ 0.7594],\n",
      "        [ 0.7567],\n",
      "        [ 0.7500],\n",
      "        [ 0.7850],\n",
      "        [ 0.7621],\n",
      "        [ 0.7644],\n",
      "        [ 0.7655],\n",
      "        [ 0.7591],\n",
      "        [ 0.7881],\n",
      "        [ 0.7713],\n",
      "        [ 0.7660],\n",
      "        [-1.0000],\n",
      "        [ 0.7622],\n",
      "        [ 0.7629],\n",
      "        [ 0.7740],\n",
      "        [ 0.7832],\n",
      "        [ 0.7622],\n",
      "        [ 0.7633],\n",
      "        [ 0.7598],\n",
      "        [ 0.7642],\n",
      "        [ 0.7586],\n",
      "        [ 0.7705],\n",
      "        [ 0.7666],\n",
      "        [ 0.7633],\n",
      "        [ 0.7647],\n",
      "        [ 0.7599],\n",
      "        [-1.0000],\n",
      "        [ 0.7631],\n",
      "        [ 0.7593],\n",
      "        [ 0.7714],\n",
      "        [-1.0000],\n",
      "        [ 0.7609],\n",
      "        [ 0.7668],\n",
      "        [ 0.7809],\n",
      "        [ 0.7668],\n",
      "        [ 0.7599],\n",
      "        [ 0.7697],\n",
      "        [ 0.7586],\n",
      "        [ 0.7636],\n",
      "        [ 0.7584],\n",
      "        [ 0.7645],\n",
      "        [-1.0000],\n",
      "        [ 0.7681],\n",
      "        [ 0.7554],\n",
      "        [ 0.7685],\n",
      "        [ 0.7629],\n",
      "        [ 0.7648],\n",
      "        [ 0.7585],\n",
      "        [ 0.7604],\n",
      "        [ 0.7674],\n",
      "        [ 0.7633],\n",
      "        [ 0.7637],\n",
      "        [ 0.7609]], device='cuda:0'))\n",
      "{'loss': tensor(0.1129, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "600 7.6\n",
      "{'episode': 601, 'agent.time_step': 6587, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 602, 'agent.time_step': 6595, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 603, 'agent.time_step': 6606, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 604, 'agent.time_step': 6611, 'rounds': 5, 'accumulate_reward': 3.0}\n",
      "{'episode': 605, 'agent.time_step': 6620, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 606, 'agent.time_step': 6629, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 607, 'agent.time_step': 6643, 'rounds': 14, 'accumulate_reward': 12.0}\n",
      "{'episode': 608, 'agent.time_step': 6658, 'rounds': 15, 'accumulate_reward': 13.0}\n",
      "{'episode': 609, 'agent.time_step': 6665, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "{'episode': 610, 'agent.time_step': 6673, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "(q_current, q_targets): (tensor([[0.6719],\n",
      "        [0.1742],\n",
      "        [0.6656],\n",
      "        [0.5820],\n",
      "        [0.6398],\n",
      "        [0.6990],\n",
      "        [0.6501],\n",
      "        [0.6558],\n",
      "        [0.6085],\n",
      "        [0.6490],\n",
      "        [0.6515],\n",
      "        [0.6109],\n",
      "        [0.6109],\n",
      "        [0.6701],\n",
      "        [0.6036],\n",
      "        [0.6489],\n",
      "        [0.6936],\n",
      "        [0.6137],\n",
      "        [0.6148],\n",
      "        [0.6590],\n",
      "        [0.6509],\n",
      "        [0.6490],\n",
      "        [0.6722],\n",
      "        [0.6398],\n",
      "        [0.4751],\n",
      "        [0.6314],\n",
      "        [0.6810],\n",
      "        [0.6427],\n",
      "        [0.7153],\n",
      "        [0.7522],\n",
      "        [0.6490],\n",
      "        [0.6495],\n",
      "        [0.6464],\n",
      "        [0.6589],\n",
      "        [0.6729],\n",
      "        [0.5924],\n",
      "        [0.6617],\n",
      "        [0.6490],\n",
      "        [0.6594],\n",
      "        [0.5973],\n",
      "        [0.6398],\n",
      "        [0.6398],\n",
      "        [0.9246],\n",
      "        [0.6398],\n",
      "        [0.6398],\n",
      "        [0.6425],\n",
      "        [0.2069],\n",
      "        [0.6489],\n",
      "        [0.6551],\n",
      "        [0.1801],\n",
      "        [0.6489],\n",
      "        [0.4978],\n",
      "        [0.6501],\n",
      "        [0.6109],\n",
      "        [0.6492],\n",
      "        [0.6501],\n",
      "        [0.6197],\n",
      "        [0.6342],\n",
      "        [0.6462],\n",
      "        [0.6398],\n",
      "        [0.6490],\n",
      "        [0.6440],\n",
      "        [0.6991],\n",
      "        [0.6489]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7506],\n",
      "        [ 0.7591],\n",
      "        [ 0.7400],\n",
      "        [ 0.7528],\n",
      "        [ 0.7575],\n",
      "        [ 0.7531],\n",
      "        [ 0.7336],\n",
      "        [ 0.7476],\n",
      "        [ 0.7650],\n",
      "        [ 0.7484],\n",
      "        [ 0.7379],\n",
      "        [-1.0000],\n",
      "        [ 0.7593],\n",
      "        [ 0.7383],\n",
      "        [ 0.7799],\n",
      "        [ 0.7505],\n",
      "        [ 0.7477],\n",
      "        [ 0.7546],\n",
      "        [ 0.7566],\n",
      "        [ 0.7389],\n",
      "        [ 0.7631],\n",
      "        [ 0.7531],\n",
      "        [ 0.7473],\n",
      "        [ 0.7704],\n",
      "        [ 0.7453],\n",
      "        [-1.0000],\n",
      "        [ 0.7444],\n",
      "        [ 0.7557],\n",
      "        [ 0.7563],\n",
      "        [ 0.7474],\n",
      "        [ 0.7481],\n",
      "        [ 0.7365],\n",
      "        [ 0.7492],\n",
      "        [ 0.7751],\n",
      "        [ 0.7577],\n",
      "        [ 0.7669],\n",
      "        [ 0.7458],\n",
      "        [ 0.7574],\n",
      "        [ 0.7523],\n",
      "        [ 0.7710],\n",
      "        [ 0.7613],\n",
      "        [ 0.7643],\n",
      "        [ 0.7534],\n",
      "        [ 0.7635],\n",
      "        [ 0.7613],\n",
      "        [ 0.7705],\n",
      "        [-1.0000],\n",
      "        [ 0.7484],\n",
      "        [ 0.7489],\n",
      "        [ 0.7482],\n",
      "        [ 0.7530],\n",
      "        [-1.0000],\n",
      "        [ 0.7453],\n",
      "        [-1.0000],\n",
      "        [ 0.7311],\n",
      "        [ 0.7316],\n",
      "        [ 0.7509],\n",
      "        [-1.0000],\n",
      "        [ 0.7515],\n",
      "        [ 0.7736],\n",
      "        [ 0.7489],\n",
      "        [ 0.7526],\n",
      "        [ 0.7555],\n",
      "        [ 0.7501]], device='cuda:0'))\n",
      "{'loss': tensor(0.1078, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 611, 'agent.time_step': 6684, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 612, 'agent.time_step': 6697, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 613, 'agent.time_step': 6709, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 614, 'agent.time_step': 6720, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 615, 'agent.time_step': 6731, 'rounds': 11, 'accumulate_reward': 9.0}\n",
      "{'episode': 616, 'agent.time_step': 6739, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 617, 'agent.time_step': 6752, 'rounds': 13, 'accumulate_reward': 11.0}\n",
      "{'episode': 618, 'agent.time_step': 6761, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 619, 'agent.time_step': 6769, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 620, 'agent.time_step': 6776, 'rounds': 7, 'accumulate_reward': 5.0}\n",
      "(q_current, q_targets): (tensor([[0.6276],\n",
      "        [0.6281],\n",
      "        [0.1736],\n",
      "        [0.5146],\n",
      "        [0.6550],\n",
      "        [0.6451],\n",
      "        [0.6166],\n",
      "        [0.6202],\n",
      "        [0.4158],\n",
      "        [0.6172],\n",
      "        [0.5931],\n",
      "        [0.6276],\n",
      "        [0.4075],\n",
      "        [0.6276],\n",
      "        [0.6281],\n",
      "        [0.6276],\n",
      "        [0.6431],\n",
      "        [0.6276],\n",
      "        [0.5625],\n",
      "        [0.6241],\n",
      "        [0.6276],\n",
      "        [0.1800],\n",
      "        [0.6276],\n",
      "        [0.5014],\n",
      "        [0.6281],\n",
      "        [0.6497],\n",
      "        [0.6355],\n",
      "        [0.5561],\n",
      "        [0.6571],\n",
      "        [0.6098],\n",
      "        [0.5639],\n",
      "        [0.6166],\n",
      "        [0.6060],\n",
      "        [0.6281],\n",
      "        [0.1798],\n",
      "        [0.6796],\n",
      "        [0.6714],\n",
      "        [0.1760],\n",
      "        [0.6166],\n",
      "        [0.6214],\n",
      "        [0.6281],\n",
      "        [0.6276],\n",
      "        [0.6276],\n",
      "        [0.5498],\n",
      "        [0.6756],\n",
      "        [0.6268],\n",
      "        [0.6060],\n",
      "        [0.1859],\n",
      "        [0.6166],\n",
      "        [0.6276],\n",
      "        [0.6327],\n",
      "        [0.6281],\n",
      "        [0.6610],\n",
      "        [0.6256],\n",
      "        [0.6276],\n",
      "        [0.6302],\n",
      "        [0.2655],\n",
      "        [0.6241],\n",
      "        [0.5625],\n",
      "        [0.2655],\n",
      "        [0.6140],\n",
      "        [0.6143],\n",
      "        [0.6184],\n",
      "        [0.6174]], device='cuda:0', grad_fn=<GatherBackward0>), tensor([[ 0.7577],\n",
      "        [ 0.7524],\n",
      "        [-1.0000],\n",
      "        [ 0.7566],\n",
      "        [ 0.7637],\n",
      "        [ 0.7566],\n",
      "        [ 0.7736],\n",
      "        [ 0.7511],\n",
      "        [-1.0000],\n",
      "        [ 0.7659],\n",
      "        [ 0.7441],\n",
      "        [ 0.7485],\n",
      "        [-1.0000],\n",
      "        [ 0.7477],\n",
      "        [ 0.7532],\n",
      "        [ 0.7559],\n",
      "        [ 0.7560],\n",
      "        [ 0.7580],\n",
      "        [ 0.7588],\n",
      "        [ 0.7457],\n",
      "        [ 0.7514],\n",
      "        [ 0.7426],\n",
      "        [ 0.7572],\n",
      "        [ 0.7770],\n",
      "        [ 0.7516],\n",
      "        [ 0.7516],\n",
      "        [ 0.7530],\n",
      "        [ 0.7576],\n",
      "        [ 0.7552],\n",
      "        [ 0.7795],\n",
      "        [ 0.7785],\n",
      "        [ 0.7852],\n",
      "        [ 0.7544],\n",
      "        [ 0.7540],\n",
      "        [-1.0000],\n",
      "        [ 0.7504],\n",
      "        [ 0.7570],\n",
      "        [-1.0000],\n",
      "        [ 0.7672],\n",
      "        [ 0.7464],\n",
      "        [ 0.7513],\n",
      "        [ 0.7541],\n",
      "        [ 0.7576],\n",
      "        [ 0.7482],\n",
      "        [ 0.7545],\n",
      "        [ 0.7571],\n",
      "        [ 0.7530],\n",
      "        [ 0.7479],\n",
      "        [ 0.7761],\n",
      "        [ 0.7505],\n",
      "        [ 0.7472],\n",
      "        [ 0.7549],\n",
      "        [ 0.7565],\n",
      "        [ 0.7410],\n",
      "        [ 0.7446],\n",
      "        [ 0.7506],\n",
      "        [ 0.7549],\n",
      "        [ 0.7481],\n",
      "        [ 0.7600],\n",
      "        [ 0.7501],\n",
      "        [ 0.7582],\n",
      "        [ 0.7741],\n",
      "        [ 0.7491],\n",
      "        [ 0.7418]], device='cuda:0'))\n",
      "{'loss': tensor(0.0776, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)}\n",
      "{'episode': 621, 'agent.time_step': 6786, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 622, 'agent.time_step': 6792, 'rounds': 6, 'accumulate_reward': 4.0}\n",
      "{'episode': 623, 'agent.time_step': 6804, 'rounds': 12, 'accumulate_reward': 10.0}\n",
      "{'episode': 624, 'agent.time_step': 6813, 'rounds': 9, 'accumulate_reward': 7.0}\n",
      "{'episode': 625, 'agent.time_step': 6823, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 626, 'agent.time_step': 6831, 'rounds': 8, 'accumulate_reward': 6.0}\n",
      "{'episode': 627, 'agent.time_step': 6841, 'rounds': 10, 'accumulate_reward': 8.0}\n",
      "{'episode': 628, 'agent.time_step': 6849, 'rounds': 8, 'accumulate_reward': 6.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores, num_rounds \u001b[39m=\u001b[39m train(agent, n_episodes\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, max_time_step\u001b[39m=\u001b[39;49m\u001b[39m3000\u001b[39;49m, eps_start\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, eps_end\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, eps_decay\u001b[39m=\u001b[39;49m\u001b[39m0.99\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[15], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(agent, n_episodes, max_time_step, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[0;32m     20\u001b[0m rounds \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m time_step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_time_step):\n\u001b[1;32m---> 22\u001b[0m     cv\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m25\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m     cv\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,image)\n\u001b[0;32m     24\u001b[0m     action_values \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mq_value(state, eps)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores, num_rounds = train(agent, n_episodes=1000, max_time_step=3000, eps_start=1.0, eps_end=0.01, eps_decay=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image : np.ndarray = env.render(mode='rgb_array')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d155ddd594e93c13dc604d9fde6a83ce6733a6c3fc0471778cef1ca6f99b89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
